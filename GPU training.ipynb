{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a463ee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!accelerate launch --mixed_precision fp16 ./train_accel.py --config_name EXP_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e55fb2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !CUDA_VISIBLE_DEVICES=0 python train.py --config_name BASELINE_HF_V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adfc1c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=0 python train.py --config_name BASELINE_HF_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eac1b9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !CUDA_VISIBLE_DEVICES=0 python train.py --config_name BASELINE_EMBED_V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0a3ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=0 python train.py --config_name BASELINE_EMBED_V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04a2411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=0 python train.py --config_name BASELINE_EMBED_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb6efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=0 python train.py --config_name MATGRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b50a7b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=0 python train.py --config_name MATGRAPHV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8460a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=0 python train.py --config_name BASELINE_EMBED_V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68f2ef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=0 python train.py --config_name BASELINE_EMBED_V5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7387fd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=0 python train.py --config_name BASELINE_HF_V5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c1ddc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=1 python train.py --config_name BASELINE_HF_V6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0efade63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=1 python train.py --config_name BASELINE_HF_V7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6d78e1f-0269-442e-98ab-487f868851c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=1 python train.py --config_name BASELINE_HF_V8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b10e564-20ed-4d96-b4bd-74161784bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=1 python train.py --config_name BASELINE_HF_V9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5a0b32e-3791-4253-b979-dc4163ae3ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=1 python eval.py --config_name BASELINE_HF_V8FTEVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26bedb23-c4cc-49d2-9cb0-2a4342a70d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_gpu_environ():\n",
    "    \"\"\"Sets CUDA_VISIBLE_DEVICES to those under minimal memory load.\n",
    "    Meant to be used in notebooks only.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import subprocess\n",
    "    query = subprocess.check_output(['nvidia-smi', '--query-gpu=memory.used', '--format=csv']).decode().split('\\n')[1:-1]\n",
    "    utilization = [int(x.replace(\" MiB\", \"\")) for x in query]\n",
    "    free = [i for i in range(len(utilization)) if utilization[i] == min(utilization)]\n",
    "    set_visible = \",\".join([str(i) for i in free])\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = set_visible\n",
    "set_gpu_environ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf265c11-0f95-421b-8b04-658abdd7f78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-02-17 05:19:43 - get_logger - Writing log to \u001b[1mlogs/graphnet_20230217-051943.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import config\n",
    "\n",
    "def seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "\n",
    "def train(cfg):\n",
    "    seed()\n",
    "    custom_model = cfg.MODEL_NAME()\n",
    "    if cfg.MODEL_WTS:\n",
    "        print(f\"Loading model weights from {cfg.MODEL_WTS}\")\n",
    "        custom_model.load_state_dict(torch.load(cfg.MODEL_WTS))\n",
    "    opt = cfg.OPT(\n",
    "        custom_model.parameters(), lr=cfg.LR, weight_decay=cfg.WD\n",
    "    )\n",
    "    loss_func = cfg.LOSS_FUNC()\n",
    "    scheduler = cfg.SCHEDULER(\n",
    "        opt,\n",
    "        num_warmup_steps=cfg.WARM_UP_PCT * cfg.EPOCHS,\n",
    "        num_training_steps=cfg.EPOCHS,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    cfg.FIT_FUNC(\n",
    "        epochs=cfg.EPOCHS,\n",
    "        model=custom_model,\n",
    "        loss_fn=loss_func,\n",
    "        opt=opt,\n",
    "        metric=cfg.METRIC,\n",
    "        config = cfg,\n",
    "        folder=cfg.FOLDER/cfg.EXP_NAME,\n",
    "        exp_name=f\"{cfg.EXP_NAME}\",\n",
    "        device=cfg.DEVICE,\n",
    "        sched=scheduler,\n",
    "    )\n",
    "    \n",
    "def main(config_name):\n",
    "    configs = eval(f\"config.{config_name}\")\n",
    "    print(f\"Training with config: {configs.__dict__}\")\n",
    "    os.makedirs(configs.FOLDER/configs.EXP_NAME)\n",
    "    train(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2d8352-19bd-4cba-90cd-85cb0bc1c7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with config: {'__module__': 'config', 'EXP_NAME': 'EXP_29_FT', 'MODEL_WTS': '/opt/slh/icecube/RESULTS/EXP_29/EXP_29_5.pth', 'LR': 0.0001, 'LOSS_FUNC': <class 'icecube.models.VonMisesFisher3DLossEcludeLossCosine'>, 'FIT_FUNC': <function fit_shufllef32 at 0x7f8983eb78c0>, 'EPOCHS': 6, 'TRN_DATASET': <class 'icecube.dataset.HuggingFaceDatasetV12'>, 'VAL_DATASET': <class 'icecube.dataset.HuggingFaceDatasetV12'>, 'COLLAT_FN': <function collate_fn_v1 at 0x7f8983eb7e60>, 'MODEL_NAME': <class 'icecube.models.IceCubeModelEncoderSensorEmbeddinngV4'>, 'BATCH_SIZE': 768, '__doc__': None}\n",
      "Loading model weights from /opt/slh/icecube/RESULTS/EXP_29/EXP_29_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py:1536: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  FutureWarning,\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdrhb\u001b[0m (\u001b[33mkaggle-hi\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/opt/slh/icecube/wandb/run-20230217_051946-3r2gtd61</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kaggle-hi/ice/runs/3r2gtd61\" target=\"_blank\">EXP_29_FT</a></strong> to <a href=\"https://wandb.ai/kaggle-hi/ice\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='1' class='' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      16.67% [1/6 6:43:47&lt;33:38:59]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>val_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='18278' class='' max='26042' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      70.19% [18278/26042 4:37:22&lt;1:57:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_range: [300, 400]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py:1536: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  FutureWarning,\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with value: 1.0040115118026733.\n",
      "   epoch  train_loss  valid_loss     metric\n",
      "0      0    0.965695    0.962668  1.0040115\n",
      "trn_range: [400, 500]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py:1536: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  FutureWarning,\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main('BASELINE_HF_V15_FT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41104639-4650-4d02-9ffd-c04ea585b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaae79eb-abca-4172-8fff-3fb172a2d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9491cd49-d8e9-4d0a-821e-ec948fc72cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0158ab-7f40-4539-81cd-2ba8b7d2a25e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "142ddef5a08e46edabc1dbc87570ddc1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_18f44b283f1143fb9f3002dd77a9a977",
       "style": "IPY_MODEL_e04e8a9d52a14b4a85a2b5ebe79b170e"
      }
     },
     "18f44b283f1143fb9f3002dd77a9a977": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3001ceccb4904badb0a0aa0deb579978": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_142ddef5a08e46edabc1dbc87570ddc1",
        "IPY_MODEL_c8a2438b5c3b4890a7fc3cb1f03e7ab7"
       ],
       "layout": "IPY_MODEL_7969962118524d07be50c1b85462ead3"
      }
     },
     "4340768b8c244f74bed7930c9e9b0eef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "452d10124d97490cb9a22d6cd5c9726d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7969962118524d07be50c1b85462ead3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c8a2438b5c3b4890a7fc3cb1f03e7ab7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_4340768b8c244f74bed7930c9e9b0eef",
       "max": 1,
       "style": "IPY_MODEL_452d10124d97490cb9a22d6cd5c9726d"
      }
     },
     "e04e8a9d52a14b4a85a2b5ebe79b170e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
