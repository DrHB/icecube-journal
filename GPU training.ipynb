{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a463ee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!accelerate launch --mixed_precision fp16 ./train_accel.py --config_name EXP_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e55fb2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !CUDA_VISIBLE_DEVICES=0 python train.py --config_name BASELINE_HF_V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adfc1c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=0 python train.py --config_name BASELINE_HF_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eac1b9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !CUDA_VISIBLE_DEVICES=0 python train.py --config_name BASELINE_EMBED_V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0a3ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=0 python train.py --config_name BASELINE_EMBED_V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04a2411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=0 python train.py --config_name BASELINE_EMBED_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb6efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=0 python train.py --config_name MATGRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b50a7b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=0 python train.py --config_name MATGRAPHV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8460a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=0 python train.py --config_name BASELINE_EMBED_V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68f2ef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=0 python train.py --config_name BASELINE_EMBED_V5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7387fd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=0 python train.py --config_name BASELINE_HF_V5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c1ddc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=1 python train.py --config_name BASELINE_HF_V6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0efade63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=1 python train.py --config_name BASELINE_HF_V7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6d78e1f-0269-442e-98ab-487f868851c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=1 python train.py --config_name BASELINE_HF_V8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b10e564-20ed-4d96-b4bd-74161784bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=1 python train.py --config_name BASELINE_HF_V9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5a0b32e-3791-4253-b979-dc4163ae3ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=1 python eval.py --config_name BASELINE_HF_V8FTEVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26bedb23-c4cc-49d2-9cb0-2a4342a70d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_gpu_environ():\n",
    "#     \"\"\"Sets CUDA_VISIBLE_DEVICES to those under minimal memory load.\n",
    "#     Meant to be used in notebooks only.\n",
    "#     \"\"\"\n",
    "#     import os\n",
    "#     import subprocess\n",
    "#     query = subprocess.check_output(['nvidia-smi', '--query-gpu=memory.used', '--format=csv']).decode().split('\\n')[1:-1]\n",
    "#     utilization = [int(x.replace(\" MiB\", \"\")) for x in query]\n",
    "#     free = [i for i in range(len(utilization)) if utilization[i] == min(utilization)]\n",
    "#     set_visible = \",\".join([str(i) for i in free])\n",
    "#     os.environ[\"CUDA_VISIBLE_DEVICES\"] = set_visible\n",
    "# set_gpu_environ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "662d0ee5-799d-4462-a2cb-230f5f109937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-02-27 22:41:45 - get_logger - Writing log to \u001b[1mlogs/graphnet_20230227-224145.log\u001b[0m\n",
      "0,1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import config\n",
    "\n",
    "def set_gpu_environ():\n",
    "    \"\"\"Sets CUDA_VISIBLE_DEVICES to those under minimal memory load.\n",
    "    Meant to be used in notebooks only.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import subprocess\n",
    "    query = subprocess.check_output(['nvidia-smi', '--query-gpu=memory.used', '--format=csv']).decode().split('\\n')[1:-1]\n",
    "    utilization = [int(x.replace(\" MiB\", \"\")) for x in query]\n",
    "    free = [i for i in range(len(utilization)) if utilization[i] == min(utilization)]\n",
    "    set_visible = \",\".join([str(i) for i in free])\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = set_visible\n",
    "    print(set_visible)\n",
    "set_gpu_environ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf265c11-0f95-421b-8b04-658abdd7f78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def train(cfg):\n",
    "    seed()\n",
    "    custom_model = cfg.MODEL_NAME()\n",
    "    if cfg.MODEL_WTS:\n",
    "        print(f\"Loading model weights from {cfg.MODEL_WTS}\")\n",
    "        custom_model.load_state_dict(torch.load(cfg.MODEL_WTS))\n",
    "    opt = cfg.OPT(\n",
    "        custom_model.parameters(), lr=cfg.LR, weight_decay=cfg.WD\n",
    "    )\n",
    "    loss_func = cfg.LOSS_FUNC()\n",
    "    len_trn_dl = (cfg.N_FILES * 200000)//cfg.BATCH_SIZE\n",
    "    warmup_steps = int(len_trn_dl * cfg.WARM_UP_PCT * cfg.EPOCHS)\n",
    "    total_steps = int(len_trn_dl * cfg.EPOCHS)\n",
    "\n",
    "    print(f\"Total steps: {total_steps}, Warmup steps: {warmup_steps}\")\n",
    "\n",
    "    scheduler = cfg.SCHEDULER(\n",
    "        opt,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps,\n",
    "    )\n",
    "\n",
    "    cfg.FIT_FUNC(\n",
    "        epochs=cfg.EPOCHS,\n",
    "        model=custom_model,\n",
    "        loss_fn=loss_func,\n",
    "        opt=opt,\n",
    "        metric=cfg.METRIC,\n",
    "        config = cfg,\n",
    "        folder=cfg.FOLDER/cfg.EXP_NAME,\n",
    "        exp_name=f\"{cfg.EXP_NAME}\",\n",
    "        device=cfg.DEVICE,\n",
    "        sched=scheduler,\n",
    "    )\n",
    "    \n",
    "def main(config_name):\n",
    "    configs = eval(f\"config.{config_name}\")\n",
    "    print(f\"Training with config: {configs.__dict__}\")\n",
    "    os.makedirs(configs.FOLDER/configs.EXP_NAME)\n",
    "    train(configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2d8352-19bd-4cba-90cd-85cb0bc1c7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with config: {'__module__': 'config', 'EXP_NAME': 'EXP_34_FT_2', 'FILTER': False, 'MODEL_WTS': '/opt/slh/icecube/RESULTS/EXP_34_FT/EXP_34_FT_5.pth', 'LR': 0.0003, 'EPOCHS': 24, 'LOSS_FUNC': <class 'icecube.modelsgraph.gVonMisesFisher3DLoss'>, 'N_FILES': 50, 'TRN_BATCH_RANGE': [[1, 51], [51, 101], [101, 151], [151, 201], [201, 251], [251, 301], [301, 351], [351, 401], [401, 451], [451, 501], [501, 551], [501, 601]], 'DEVICE': 'cuda:1', 'NUM_WORKERS': 22, 'BATCH_SIZE': 1280, '__doc__': None}\n",
      "Loading model weights from /opt/slh/icecube/RESULTS/EXP_34_FT/EXP_34_FT_5.pth\n",
      "Total steps: 187488, Warmup steps: 18748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdrhb\u001b[0m (\u001b[33mkaggle-hi\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/opt/slh/icecube/wandb/run-20230227_224149-1n1dho9r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kaggle-hi/ice/runs/1n1dho9r\" target=\"_blank\">EXP_34_FT_2</a></strong> to <a href=\"https://wandb.ai/kaggle-hi/ice\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='12' class='' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [12/24 14:25:49&lt;14:25:49]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>val_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='729' class='' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      93.22% [729/782 04:13&lt;00:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_range: [1, 51]\n",
      "Better model found at epoch 0 with value: 1.012536883354187.\n",
      "   epoch  train_loss  valid_loss     metric\n",
      "0      0    1.469686      1.4786  1.0125369\n",
      "trn_range: [51, 101]\n",
      "Better model found at epoch 1 with value: 1.0128681659698486.\n",
      "   epoch  train_loss  valid_loss     metric\n",
      "0      1    1.477044     1.47958  1.0128682\n",
      "trn_range: [101, 151]\n",
      "Better model found at epoch 2 with value: 1.0168836116790771.\n",
      "   epoch  train_loss  valid_loss     metric\n",
      "0      2    1.487331    1.487236  1.0168836\n",
      "trn_range: [151, 201]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 5 with value: 1.0167895555496216.\n",
      "   epoch  train_loss  valid_loss     metric\n",
      "0      5    1.484505      1.4865  1.0167896\n",
      "trn_range: [301, 351]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 10 with value: 1.014186143875122.\n",
      "   epoch  train_loss  valid_loss     metric\n",
      "0     10    1.469914    1.469508  1.0141861\n",
      "trn_range: [501, 601]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main('BASELINE_graph_V9_FT_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41104639-4650-4d02-9ffd-c04ea585b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaae79eb-abca-4172-8fff-3fb172a2d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9491cd49-d8e9-4d0a-821e-ec948fc72cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "kff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0158ab-7f40-4539-81cd-2ba8b7d2a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658281cd-a1cb-415f-9954-49e1cec5c750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e27f07b-a2fc-437d-b960-3f76a7a98e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc17aeb5-65b2-4ae7-a7eb-63b05a8651f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2663b7-965e-4f1b-b95f-8f4e05e61b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae356784-de06-4466-b51a-c657b1cdf739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b2691-f7cf-4758-8343-85bddf058869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2b3a339f29634d0b99f33918912aa00a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3e39bf17862049df97609f2f7cc6f220": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8f3e17110430483db0f93fe6ce32b591": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c1db6db699e04cff9a1c4fcd93b89132": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_fa5c7137198b451fbefb363b4f32f1c5",
        "IPY_MODEL_d485d334241a4e3c9220b8f1971c6024"
       ],
       "layout": "IPY_MODEL_8f3e17110430483db0f93fe6ce32b591"
      }
     },
     "d22dd4b3c03b4e07a84511ceeebe728a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d485d334241a4e3c9220b8f1971c6024": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_3e39bf17862049df97609f2f7cc6f220",
       "max": 1,
       "style": "IPY_MODEL_d22dd4b3c03b4e07a84511ceeebe728a"
      }
     },
     "e2f9216bfd854dc596078ebfa9c9f9c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fa5c7137198b451fbefb363b4f32f1c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_e2f9216bfd854dc596078ebfa9c9f9c4",
       "style": "IPY_MODEL_2b3a339f29634d0b99f33918912aa00a"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
