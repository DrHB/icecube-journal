{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f418a53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,0\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "#os.environ[\"NCCL_P2P_DISABLE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6efa89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "from fastai_fix import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b613edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT = 'init'\n",
    "PATH = 'data/'\n",
    "\n",
    "NUM_WORKERS = 12\n",
    "SEED = 2023\n",
    "bs = 512\n",
    "L = 192\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)\n",
    "os.makedirs(OUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ce4798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random\n",
    "from typing import Iterator, Iterable, Optional, Sequence, List, TypeVar, Generic, Sized, Union\n",
    "\n",
    "class RandomChunkSampler(torch.utils.data.Sampler[int]):\n",
    "    r\"\"\"Samples elements randomly. If without replacement, then sample from a shuffled dataset.\n",
    "    If with replacement, then user can specify :attr:`num_samples` to draw.\n",
    "    Args:\n",
    "        data_source (Dataset): dataset to sample from\n",
    "        replacement (bool): samples are drawn on-demand with replacement if ``True``, default=``False``\n",
    "        num_samples (int): number of samples to draw, default=`len(dataset)`.\n",
    "        generator (Generator): Generator used in sampling.\n",
    "    \"\"\"\n",
    "    data_source: Sized\n",
    "    replacement: bool\n",
    "\n",
    "    def __init__(self, data_source: Sized, num_samples: Optional[int] = None,\n",
    "                 generator=None, chunk_size=200000, **kwargs) -> None:\n",
    "        self.data_source = data_source\n",
    "        self._num_samples = num_samples\n",
    "        self.generator = generator\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "        if not isinstance(self.num_samples, int) or self.num_samples <= 0:\n",
    "            raise ValueError(\"num_samples should be a positive integer \"\n",
    "                             \"value, but got num_samples={}\".format(self.num_samples))\n",
    "\n",
    "    @property\n",
    "    def num_samples(self) -> int:\n",
    "        # dataset size might change at runtime\n",
    "        if self._num_samples is None:\n",
    "            return len(self.data_source)\n",
    "        return self._num_samples\n",
    "\n",
    "    def __iter__(self) -> Iterator[int]:\n",
    "        n = len(self.data_source)\n",
    "        if self.generator is None:\n",
    "            seed = int(torch.empty((), dtype=torch.int64).random_().item())\n",
    "            generator = torch.Generator()\n",
    "            generator.manual_seed(seed)\n",
    "        else:\n",
    "            generator = self.generator\n",
    "\n",
    "        chunk_list = torch.randperm(self.num_samples // self.chunk_size, generator=generator).tolist()\n",
    "        for i in range(self.num_samples // self.chunk_size):\n",
    "            chunk = chunk_list[i]\n",
    "            yield from (chunk*self.chunk_size + torch.randperm(self.chunk_size, generator=generator)).tolist()\n",
    "        #yield from ((self.num_samples // self.chunk_size)*self.chunk_size + \n",
    "        #    torch.randperm(self.num_samples%self.chunk_size, generator=generator)).tolist()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.num_samples\n",
    "    \n",
    "class LenMatchBatchSampler(torch.utils.data.BatchSampler):\n",
    "    def __iter__(self):\n",
    "        buckets = [[]] * 100\n",
    "        yielded = 0\n",
    "\n",
    "        for idx in self.sampler:\n",
    "            s = self.sampler.data_source[idx]\n",
    "            if isinstance(s,tuple): L = s[0][\"mask\"].sum()\n",
    "            else: L = s[\"mask\"].sum()\n",
    "            #if torch.rand(1).item() < 0.1: L = int(1.5*L)\n",
    "            L = L // 16 \n",
    "            if len(buckets[L]) == 0:  buckets[L] = []\n",
    "            buckets[L].append(idx)\n",
    "            \n",
    "            if len(buckets[L]) == self.batch_size:\n",
    "                batch = list(buckets[L])\n",
    "                yield batch\n",
    "                yielded += 1\n",
    "                buckets[L] = []\n",
    "                \n",
    "        batch = []\n",
    "        leftover = [idx for bucket in buckets for idx in bucket]\n",
    "\n",
    "        for idx in leftover:\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yielded += 1\n",
    "                yield batch\n",
    "                batch = []\n",
    "\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yielded += 1\n",
    "            yield batch\n",
    "\n",
    "        #assert len(self) == yielded,\\\n",
    "        #  \"produced an inccorect number of batches. expected %i, but yielded %i\" %(len(self), yielded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4709406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import os,gc\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def prepare_sensors(path=PATH):\n",
    "    sensors = pd.read_csv(os.path.join(path,'sensor_geometry.csv')).astype(\n",
    "        {\n",
    "            \"sensor_id\": np.int16,\n",
    "            \"x\": np.float32,\n",
    "            \"y\": np.float32,\n",
    "            \"z\": np.float32,\n",
    "        }\n",
    "    )\n",
    "    sensors[\"string\"] = 0\n",
    "    sensors[\"qe\"] = 0#1\n",
    "\n",
    "    for i in range(len(sensors) // 60):\n",
    "        start, end = i * 60, (i * 60) + 60\n",
    "        sensors.loc[start:end, \"string\"] = i\n",
    "\n",
    "        # High Quantum Efficiency in the lower 50 DOMs - https://arxiv.org/pdf/2209.03042.pdf (Figure 1)\n",
    "        if i in range(78, 86):\n",
    "            start_veto, end_veto = i * 60, (i * 60) + 10\n",
    "            start_core, end_core = end_veto + 1, (i * 60) + 60\n",
    "            sensors.loc[start_core:end_core, \"qe\"] = 1# 1.35\n",
    "\n",
    "    # https://github.com/graphnet-team/graphnet/blob/b2bad25528652587ab0cdb7cf2335ee254cfa2db/src/graphnet/models/detector/icecube.py#L33-L41\n",
    "    # Assume that \"rde\" (relative dom efficiency) is equivalent to QE\n",
    "    sensors[\"x\"] /= 500\n",
    "    sensors[\"y\"] /= 500\n",
    "    sensors[\"z\"] /= 500\n",
    "    #sensors[\"qe\"] -= 1.25\n",
    "    #sensors[\"qe\"] /= 0.25\n",
    "\n",
    "    return sensors\n",
    "\n",
    "def ice_transparency(path=PATH, datum=1950):\n",
    "    # Data from page 31 of https://arxiv.org/pdf/1301.5361.pdf\n",
    "    # Datum is from footnote 8 of page 29\n",
    "    df = pd.read_csv(os.path.join(path,'ice_transparency.txt'), delim_whitespace=True)\n",
    "    df[\"z\"] = df[\"depth\"] - datum\n",
    "    df[\"z_norm\"] = df[\"z\"] / 500\n",
    "    df[[\"scattering_len_norm\", \"absorption_len_norm\"]] = RobustScaler().fit_transform(\n",
    "        df[[\"scattering_len\", \"absorption_len\"]])\n",
    "\n",
    "    # These are both roughly equivalent after scaling\n",
    "    f_scattering = interp1d(df[\"z_norm\"], df[\"scattering_len_norm\"])\n",
    "    f_absorption = interp1d(df[\"z_norm\"], df[\"absorption_len_norm\"])\n",
    "    return f_scattering, f_absorption\n",
    "\n",
    "class IceCubeDataset(Dataset):\n",
    "    def __init__(self, path=PATH, chunk_size=200000, L=256, buf_size=4, train=True, reduce_size=-1):\n",
    "        #path_geometry=PATH_GEOMETRY, /sensor_geometry.csv\n",
    "        self.path = os.path.join(path,'train')\n",
    "        self.files = [p for p in sorted(os.listdir(self.path)) if p!='batch_660.parquet'] #660 is shorter\n",
    "        val_fnames = ['batch_655.parquet','batch_656.parquet','batch_657.parquet','batch_658.parquet',\n",
    "                      'batch_659.parquet']\n",
    "        if not train: self.files = val_fnames\n",
    "        else: self.files = sorted(set(self.files) - set(val_fnames))\n",
    "        self.chunk_size = chunk_size\n",
    "        self.buf = OrderedDict()\n",
    "        self.L,self.buf_size = L,buf_size\n",
    "        sensors = prepare_sensors(path)\n",
    "        self.geometry = torch.from_numpy(sensors[['x','y','z']].values.astype(np.float32))\n",
    "        self.qe = sensors['qe'].values\n",
    "        self.ice_properties = ice_transparency(path)\n",
    "        \n",
    "        df = pd.read_parquet(os.path.join(path,'train_meta.parquet'))\n",
    "        df = df[['event_id','azimuth','zenith']]\n",
    "        df['azimuth'] = df['azimuth'].astype(np.float32)\n",
    "        df['zenith'] = df['zenith'].astype(np.float32)\n",
    "        df['event_id'] = df['event_id'].astype(np.int32)\n",
    "        df = df.set_index('event_id',drop=True)\n",
    "        self.target = df\n",
    "        gc.collect()\n",
    "        self.reduce_size = reduce_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)*self.chunk_size if self.reduce_size < 0 \\\n",
    "                else int(self.reduce_size*len(self.files))*self.chunk_size\n",
    "        \n",
    "    def __getitem__(self, idx0):\n",
    "        fname = self.files[idx0//self.chunk_size]\n",
    "        if fname not in self.buf:\n",
    "            df = pl.read_parquet(os.path.join(self.path,fname))\n",
    "            df = df.groupby(\"event_id\").agg([\n",
    "                pl.count(),\n",
    "                pl.col(\"sensor_id\").list(),\n",
    "                pl.col(\"time\").list(),\n",
    "                pl.col(\"charge\").list(),\n",
    "                pl.col(\"auxiliary\").list(),])\n",
    "            self.buf[fname] = df.sort('event_id')\n",
    "            if len(self.buf) > self.buf_size: del self.buf[list(self.buf.keys())[0]]\n",
    "        \n",
    "        idx = idx0%self.chunk_size\n",
    "        df = self.buf[fname]\n",
    "        sensor_id =  df[idx]['sensor_id'][0].item().to_numpy()\n",
    "        time =  df[idx]['time'][0].item().to_numpy()\n",
    "        charge = df[idx]['charge'][0].item().to_numpy()\n",
    "        auxiliary = df[idx]['auxiliary'][0].item().to_numpy()\n",
    "        event_idx = df[idx]['event_id'].item()\n",
    "            \n",
    "        #sensor_id = sensor_id[~auxiliary]\n",
    "        #time = time[~auxiliary]\n",
    "        #charge = charge[~auxiliary]\n",
    "        \n",
    "        time = (time - 1e4)/3e4\n",
    "        charge = np.log10(charge)/3.0 #np.log(charge)\n",
    "        \n",
    "        L = len(sensor_id)\n",
    "        if L < self.L:\n",
    "            sensor_id = np.pad(sensor_id,(0,max(0,self.L-L)))\n",
    "            time = np.pad(time,(0,max(0,self.L-L)))\n",
    "            charge = np.pad(charge,(0,max(0,self.L-L)))\n",
    "            auxiliary = np.pad(auxiliary,(0,max(0,self.L-L)))\n",
    "        else:\n",
    "            ids = torch.randperm(L).numpy()\n",
    "            auxiliary_n = np.where(~auxiliary)[0]\n",
    "            auxiliary_p = np.where(auxiliary)[0]\n",
    "            ids_n = ids[auxiliary_n][:min(self.L,len(auxiliary_n))]\n",
    "            ids_p = ids[auxiliary_p][:min(self.L-len(ids_n),len(auxiliary_p))]\n",
    "            ids = np.concatenate([ids_n,ids_p])\n",
    "            ids.sort()\n",
    "            L = len(ids)\n",
    "            \n",
    "            sensor_id = sensor_id[ids]\n",
    "            time = time[ids]\n",
    "            charge = charge[ids]\n",
    "            auxiliary = auxiliary[ids]\n",
    "            L = len(ids)\n",
    "            \n",
    "        attn_mask = torch.zeros(self.L, dtype=torch.bool)\n",
    "        attn_mask[:L] = True\n",
    "        sensor_id = torch.from_numpy(sensor_id).long()\n",
    "        pos = self.geometry[sensor_id]\n",
    "        pos[L:] = 0\n",
    "        qe = self.qe[sensor_id]\n",
    "        qe[L:] = 0\n",
    "        ice_properties = np.stack([self.ice_properties[0](pos[:L,2]),\n",
    "                                   self.ice_properties[1](pos[:L,2])],-1)\n",
    "        ice_properties = np.pad(ice_properties,((0,max(0,self.L-L)),(0,0)))\n",
    "        ice_properties = torch.from_numpy(ice_properties).float()\n",
    "        \n",
    "        target = self.target.loc[event_idx].values\n",
    "\n",
    "        return {'sensor_id': sensor_id, 'time': torch.from_numpy(time).float(),\n",
    "                'charge': torch.from_numpy(charge).float(), 'pos':pos, 'mask':attn_mask,\n",
    "                'idx':event_idx, 'auxiliary':torch.from_numpy(auxiliary).long(),\n",
    "                'qe':qe, 'ice_properties':ice_properties},\\\n",
    "               {'target': torch.from_numpy(target).float()}\n",
    "    \n",
    "    \n",
    "class IceCubeDataset_len(Dataset):\n",
    "    def __init__(self, path=PATH, chunk_size=200000, L=256, buf_size=2, train=True, reduce_size=-1):\n",
    "        #path_geometry=PATH_GEOMETRY, /sensor_geometry.csv\n",
    "        self.path = os.path.join(path,'train')\n",
    "        self.files = [p for p in sorted(os.listdir(self.path)) if p!='batch_660.parquet'] #660 is shorter\n",
    "        val_fnames = ['batch_655.parquet','batch_656.parquet','batch_657.parquet','batch_658.parquet',\n",
    "                      'batch_659.parquet']\n",
    "        if not train: self.files = val_fnames\n",
    "        else: self.files = sorted(set(self.files) - set(val_fnames))\n",
    "        self.chunk_size = chunk_size\n",
    "        self.buf = OrderedDict()\n",
    "        self.L,self.buf_size = L,buf_size\n",
    "        sensors = prepare_sensors(path)\n",
    "        self.geometry = torch.from_numpy(sensors[['x','y','z']].values.astype(np.float32))\n",
    "        self.qe = sensors['qe'].values\n",
    "        self.ice_properties = ice_transparency(path)\n",
    "        \n",
    "        gc.collect()\n",
    "        self.reduce_size = reduce_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)*self.chunk_size if self.reduce_size < 0 \\\n",
    "                else int(self.reduce_size*len(self.files))*self.chunk_size\n",
    "        \n",
    "    def __getitem__(self, idx0):\n",
    "        fname = self.files[idx0//self.chunk_size]\n",
    "        if fname not in self.buf:\n",
    "            df = pl.read_parquet(os.path.join(self.path,fname))\n",
    "            df = df.groupby(\"event_id\").agg([\n",
    "                pl.count(),\n",
    "                pl.col(\"sensor_id\").list(),\n",
    "                pl.col(\"time\").list(),\n",
    "                pl.col(\"charge\").list(),\n",
    "                pl.col(\"auxiliary\").list(),])\n",
    "            self.buf[fname] = df.sort('event_id')\n",
    "            if len(self.buf) > self.buf_size: del self.buf[list(self.buf.keys())[0]]\n",
    "        \n",
    "        idx = idx0%self.chunk_size\n",
    "        df = self.buf[fname]\n",
    "        sensor_id =  df[idx]['sensor_id'][0].item().to_numpy()\n",
    "        mask = torch.ones(min(len(sensor_id),self.L), dtype=torch.long)\n",
    "        return {'mask':mask},{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "396a8265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "from timm.models.layers import drop_path, to_2tuple, trunc_normal_\n",
    "\n",
    "from timm.models.layers import drop_path, to_2tuple, trunc_normal_\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training)\n",
    "    \n",
    "    def extra_repr(self) -> str:\n",
    "        return 'p={}'.format(self.drop_prob)\n",
    "    \n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        # x = self.drop(x)\n",
    "        # commit this for the orignal BERT implement \n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "#BEiTv2 block\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., init_values=None, act_layer=nn.GELU, norm_layer=nn.LayerNorm,\n",
    "                 window_size=None, attn_head_dim=None, **kwargs):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = nn.MultiheadAttention(dim, num_heads, dropout=drop, batch_first=True)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "        if init_values is not None:\n",
    "            self.gamma_1 = nn.Parameter(init_values * torch.ones((dim)),requires_grad=True)\n",
    "            self.gamma_2 = nn.Parameter(init_values * torch.ones((dim)),requires_grad=True)\n",
    "        else:\n",
    "            self.gamma_1, self.gamma_2 = None, None\n",
    "\n",
    "    def forward(self, x, attn_mask=None, key_padding_mask=None):\n",
    "        if self.gamma_1 is None:\n",
    "            xn = self.norm1(x)\n",
    "            x = x + self.drop_path(self.attn(xn,xn,xn,\n",
    "                            attn_mask=attn_mask,\n",
    "                            key_padding_mask=key_padding_mask,\n",
    "                            need_weights=False)[0])\n",
    "            x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        else:\n",
    "            xn = self.norm1(x)\n",
    "            x = x + self.drop_path(self.gamma_1 * self.drop_path(self.attn(xn,xn,xn,\n",
    "                            attn_mask=attn_mask,\n",
    "                            key_padding_mask=key_padding_mask,\n",
    "                            need_weights=False)[0]))\n",
    "            x = x + self.drop_path(self.gamma_2 * self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim=16, M=10000):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.M = M\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(self.M) / half_dim\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * (-emb))\n",
    "        emb = x[...,None] * emb[None,...]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "class Extractor(nn.Module):\n",
    "    def __init__(self, dim_base=128, dim=384):\n",
    "        super().__init__()\n",
    "        self.emb = SinusoidalPosEmb(dim=dim_base)\n",
    "        self.emb2 = SinusoidalPosEmb(dim=dim_base//2)\n",
    "        self.aux_emb = nn.Embedding(2,dim_base//2)\n",
    "        self.qe_emb = nn.Embedding(2,dim_base//2)\n",
    "        self.proj = nn.Linear(dim_base*7,dim)\n",
    "        \n",
    "    def forward(self, x, Lmax=None):\n",
    "        pos = x['pos'] if Lmax is None else x['pos'][:,:Lmax]\n",
    "        charge = x['charge'] if Lmax is None else x['charge'][:,:Lmax]\n",
    "        time = x['time'] if Lmax is None else x['time'][:,:Lmax]\n",
    "        auxiliary = x['auxiliary'] if Lmax is None else x['auxiliary'][:,:Lmax]\n",
    "        qe = x['qe'] if Lmax is None else x['qe'][:,:Lmax]\n",
    "        ice_properties = x['ice_properties'] if Lmax is None else x['ice_properties'][:,:Lmax]\n",
    "        \n",
    "        x = torch.cat([self.emb(100*pos).flatten(-2), self.emb(40*charge),\n",
    "                       self.emb(100*time),self.aux_emb(auxiliary),self.qe_emb(qe),\n",
    "                       self.emb2(50*ice_properties).flatten(-2)],-1)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "class DeepIceModel(nn.Module):\n",
    "    def __init__(self, dim=384, dim_base=128, depth=12, use_checkpoint=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.extractor = Extractor(dim_base,dim)\n",
    "        self.cls_token = nn.Linear(dim,1,bias=False)\n",
    "        self.blocks = nn.ModuleList([ \n",
    "            Block(\n",
    "                dim=dim, num_heads=dim//64, mlp_ratio=4, drop_path=0, init_values=1,)\n",
    "            for i in range(depth)])\n",
    "        #self.blocks = nn.ModuleList([ \n",
    "        #    nn.TransformerEncoderLayer(dim,dim//64,dim*4,dropout=0,\n",
    "        #        activation=nn.GELU(), batch_first=True, norm_first=True)\n",
    "        #    for i in range(depth)])\n",
    "\n",
    "        self.proj_out = nn.Linear(dim,3)\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "        self.apply(self._init_weights)\n",
    "        trunc_normal_(self.cls_token.weight, std=.02)\n",
    "\n",
    "    def fix_init_weight(self):\n",
    "        def rescale(param, layer_id):\n",
    "            param.div_(math.sqrt(2.0 * layer_id))\n",
    "\n",
    "        for layer_id, layer in enumerate(self.blocks):\n",
    "            rescale(layer.attn.proj.weight.data, layer_id + 1)\n",
    "            rescale(layer.mlp.fc2.weight.data, layer_id + 1)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    def init_weights(self, pretrained=None):\n",
    "        def _init_weights(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                trunc_normal_(m.weight, std=.02)\n",
    "                if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.LayerNorm):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "        self.apply(_init_weights)\n",
    "    \n",
    "    def forward(self, x0):\n",
    "        mask = x0['mask']\n",
    "        B,_ = mask.shape\n",
    "        mask = torch.cat([torch.ones(B,1,dtype=mask.dtype, device=mask.device),mask],1)\n",
    "        attn_mask = torch.zeros(mask.shape, device=mask.device)\n",
    "        attn_mask[~mask] = -torch.inf\n",
    "        Lmax = mask.sum(-1).max()\n",
    "        \n",
    "        x = self.extractor(x0, Lmax-1)\n",
    "        cls_token = self.cls_token.weight.unsqueeze(0).expand(B,-1,-1)\n",
    "        x = torch.cat([cls_token,x],1)\n",
    "        x,mask,attn_mask = x[:,:Lmax], mask[:,:Lmax], attn_mask[:,:Lmax]\n",
    "        \n",
    "        #Lmax = mask.max(0)[0].sum()\n",
    "        Lmax = mask.sum(-1).max()\n",
    "        x,mask,attn_mask = x[:,:Lmax], mask[:,:Lmax], attn_mask[:,:Lmax]\n",
    "        #print(Lmax)\n",
    "        \n",
    "        for blk in self.blocks:\n",
    "            if self.use_checkpoint:\n",
    "                x = checkpoint.checkpoint(blk, x, None, attn_mask)\n",
    "            else: x = blk(x, None, attn_mask)\n",
    "                \n",
    "        x = self.proj_out(x[:,0]) #cls token\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03a08fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from loss_functions import VonMisesFisher3DLoss\n",
    "\n",
    "def loss(pred,y):\n",
    "    #print(pred.max())\n",
    "    pred = F.normalize(pred.float(),dim=-1)\n",
    "    \n",
    "    sa2 = torch.sin(y['target'][:,0])\n",
    "    ca2 = torch.cos(y['target'][:,0])\n",
    "    sz2 = torch.sin(y['target'][:,1])\n",
    "    cz2 = torch.cos(y['target'][:,1])\n",
    "    \n",
    "    scalar_prod = (pred[:,0]*sa2*sz2 + pred[:,1]*ca2*sz2 + pred[:,2]*cz2).clip(-1+1e-8,1-1e-8)\n",
    "    return torch.acos(scalar_prod).abs().mean(-1)   \n",
    "\n",
    "def loss_vms(pred,y):\n",
    "    sa2 = torch.sin(y['target'][:,0])\n",
    "    ca2 = torch.cos(y['target'][:,0])\n",
    "    sz2 = torch.sin(y['target'][:,1])\n",
    "    cz2 = torch.cos(y['target'][:,1])\n",
    "    t = torch.stack([sa2*sz2,ca2*sz2,cz2],-1)\n",
    "    \n",
    "    p = pred.float()\n",
    "    l = torch.norm(pred.float(),dim=-1).unsqueeze(-1)\n",
    "    p = torch.cat([pred.float()/l,l],-1)\n",
    "    \n",
    "    loss = VonMisesFisher3DLoss()(p,t)\n",
    "    return loss\n",
    "\n",
    "def get_val(pred):\n",
    "    pred = F.normalize(pred,dim=-1)\n",
    "    zen = torch.acos(pred[:,2].clip(-1,1))\n",
    "    f = F.normalize(pred[:,:2],dim=-1)\n",
    "    az = torch.asin(f[:,0].clip(-1,1))\n",
    "    az = torch.where(f[:,1] > 0, az, math.pi - az)\n",
    "    az = torch.where(az > 0, az, az + 2.0*math.pi)\n",
    "    return torch.stack([az,zen],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3a400ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to(x, device='cuda'):\n",
    "    return {k:x[k].to(device) for k in x}\n",
    "\n",
    "def to_device(x, device='cuda'):\n",
    "    return tuple(dict_to(e,device) for e in x)\n",
    "\n",
    "class DeviceDataLoader:\n",
    "    def __init__(self, dataloader, device='cuda'):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dataloader:\n",
    "            yield tuple(dict_to(x, self.device) for x in batch)\n",
    "            \n",
    "def WrapperAdamW(param_groups,**kwargs):\n",
    "    return OptimWrapper(param_groups,torch.optim.AdamW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f40b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "037a8dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'init5small'\n",
    "\n",
    "ds_train = IceCubeDataset(train=True, reduce_size=0.125, L=L)\n",
    "ds_train_len = IceCubeDataset_len(train=True, reduce_size=0.125, L=L)\n",
    "len_sampler_train = LenMatchBatchSampler(RandomChunkSampler(ds_train_len),batch_size=bs, drop_last=True)\n",
    "dl_train = DeviceDataLoader(DataLoader(ds_train, batch_sampler=len_sampler_train, num_workers=4, \n",
    "                        persistent_workers=True))\n",
    "#dl_train = DeviceDataLoader(DataLoader(ds_train, batch_size=bs, sampler=RandomChunkSampler(ds_train),\n",
    "#                            num_workers=8, persistent_workers=True, drop_last=True))\n",
    "#there is a bug in process pool creation, so persistent_workers and num_workers=0 are important\n",
    "ds_val = IceCubeDataset(train=False, L=L)\n",
    "ds_val_len = IceCubeDataset_len(train=False, L=L)\n",
    "len_sampler_val = LenMatchBatchSampler(RandomChunkSampler(ds_val_len),batch_size=bs, drop_last=False)\n",
    "dl_val = DeviceDataLoader(DataLoader(ds_val, batch_sampler=len_sampler_val, num_workers=0))\n",
    "#dl_val= DeviceDataLoader(DataLoader(ds_val, batch_size=bs, sampler=RandomChunkSampler(ds_val),\n",
    "#                            num_workers=0, drop_last=False))\n",
    "\n",
    "data = DataLoaders(dl_train,dl_val)\n",
    "\n",
    "model = DeepIceModel(dim=192, dim_base=96)   \n",
    "#model.load_state_dict(torch.load(os.path.join(OUT,f'{fname}_0.pth')))\n",
    "model = model.cuda()\n",
    "model = nn.DataParallel(model)\n",
    "learn = Learner(data, model, loss_func=loss_vms,cbs=[GradientClip(3.0),\n",
    "            SaveModelCallback(monitor='loss',comp=np.less,at_end=True),\n",
    "            GradientAccumulation(n_acc=4)],\n",
    "            metrics=[loss], opt_func=partial(WrapperAdamW,eps=1e-7)).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013d681a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='7' class='' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      87.50% [7/8 10:46:10&lt;1:32:18]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.551479</td>\n",
       "      <td>1.551634</td>\n",
       "      <td>1.050313</td>\n",
       "      <td>1:35:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.492294</td>\n",
       "      <td>1.507602</td>\n",
       "      <td>1.030347</td>\n",
       "      <td>1:31:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.451025</td>\n",
       "      <td>1.462651</td>\n",
       "      <td>1.011444</td>\n",
       "      <td>1:31:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.437055</td>\n",
       "      <td>1.450091</td>\n",
       "      <td>1.013685</td>\n",
       "      <td>1:31:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.409240</td>\n",
       "      <td>1.437440</td>\n",
       "      <td>1.000499</td>\n",
       "      <td>1:31:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.413827</td>\n",
       "      <td>1.400107</td>\n",
       "      <td>0.995099</td>\n",
       "      <td>1:31:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.385879</td>\n",
       "      <td>1.386819</td>\n",
       "      <td>0.988151</td>\n",
       "      <td>1:32:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='5341' class='' max='31640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      16.88% [5341/31640 13:51&lt;1:08:12 1.3739]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with loss value: 1.0503125190734863.\n",
      "Better model found at epoch 1 with loss value: 1.0303469896316528.\n",
      "Better model found at epoch 2 with loss value: 1.0114437341690063.\n",
      "Better model found at epoch 4 with loss value: 1.0004990100860596.\n",
      "Better model found at epoch 5 with loss value: 0.9950990676879883.\n",
      "Better model found at epoch 6 with loss value: 0.988151490688324.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(8, lr_max=5e-4, wd=0.05, pct_start=0.01)\n",
    "#torch.save(learn.model.state_dict(),os.path.join(OUT,f'{fname}_0.pth'))\n",
    "torch.save(learn.model.module.state_dict(),os.path.join(OUT,f'{fname}_0.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acee85d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c12eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b15cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9f78eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
