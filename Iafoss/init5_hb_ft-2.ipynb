{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f418a53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('/opt/slh/icecube/')\n",
    "\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "#os.environ[\"NCCL_P2P_DISABLE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6efa89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-05 23:24:23 - get_logger - Writing log to \u001b[1mlogs/graphnet_20230305-232423.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "from icecube.models import EncoderWithDirectionReconstructionV8\n",
    "from fastai_fix import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b613edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT = 'init_ft_2'\n",
    "PATH = '../data/'\n",
    "\n",
    "NUM_WORKERS = 16\n",
    "SEED = 2023\n",
    "bs = 512\n",
    "L = 196\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)\n",
    "os.makedirs(OUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ce4798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random\n",
    "from typing import Iterator, Iterable, Optional, Sequence, List, TypeVar, Generic, Sized, Union\n",
    "\n",
    "class RandomChunkSampler(torch.utils.data.Sampler[int]):\n",
    "    r\"\"\"Samples elements randomly. If without replacement, then sample from a shuffled dataset.\n",
    "    If with replacement, then user can specify :attr:`num_samples` to draw.\n",
    "    Args:\n",
    "        data_source (Dataset): dataset to sample from\n",
    "        replacement (bool): samples are drawn on-demand with replacement if ``True``, default=``False``\n",
    "        num_samples (int): number of samples to draw, default=`len(dataset)`.\n",
    "        generator (Generator): Generator used in sampling.\n",
    "    \"\"\"\n",
    "    data_source: Sized\n",
    "    replacement: bool\n",
    "\n",
    "    def __init__(self, data_source: Sized, num_samples: Optional[int] = None,\n",
    "                 generator=None, chunk_size=200000, **kwargs) -> None:\n",
    "        self.data_source = data_source\n",
    "        self._num_samples = num_samples\n",
    "        self.generator = generator\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "        if not isinstance(self.num_samples, int) or self.num_samples <= 0:\n",
    "            raise ValueError(\"num_samples should be a positive integer \"\n",
    "                             \"value, but got num_samples={}\".format(self.num_samples))\n",
    "\n",
    "    @property\n",
    "    def num_samples(self) -> int:\n",
    "        # dataset size might change at runtime\n",
    "        if self._num_samples is None:\n",
    "            return len(self.data_source)\n",
    "        return self._num_samples\n",
    "\n",
    "    def __iter__(self) -> Iterator[int]:\n",
    "        n = len(self.data_source)\n",
    "        if self.generator is None:\n",
    "            seed = int(torch.empty((), dtype=torch.int64).random_().item())\n",
    "            generator = torch.Generator()\n",
    "            generator.manual_seed(seed)\n",
    "        else:\n",
    "            generator = self.generator\n",
    "\n",
    "        chunk_list = torch.randperm(self.num_samples // self.chunk_size, generator=generator).tolist()\n",
    "        for i in range(self.num_samples // self.chunk_size):\n",
    "            chunk = chunk_list[i]\n",
    "            yield from (chunk*self.chunk_size + torch.randperm(self.chunk_size, generator=generator)).tolist()\n",
    "        #yield from ((self.num_samples // self.chunk_size)*self.chunk_size + \n",
    "        #    torch.randperm(self.num_samples%self.chunk_size, generator=generator)).tolist()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.num_samples\n",
    "    \n",
    "class LenMatchBatchSampler(torch.utils.data.BatchSampler):\n",
    "    def __iter__(self):\n",
    "        buckets = [[]] * 100\n",
    "        yielded = 0\n",
    "\n",
    "        for idx in self.sampler:\n",
    "            s = self.sampler.data_source[idx]\n",
    "            if isinstance(s,tuple): L = s[0][\"mask\"].sum()\n",
    "            else: L = s[\"mask\"].sum()\n",
    "            #if torch.rand(1).item() < 0.1: L = int(1.5*L)\n",
    "            L = L // 16 \n",
    "            if len(buckets[L]) == 0:  buckets[L] = []\n",
    "            buckets[L].append(idx)\n",
    "            \n",
    "            if len(buckets[L]) == self.batch_size:\n",
    "                batch = list(buckets[L])\n",
    "                yield batch\n",
    "                yielded += 1\n",
    "                buckets[L] = []\n",
    "                \n",
    "        batch = []\n",
    "        leftover = [idx for bucket in buckets for idx in bucket]\n",
    "\n",
    "        for idx in leftover:\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yielded += 1\n",
    "                yield batch\n",
    "                batch = []\n",
    "\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yielded += 1\n",
    "            yield batch\n",
    "\n",
    "        #assert len(self) == yielded,\\\n",
    "        #  \"produced an inccorect number of batches. expected %i, but yielded %i\" %(len(self), yielded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4709406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import os,gc\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def prepare_sensors(path=PATH):\n",
    "    sensors = pd.read_csv(os.path.join(path,'sensor_geometry.csv')).astype(\n",
    "        {\n",
    "            \"sensor_id\": np.int16,\n",
    "            \"x\": np.float32,\n",
    "            \"y\": np.float32,\n",
    "            \"z\": np.float32,\n",
    "        }\n",
    "    )\n",
    "    sensors[\"string\"] = 0\n",
    "    sensors[\"qe\"] = 0#1\n",
    "\n",
    "    for i in range(len(sensors) // 60):\n",
    "        start, end = i * 60, (i * 60) + 60\n",
    "        sensors.loc[start:end, \"string\"] = i\n",
    "\n",
    "        # High Quantum Efficiency in the lower 50 DOMs - https://arxiv.org/pdf/2209.03042.pdf (Figure 1)\n",
    "        if i in range(78, 86):\n",
    "            start_veto, end_veto = i * 60, (i * 60) + 10\n",
    "            start_core, end_core = end_veto + 1, (i * 60) + 60\n",
    "            sensors.loc[start_core:end_core, \"qe\"] = 1# 1.35\n",
    "\n",
    "    # https://github.com/graphnet-team/graphnet/blob/b2bad25528652587ab0cdb7cf2335ee254cfa2db/src/graphnet/models/detector/icecube.py#L33-L41\n",
    "    # Assume that \"rde\" (relative dom efficiency) is equivalent to QE\n",
    "    sensors[\"x\"] /= 500\n",
    "    sensors[\"y\"] /= 500\n",
    "    sensors[\"z\"] /= 500\n",
    "    #sensors[\"qe\"] -= 1.25\n",
    "    #sensors[\"qe\"] /= 0.25\n",
    "\n",
    "    return sensors\n",
    "\n",
    "def ice_transparency(path=PATH, datum=1950):\n",
    "    # Data from page 31 of https://arxiv.org/pdf/1301.5361.pdf\n",
    "    # Datum is from footnote 8 of page 29\n",
    "    df = pd.read_csv(os.path.join(path,'ice_transparency.txt'), delim_whitespace=True)\n",
    "    df[\"z\"] = df[\"depth\"] - datum\n",
    "    df[\"z_norm\"] = df[\"z\"] / 500\n",
    "    df[[\"scattering_len_norm\", \"absorption_len_norm\"]] = RobustScaler().fit_transform(\n",
    "        df[[\"scattering_len\", \"absorption_len\"]])\n",
    "\n",
    "    # These are both roughly equivalent after scaling\n",
    "    f_scattering = interp1d(df[\"z_norm\"], df[\"scattering_len_norm\"])\n",
    "    f_absorption = interp1d(df[\"z_norm\"], df[\"absorption_len_norm\"])\n",
    "    return f_scattering, f_absorption\n",
    "\n",
    "class IceCubeDataset(Dataset):\n",
    "    def __init__(self, path=PATH, chunk_size=200000, L=256, buf_size=4, train=True, reduce_size=-1):\n",
    "        #path_geometry=PATH_GEOMETRY, /sensor_geometry.csv\n",
    "        self.path = os.path.join(path,'train')\n",
    "        self.files = [p for p in sorted(os.listdir(self.path)) if p!='batch_660.parquet'] #660 is shorter\n",
    "        val_fnames = ['batch_655.parquet','batch_656.parquet','batch_657.parquet','batch_658.parquet',\n",
    "                      'batch_659.parquet']\n",
    "        if not train: self.files = val_fnames\n",
    "        else: self.files = sorted(set(self.files) - set(val_fnames))\n",
    "        self.chunk_size = chunk_size\n",
    "        self.buf = OrderedDict()\n",
    "        self.L,self.buf_size = L,buf_size\n",
    "        sensors = prepare_sensors(path)\n",
    "        self.geometry = torch.from_numpy(sensors[['x','y','z']].values.astype(np.float32))\n",
    "        self.qe = sensors['qe'].values\n",
    "        self.ice_properties = ice_transparency(path)\n",
    "        \n",
    "        df = pd.read_parquet(os.path.join(path,'train_meta.parquet'))\n",
    "        df = df[['event_id','azimuth','zenith']]\n",
    "        df['azimuth'] = df['azimuth'].astype(np.float32)\n",
    "        df['zenith'] = df['zenith'].astype(np.float32)\n",
    "        df['event_id'] = df['event_id'].astype(np.int32)\n",
    "        df = df.set_index('event_id',drop=True)\n",
    "        self.target = df\n",
    "        gc.collect()\n",
    "        self.reduce_size = reduce_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)*self.chunk_size if self.reduce_size < 0 \\\n",
    "                else int(self.reduce_size*len(self.files))*self.chunk_size\n",
    "        \n",
    "    def __getitem__(self, idx0):\n",
    "        fname = self.files[idx0//self.chunk_size]\n",
    "        if fname not in self.buf:\n",
    "            df = pl.read_parquet(os.path.join(self.path,fname))\n",
    "            df = df.groupby(\"event_id\").agg([\n",
    "                pl.count(),\n",
    "                pl.col(\"sensor_id\").list(),\n",
    "                pl.col(\"time\").list(),\n",
    "                pl.col(\"charge\").list(),\n",
    "                pl.col(\"auxiliary\").list(),])\n",
    "            self.buf[fname] = df.sort('event_id')\n",
    "            if len(self.buf) > self.buf_size: del self.buf[list(self.buf.keys())[0]]\n",
    "        \n",
    "        idx = idx0%self.chunk_size\n",
    "        df = self.buf[fname]\n",
    "        sensor_id =  df[idx]['sensor_id'][0].item().to_numpy()\n",
    "        time =  df[idx]['time'][0].item().to_numpy()\n",
    "        charge = df[idx]['charge'][0].item().to_numpy()\n",
    "        auxiliary = df[idx]['auxiliary'][0].item().to_numpy()\n",
    "        event_idx = df[idx]['event_id'].item()\n",
    "            \n",
    "        #sensor_id = sensor_id[~auxiliary]\n",
    "        #time = time[~auxiliary]\n",
    "        #charge = charge[~auxiliary]\n",
    "        \n",
    "        time = (time - 1e4)/3e4\n",
    "        charge = np.log10(charge)/3.0 #np.log(charge)\n",
    "        \n",
    "        L = len(sensor_id)\n",
    "        if L < self.L:\n",
    "            sensor_id = np.pad(sensor_id,(0,max(0,self.L-L)))\n",
    "            time = np.pad(time,(0,max(0,self.L-L)))\n",
    "            charge = np.pad(charge,(0,max(0,self.L-L)))\n",
    "            auxiliary = np.pad(auxiliary,(0,max(0,self.L-L)))\n",
    "        else:\n",
    "            ids = torch.randperm(L).numpy()\n",
    "            auxiliary_n = np.where(~auxiliary)[0]\n",
    "            auxiliary_p = np.where(auxiliary)[0]\n",
    "            ids_n = ids[auxiliary_n][:min(self.L,len(auxiliary_n))]\n",
    "            ids_p = ids[auxiliary_p][:min(self.L-len(ids_n),len(auxiliary_p))]\n",
    "            ids = np.concatenate([ids_n,ids_p])\n",
    "            ids.sort()\n",
    "            L = len(ids)\n",
    "            \n",
    "            sensor_id = sensor_id[ids]\n",
    "            time = time[ids]\n",
    "            charge = charge[ids]\n",
    "            auxiliary = auxiliary[ids]\n",
    "            L = len(ids)\n",
    "            \n",
    "        attn_mask = torch.zeros(self.L, dtype=torch.bool)\n",
    "        attn_mask[:L] = True\n",
    "        sensor_id = torch.from_numpy(sensor_id).long()\n",
    "        pos = self.geometry[sensor_id]\n",
    "        pos[L:] = 0\n",
    "        qe = self.qe[sensor_id]\n",
    "        qe[L:] = 0\n",
    "        ice_properties = np.stack([self.ice_properties[0](pos[:L,2]),\n",
    "                                   self.ice_properties[1](pos[:L,2])],-1)\n",
    "        ice_properties = np.pad(ice_properties,((0,max(0,self.L-L)),(0,0)))\n",
    "        ice_properties = torch.from_numpy(ice_properties).float()\n",
    "        \n",
    "        target = self.target.loc[event_idx].values\n",
    "\n",
    "        return {'sensor_id': sensor_id, 'time': torch.from_numpy(time).float(),\n",
    "                'charge': torch.from_numpy(charge).float(), 'pos':pos, 'mask':attn_mask,\n",
    "                'idx':event_idx, 'auxiliary':torch.from_numpy(auxiliary).long(),\n",
    "                'qe':qe, 'ice_properties':ice_properties},\\\n",
    "               {'target': torch.from_numpy(target).float()}\n",
    "    \n",
    "    \n",
    "class IceCubeDataset_len(Dataset):\n",
    "    def __init__(self, path=PATH, chunk_size=200000, L=256, buf_size=2, train=True, reduce_size=-1):\n",
    "        #path_geometry=PATH_GEOMETRY, /sensor_geometry.csv\n",
    "        self.path = os.path.join(path,'train')\n",
    "        self.files = [p for p in sorted(os.listdir(self.path)) if p!='batch_660.parquet'] #660 is shorter\n",
    "        val_fnames = ['batch_655.parquet','batch_656.parquet','batch_657.parquet','batch_658.parquet',\n",
    "                      'batch_659.parquet']\n",
    "        if not train: self.files = val_fnames\n",
    "        else: self.files = sorted(set(self.files) - set(val_fnames))\n",
    "        self.chunk_size = chunk_size\n",
    "        self.buf = OrderedDict()\n",
    "        self.L,self.buf_size = L,buf_size\n",
    "        sensors = prepare_sensors(path)\n",
    "        self.geometry = torch.from_numpy(sensors[['x','y','z']].values.astype(np.float32))\n",
    "        self.qe = sensors['qe'].values\n",
    "        self.ice_properties = ice_transparency(path)\n",
    "        \n",
    "        gc.collect()\n",
    "        self.reduce_size = reduce_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)*self.chunk_size if self.reduce_size < 0 \\\n",
    "                else int(self.reduce_size*len(self.files))*self.chunk_size\n",
    "        \n",
    "    def __getitem__(self, idx0):\n",
    "        fname = self.files[idx0//self.chunk_size]\n",
    "        if fname not in self.buf:\n",
    "            df = pl.read_parquet(os.path.join(self.path,fname))\n",
    "            df = df.groupby(\"event_id\").agg([\n",
    "                pl.count(),\n",
    "                pl.col(\"sensor_id\").list(),\n",
    "                pl.col(\"time\").list(),\n",
    "                pl.col(\"charge\").list(),\n",
    "                pl.col(\"auxiliary\").list(),])\n",
    "            self.buf[fname] = df.sort('event_id')\n",
    "            if len(self.buf) > self.buf_size: del self.buf[list(self.buf.keys())[0]]\n",
    "        \n",
    "        idx = idx0%self.chunk_size\n",
    "        df = self.buf[fname]\n",
    "        sensor_id =  df[idx]['sensor_id'][0].item().to_numpy()\n",
    "        mask = torch.ones(min(len(sensor_id),self.L), dtype=torch.long)\n",
    "        return {'mask':mask},{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03a08fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from loss_functions import VonMisesFisher3DLoss\n",
    "\n",
    "def loss(pred,y):\n",
    "    #print(pred.max())\n",
    "    pred = F.normalize(pred.float(),dim=-1)\n",
    "    \n",
    "    sa2 = torch.sin(y['target'][:,0])\n",
    "    ca2 = torch.cos(y['target'][:,0])\n",
    "    sz2 = torch.sin(y['target'][:,1])\n",
    "    cz2 = torch.cos(y['target'][:,1])\n",
    "    \n",
    "    scalar_prod = (pred[:,0]*sa2*sz2 + pred[:,1]*ca2*sz2 + pred[:,2]*cz2).clip(-1+1e-8,1-1e-8)\n",
    "    return torch.acos(scalar_prod).abs().mean(-1)   \n",
    "\n",
    "def loss_vms(pred,y):\n",
    "    sa2 = torch.sin(y['target'][:,0])\n",
    "    ca2 = torch.cos(y['target'][:,0])\n",
    "    sz2 = torch.sin(y['target'][:,1])\n",
    "    cz2 = torch.cos(y['target'][:,1])\n",
    "    t = torch.stack([sa2*sz2,ca2*sz2,cz2],-1)\n",
    "    \n",
    "    p = pred.float()\n",
    "    l = torch.norm(pred.float(),dim=-1).unsqueeze(-1)\n",
    "    p = torch.cat([pred.float()/l,l],-1)\n",
    "    \n",
    "    loss = VonMisesFisher3DLoss()(p,t)\n",
    "    return loss\n",
    "\n",
    "def get_val(pred):\n",
    "    pred = F.normalize(pred,dim=-1)\n",
    "    zen = torch.acos(pred[:,2].clip(-1,1))\n",
    "    f = F.normalize(pred[:,:2],dim=-1)\n",
    "    az = torch.asin(f[:,0].clip(-1,1))\n",
    "    az = torch.where(f[:,1] > 0, az, math.pi - az)\n",
    "    az = torch.where(az > 0, az, az + 2.0*math.pi)\n",
    "    return torch.stack([az,zen],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3a400ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to(x, device='cuda'):\n",
    "    return {k:x[k].to(device) for k in x}\n",
    "\n",
    "def to_device(x, device='cuda'):\n",
    "    return tuple(dict_to(e,device) for e in x)\n",
    "\n",
    "class DeviceDataLoader:\n",
    "    def __init__(self, dataloader, device='cuda'):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dataloader:\n",
    "            yield tuple(dict_to(x, self.device) for x in batch)\n",
    "            \n",
    "def WrapperAdamW(param_groups,**kwargs):\n",
    "    return OptimWrapper(param_groups,torch.optim.AdamW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f40b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "037a8dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'md_F3'\n",
    "\n",
    "ds_train = IceCubeDataset(train=True, reduce_size=0.125, L=L)\n",
    "ds_train_len = IceCubeDataset_len(train=True, reduce_size=0.125, L=L)\n",
    "len_sampler_train = LenMatchBatchSampler(RandomChunkSampler(ds_train_len),batch_size=bs, drop_last=True)\n",
    "dl_train = DeviceDataLoader(DataLoader(ds_train, batch_sampler=len_sampler_train, num_workers=NUM_WORKERS, \n",
    "                        persistent_workers=True))\n",
    "#dl_train = DeviceDataLoader(DataLoader(ds_train, batch_size=bs, sampler=RandomChunkSampler(ds_train),\n",
    "#                            num_workers=8, persistent_workers=True, drop_last=True))\n",
    "#there is a bug in process pool creation, so persistent_workers and num_workers=0 are important\n",
    "ds_val = IceCubeDataset(train=False, L=L)\n",
    "ds_val_len = IceCubeDataset_len(train=False, L=L)\n",
    "len_sampler_val = LenMatchBatchSampler(RandomChunkSampler(ds_val_len),batch_size=bs, drop_last=False)\n",
    "dl_val = DeviceDataLoader(DataLoader(ds_val, batch_sampler=len_sampler_val, num_workers=0))\n",
    "#dl_val= DeviceDataLoader(DataLoader(ds_val, batch_size=bs, sampler=RandomChunkSampler(ds_val),\n",
    "#                            num_workers=0, drop_last=False))\n",
    "\n",
    "data = DataLoaders(dl_train,dl_val)\n",
    "model = EncoderWithDirectionReconstructionV8()\n",
    "model = model.cuda()\n",
    "learn = Learner(data, model, path = OUT,  loss_func=loss_vms,cbs=[GradientClip(3.0),\n",
    "            SaveModelCallback(monitor='loss',comp=np.less, every_epoch=True),\n",
    "            GradientAccumulation(n_acc=4)],\n",
    "            metrics=[loss], opt_func=partial(WrapperAdamW,eps=1e-7)).to_fp16()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bb9e66-c4d5-4650-b73a-109acc455e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa397f7-e465-478a-9ca9-2eabf100701e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac120a18-8e67-490a-bc99-6b1b5d4333de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23ff8720-072f-45d0-933f-f4ce9fdc36b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model.load_state_dict(torch.load('/opt/slh/icecube/Iafoss/models/model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ace60-f05d-46df-84f8-b9a41aca6268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='5' class='' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      62.50% [5/8 15:31:35&lt;9:18:57]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.392886</td>\n",
       "      <td>1.395450</td>\n",
       "      <td>0.990738</td>\n",
       "      <td>3:06:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.384596</td>\n",
       "      <td>1.393732</td>\n",
       "      <td>0.990824</td>\n",
       "      <td>3:06:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.363555</td>\n",
       "      <td>1.389181</td>\n",
       "      <td>0.990704</td>\n",
       "      <td>3:06:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.341745</td>\n",
       "      <td>1.394532</td>\n",
       "      <td>0.989744</td>\n",
       "      <td>3:06:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.343110</td>\n",
       "      <td>1.385756</td>\n",
       "      <td>0.986086</td>\n",
       "      <td>3:06:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='19714' class='' max='31640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      62.31% [19714/31640 1:41:20&lt;1:01:18 1.3808]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:63: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#learn.load('opt/slh/icecube/Iafoss/models/model.pth')\n",
    "learn.fit_one_cycle(8, lr_max=(5e-4)/10, wd=0.05, pct_start=0.01)\n",
    "torch.save(learn.model.state_dict(),os.path.join(OUT,f'{fname}_0.pth'))\n",
    "#torch.save(learn.model.module.state_dict(),os.path.join(OUT,f'{fname}_0.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "479a1cdb-9613-4dc9-8fd8-5e0bcaf635a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:63: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(#2) [1.393336296081543,0.9855865836143494]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5cdad22-a909-436b-a791-bdf6fd040454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:63: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(#2) [1.3875356912612915,0.9860274195671082]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('model_5');\n",
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e18999e3-9478-4b5b-b591-1dbbddaf04fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:63: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(#2) [1.3875775337219238,0.9854189157485962]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('model_6');\n",
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5d77ab3-6c28-4611-a070-91ab2fe15058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:63: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(#2) [1.3934669494628906,0.9855033159255981]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('model_7');\n",
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb15df7-f6a9-47e6-81f2-57c8446bb2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
