{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f418a53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('/opt/slh/icecube/')\n",
    "\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "#os.environ[\"NCCL_P2P_DISABLE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6efa89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-03 16:05:47 - get_logger - Writing log to \u001b[1mlogs/graphnet_20230303-160547.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "from icecube.models import EncoderWithDirectionReconstructionV8\n",
    "from fastai_fix import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b613edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT = 'init'\n",
    "PATH = '../data/'\n",
    "\n",
    "NUM_WORKERS = 20\n",
    "SEED = 2023\n",
    "bs = 512\n",
    "L = 192\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)\n",
    "os.makedirs(OUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ce4798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random\n",
    "from typing import Iterator, Iterable, Optional, Sequence, List, TypeVar, Generic, Sized, Union\n",
    "\n",
    "class RandomChunkSampler(torch.utils.data.Sampler[int]):\n",
    "    r\"\"\"Samples elements randomly. If without replacement, then sample from a shuffled dataset.\n",
    "    If with replacement, then user can specify :attr:`num_samples` to draw.\n",
    "    Args:\n",
    "        data_source (Dataset): dataset to sample from\n",
    "        replacement (bool): samples are drawn on-demand with replacement if ``True``, default=``False``\n",
    "        num_samples (int): number of samples to draw, default=`len(dataset)`.\n",
    "        generator (Generator): Generator used in sampling.\n",
    "    \"\"\"\n",
    "    data_source: Sized\n",
    "    replacement: bool\n",
    "\n",
    "    def __init__(self, data_source: Sized, num_samples: Optional[int] = None,\n",
    "                 generator=None, chunk_size=200000, **kwargs) -> None:\n",
    "        self.data_source = data_source\n",
    "        self._num_samples = num_samples\n",
    "        self.generator = generator\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "        if not isinstance(self.num_samples, int) or self.num_samples <= 0:\n",
    "            raise ValueError(\"num_samples should be a positive integer \"\n",
    "                             \"value, but got num_samples={}\".format(self.num_samples))\n",
    "\n",
    "    @property\n",
    "    def num_samples(self) -> int:\n",
    "        # dataset size might change at runtime\n",
    "        if self._num_samples is None:\n",
    "            return len(self.data_source)\n",
    "        return self._num_samples\n",
    "\n",
    "    def __iter__(self) -> Iterator[int]:\n",
    "        n = len(self.data_source)\n",
    "        if self.generator is None:\n",
    "            seed = int(torch.empty((), dtype=torch.int64).random_().item())\n",
    "            generator = torch.Generator()\n",
    "            generator.manual_seed(seed)\n",
    "        else:\n",
    "            generator = self.generator\n",
    "\n",
    "        chunk_list = torch.randperm(self.num_samples // self.chunk_size, generator=generator).tolist()\n",
    "        for i in range(self.num_samples // self.chunk_size):\n",
    "            chunk = chunk_list[i]\n",
    "            yield from (chunk*self.chunk_size + torch.randperm(self.chunk_size, generator=generator)).tolist()\n",
    "        #yield from ((self.num_samples // self.chunk_size)*self.chunk_size + \n",
    "        #    torch.randperm(self.num_samples%self.chunk_size, generator=generator)).tolist()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.num_samples\n",
    "    \n",
    "class LenMatchBatchSampler(torch.utils.data.BatchSampler):\n",
    "    def __iter__(self):\n",
    "        buckets = [[]] * 100\n",
    "        yielded = 0\n",
    "\n",
    "        for idx in self.sampler:\n",
    "            s = self.sampler.data_source[idx]\n",
    "            if isinstance(s,tuple): L = s[0][\"mask\"].sum()\n",
    "            else: L = s[\"mask\"].sum()\n",
    "            #if torch.rand(1).item() < 0.1: L = int(1.5*L)\n",
    "            L = L // 16 \n",
    "            if len(buckets[L]) == 0:  buckets[L] = []\n",
    "            buckets[L].append(idx)\n",
    "            \n",
    "            if len(buckets[L]) == self.batch_size:\n",
    "                batch = list(buckets[L])\n",
    "                yield batch\n",
    "                yielded += 1\n",
    "                buckets[L] = []\n",
    "                \n",
    "        batch = []\n",
    "        leftover = [idx for bucket in buckets for idx in bucket]\n",
    "\n",
    "        for idx in leftover:\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yielded += 1\n",
    "                yield batch\n",
    "                batch = []\n",
    "\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yielded += 1\n",
    "            yield batch\n",
    "\n",
    "        #assert len(self) == yielded,\\\n",
    "        #  \"produced an inccorect number of batches. expected %i, but yielded %i\" %(len(self), yielded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4709406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import os,gc\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def prepare_sensors(path=PATH):\n",
    "    sensors = pd.read_csv(os.path.join(path,'sensor_geometry.csv')).astype(\n",
    "        {\n",
    "            \"sensor_id\": np.int16,\n",
    "            \"x\": np.float32,\n",
    "            \"y\": np.float32,\n",
    "            \"z\": np.float32,\n",
    "        }\n",
    "    )\n",
    "    sensors[\"string\"] = 0\n",
    "    sensors[\"qe\"] = 0#1\n",
    "\n",
    "    for i in range(len(sensors) // 60):\n",
    "        start, end = i * 60, (i * 60) + 60\n",
    "        sensors.loc[start:end, \"string\"] = i\n",
    "\n",
    "        # High Quantum Efficiency in the lower 50 DOMs - https://arxiv.org/pdf/2209.03042.pdf (Figure 1)\n",
    "        if i in range(78, 86):\n",
    "            start_veto, end_veto = i * 60, (i * 60) + 10\n",
    "            start_core, end_core = end_veto + 1, (i * 60) + 60\n",
    "            sensors.loc[start_core:end_core, \"qe\"] = 1# 1.35\n",
    "\n",
    "    # https://github.com/graphnet-team/graphnet/blob/b2bad25528652587ab0cdb7cf2335ee254cfa2db/src/graphnet/models/detector/icecube.py#L33-L41\n",
    "    # Assume that \"rde\" (relative dom efficiency) is equivalent to QE\n",
    "    sensors[\"x\"] /= 500\n",
    "    sensors[\"y\"] /= 500\n",
    "    sensors[\"z\"] /= 500\n",
    "    #sensors[\"qe\"] -= 1.25\n",
    "    #sensors[\"qe\"] /= 0.25\n",
    "\n",
    "    return sensors\n",
    "\n",
    "def ice_transparency(path=PATH, datum=1950):\n",
    "    # Data from page 31 of https://arxiv.org/pdf/1301.5361.pdf\n",
    "    # Datum is from footnote 8 of page 29\n",
    "    df = pd.read_csv(os.path.join(path,'ice_transparency.txt'), delim_whitespace=True)\n",
    "    df[\"z\"] = df[\"depth\"] - datum\n",
    "    df[\"z_norm\"] = df[\"z\"] / 500\n",
    "    df[[\"scattering_len_norm\", \"absorption_len_norm\"]] = RobustScaler().fit_transform(\n",
    "        df[[\"scattering_len\", \"absorption_len\"]])\n",
    "\n",
    "    # These are both roughly equivalent after scaling\n",
    "    f_scattering = interp1d(df[\"z_norm\"], df[\"scattering_len_norm\"])\n",
    "    f_absorption = interp1d(df[\"z_norm\"], df[\"absorption_len_norm\"])\n",
    "    return f_scattering, f_absorption\n",
    "\n",
    "class IceCubeDataset(Dataset):\n",
    "    def __init__(self, path=PATH, chunk_size=200000, L=256, buf_size=4, train=True, reduce_size=-1):\n",
    "        #path_geometry=PATH_GEOMETRY, /sensor_geometry.csv\n",
    "        self.path = os.path.join(path,'train')\n",
    "        self.files = [p for p in sorted(os.listdir(self.path)) if p!='batch_660.parquet'] #660 is shorter\n",
    "        val_fnames = ['batch_655.parquet','batch_656.parquet','batch_657.parquet','batch_658.parquet',\n",
    "                      'batch_659.parquet']\n",
    "        if not train: self.files = val_fnames\n",
    "        else: self.files = sorted(set(self.files) - set(val_fnames))\n",
    "        self.chunk_size = chunk_size\n",
    "        self.buf = OrderedDict()\n",
    "        self.L,self.buf_size = L,buf_size\n",
    "        sensors = prepare_sensors(path)\n",
    "        self.geometry = torch.from_numpy(sensors[['x','y','z']].values.astype(np.float32))\n",
    "        self.qe = sensors['qe'].values\n",
    "        self.ice_properties = ice_transparency(path)\n",
    "        \n",
    "        df = pd.read_parquet(os.path.join(path,'train_meta.parquet'))\n",
    "        df = df[['event_id','azimuth','zenith']]\n",
    "        df['azimuth'] = df['azimuth'].astype(np.float32)\n",
    "        df['zenith'] = df['zenith'].astype(np.float32)\n",
    "        df['event_id'] = df['event_id'].astype(np.int32)\n",
    "        df = df.set_index('event_id',drop=True)\n",
    "        self.target = df\n",
    "        gc.collect()\n",
    "        self.reduce_size = reduce_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)*self.chunk_size if self.reduce_size < 0 \\\n",
    "                else int(self.reduce_size*len(self.files))*self.chunk_size\n",
    "        \n",
    "    def __getitem__(self, idx0):\n",
    "        fname = self.files[idx0//self.chunk_size]\n",
    "        if fname not in self.buf:\n",
    "            df = pl.read_parquet(os.path.join(self.path,fname))\n",
    "            df = df.groupby(\"event_id\").agg([\n",
    "                pl.count(),\n",
    "                pl.col(\"sensor_id\").list(),\n",
    "                pl.col(\"time\").list(),\n",
    "                pl.col(\"charge\").list(),\n",
    "                pl.col(\"auxiliary\").list(),])\n",
    "            self.buf[fname] = df.sort('event_id')\n",
    "            if len(self.buf) > self.buf_size: del self.buf[list(self.buf.keys())[0]]\n",
    "        \n",
    "        idx = idx0%self.chunk_size\n",
    "        df = self.buf[fname]\n",
    "        sensor_id =  df[idx]['sensor_id'][0].item().to_numpy()\n",
    "        time =  df[idx]['time'][0].item().to_numpy()\n",
    "        charge = df[idx]['charge'][0].item().to_numpy()\n",
    "        auxiliary = df[idx]['auxiliary'][0].item().to_numpy()\n",
    "        event_idx = df[idx]['event_id'].item()\n",
    "            \n",
    "        #sensor_id = sensor_id[~auxiliary]\n",
    "        #time = time[~auxiliary]\n",
    "        #charge = charge[~auxiliary]\n",
    "        \n",
    "        time = (time - 1e4)/3e4\n",
    "        charge = np.log10(charge)/3.0 #np.log(charge)\n",
    "        \n",
    "        L = len(sensor_id)\n",
    "        if L < self.L:\n",
    "            sensor_id = np.pad(sensor_id,(0,max(0,self.L-L)))\n",
    "            time = np.pad(time,(0,max(0,self.L-L)))\n",
    "            charge = np.pad(charge,(0,max(0,self.L-L)))\n",
    "            auxiliary = np.pad(auxiliary,(0,max(0,self.L-L)))\n",
    "        else:\n",
    "            ids = torch.randperm(L).numpy()\n",
    "            auxiliary_n = np.where(~auxiliary)[0]\n",
    "            auxiliary_p = np.where(auxiliary)[0]\n",
    "            ids_n = ids[auxiliary_n][:min(self.L,len(auxiliary_n))]\n",
    "            ids_p = ids[auxiliary_p][:min(self.L-len(ids_n),len(auxiliary_p))]\n",
    "            ids = np.concatenate([ids_n,ids_p])\n",
    "            ids.sort()\n",
    "            L = len(ids)\n",
    "            \n",
    "            sensor_id = sensor_id[ids]\n",
    "            time = time[ids]\n",
    "            charge = charge[ids]\n",
    "            auxiliary = auxiliary[ids]\n",
    "            L = len(ids)\n",
    "            \n",
    "        attn_mask = torch.zeros(self.L, dtype=torch.bool)\n",
    "        attn_mask[:L] = True\n",
    "        sensor_id = torch.from_numpy(sensor_id).long()\n",
    "        pos = self.geometry[sensor_id]\n",
    "        pos[L:] = 0\n",
    "        qe = self.qe[sensor_id]\n",
    "        qe[L:] = 0\n",
    "        ice_properties = np.stack([self.ice_properties[0](pos[:L,2]),\n",
    "                                   self.ice_properties[1](pos[:L,2])],-1)\n",
    "        ice_properties = np.pad(ice_properties,((0,max(0,self.L-L)),(0,0)))\n",
    "        ice_properties = torch.from_numpy(ice_properties).float()\n",
    "        \n",
    "        target = self.target.loc[event_idx].values\n",
    "\n",
    "        return {'sensor_id': sensor_id, 'time': torch.from_numpy(time).float(),\n",
    "                'charge': torch.from_numpy(charge).float(), 'pos':pos, 'mask':attn_mask,\n",
    "                'idx':event_idx, 'auxiliary':torch.from_numpy(auxiliary).long(),\n",
    "                'qe':qe, 'ice_properties':ice_properties},\\\n",
    "               {'target': torch.from_numpy(target).float()}\n",
    "    \n",
    "    \n",
    "class IceCubeDataset_len(Dataset):\n",
    "    def __init__(self, path=PATH, chunk_size=200000, L=256, buf_size=2, train=True, reduce_size=-1):\n",
    "        #path_geometry=PATH_GEOMETRY, /sensor_geometry.csv\n",
    "        self.path = os.path.join(path,'train')\n",
    "        self.files = [p for p in sorted(os.listdir(self.path)) if p!='batch_660.parquet'] #660 is shorter\n",
    "        val_fnames = ['batch_655.parquet','batch_656.parquet','batch_657.parquet','batch_658.parquet',\n",
    "                      'batch_659.parquet']\n",
    "        if not train: self.files = val_fnames\n",
    "        else: self.files = sorted(set(self.files) - set(val_fnames))\n",
    "        self.chunk_size = chunk_size\n",
    "        self.buf = OrderedDict()\n",
    "        self.L,self.buf_size = L,buf_size\n",
    "        sensors = prepare_sensors(path)\n",
    "        self.geometry = torch.from_numpy(sensors[['x','y','z']].values.astype(np.float32))\n",
    "        self.qe = sensors['qe'].values\n",
    "        self.ice_properties = ice_transparency(path)\n",
    "        \n",
    "        gc.collect()\n",
    "        self.reduce_size = reduce_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)*self.chunk_size if self.reduce_size < 0 \\\n",
    "                else int(self.reduce_size*len(self.files))*self.chunk_size\n",
    "        \n",
    "    def __getitem__(self, idx0):\n",
    "        fname = self.files[idx0//self.chunk_size]\n",
    "        if fname not in self.buf:\n",
    "            df = pl.read_parquet(os.path.join(self.path,fname))\n",
    "            df = df.groupby(\"event_id\").agg([\n",
    "                pl.count(),\n",
    "                pl.col(\"sensor_id\").list(),\n",
    "                pl.col(\"time\").list(),\n",
    "                pl.col(\"charge\").list(),\n",
    "                pl.col(\"auxiliary\").list(),])\n",
    "            self.buf[fname] = df.sort('event_id')\n",
    "            if len(self.buf) > self.buf_size: del self.buf[list(self.buf.keys())[0]]\n",
    "        \n",
    "        idx = idx0%self.chunk_size\n",
    "        df = self.buf[fname]\n",
    "        sensor_id =  df[idx]['sensor_id'][0].item().to_numpy()\n",
    "        mask = torch.ones(min(len(sensor_id),self.L), dtype=torch.long)\n",
    "        return {'mask':mask},{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "396a8265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "from timm.models.layers import drop_path, to_2tuple, trunc_normal_\n",
    "\n",
    "from timm.models.layers import drop_path, to_2tuple, trunc_normal_\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training)\n",
    "    \n",
    "    def extra_repr(self) -> str:\n",
    "        return 'p={}'.format(self.drop_prob)\n",
    "    \n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        # x = self.drop(x)\n",
    "        # commit this for the orignal BERT implement \n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "#BEiTv2 block\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., init_values=None, act_layer=nn.GELU, norm_layer=nn.LayerNorm,\n",
    "                 window_size=None, attn_head_dim=None, **kwargs):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = nn.MultiheadAttention(dim, num_heads, dropout=drop, batch_first=True)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "        if init_values is not None:\n",
    "            self.gamma_1 = nn.Parameter(init_values * torch.ones((dim)),requires_grad=True)\n",
    "            self.gamma_2 = nn.Parameter(init_values * torch.ones((dim)),requires_grad=True)\n",
    "        else:\n",
    "            self.gamma_1, self.gamma_2 = None, None\n",
    "\n",
    "    def forward(self, x, attn_mask=None, key_padding_mask=None):\n",
    "        if self.gamma_1 is None:\n",
    "            xn = self.norm1(x)\n",
    "            x = x + self.drop_path(self.attn(xn,xn,xn,\n",
    "                            attn_mask=attn_mask,\n",
    "                            key_padding_mask=key_padding_mask,\n",
    "                            need_weights=False)[0])\n",
    "            x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        else:\n",
    "            xn = self.norm1(x)\n",
    "            x = x + self.drop_path(self.gamma_1 * self.drop_path(self.attn(xn,xn,xn,\n",
    "                            attn_mask=attn_mask,\n",
    "                            key_padding_mask=key_padding_mask,\n",
    "                            need_weights=False)[0]))\n",
    "            x = x + self.drop_path(self.gamma_2 * self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim=16, M=10000):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.M = M\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(self.M) / half_dim\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * (-emb))\n",
    "        emb = x[...,None] * emb[None,...]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "class Extractor(nn.Module):\n",
    "    def __init__(self, dim_base=128, dim=384):\n",
    "        super().__init__()\n",
    "        self.emb = SinusoidalPosEmb(dim=dim_base)\n",
    "        self.emb2 = SinusoidalPosEmb(dim=dim_base//2)\n",
    "        self.aux_emb = nn.Embedding(2,dim_base//2)\n",
    "        self.qe_emb = nn.Embedding(2,dim_base//2)\n",
    "        self.proj = nn.Linear(dim_base*7,dim)\n",
    "        \n",
    "    def forward(self, x, Lmax=None):\n",
    "        pos = x['pos'] if Lmax is None else x['pos'][:,:Lmax]\n",
    "        charge = x['charge'] if Lmax is None else x['charge'][:,:Lmax]\n",
    "        time = x['time'] if Lmax is None else x['time'][:,:Lmax]\n",
    "        auxiliary = x['auxiliary'] if Lmax is None else x['auxiliary'][:,:Lmax]\n",
    "        qe = x['qe'] if Lmax is None else x['qe'][:,:Lmax]\n",
    "        ice_properties = x['ice_properties'] if Lmax is None else x['ice_properties'][:,:Lmax]\n",
    "        \n",
    "        x = torch.cat([self.emb(100*pos).flatten(-2), self.emb(40*charge),\n",
    "                       self.emb(100*time),self.aux_emb(auxiliary),self.qe_emb(qe),\n",
    "                       self.emb2(50*ice_properties).flatten(-2)],-1)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "class DeepIceModel(nn.Module):\n",
    "    def __init__(self, dim=384, dim_base=128, depth=12, use_checkpoint=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.extractor = Extractor(dim_base,dim)\n",
    "        self.cls_token = nn.Linear(dim,1,bias=False)\n",
    "        self.blocks = nn.ModuleList([ \n",
    "            Block(\n",
    "                dim=dim, num_heads=dim//64, mlp_ratio=4, drop_path=0, init_values=1,)\n",
    "            for i in range(depth)])\n",
    "        #self.blocks = nn.ModuleList([ \n",
    "        #    nn.TransformerEncoderLayer(dim,dim//64,dim*4,dropout=0,\n",
    "        #        activation=nn.GELU(), batch_first=True, norm_first=True)\n",
    "        #    for i in range(depth)])\n",
    "\n",
    "        self.proj_out = nn.Linear(dim,3)\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "        self.apply(self._init_weights)\n",
    "        trunc_normal_(self.cls_token.weight, std=.02)\n",
    "\n",
    "    def fix_init_weight(self):\n",
    "        def rescale(param, layer_id):\n",
    "            param.div_(math.sqrt(2.0 * layer_id))\n",
    "\n",
    "        for layer_id, layer in enumerate(self.blocks):\n",
    "            rescale(layer.attn.proj.weight.data, layer_id + 1)\n",
    "            rescale(layer.mlp.fc2.weight.data, layer_id + 1)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    def init_weights(self, pretrained=None):\n",
    "        def _init_weights(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                trunc_normal_(m.weight, std=.02)\n",
    "                if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.LayerNorm):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "        self.apply(_init_weights)\n",
    "    \n",
    "    def forward(self, x0):\n",
    "        mask = x0['mask']\n",
    "        B,_ = mask.shape\n",
    "        mask = torch.cat([torch.ones(B,1,dtype=mask.dtype, device=mask.device),mask],1)\n",
    "        attn_mask = torch.zeros(mask.shape, device=mask.device)\n",
    "        attn_mask[~mask] = -torch.inf\n",
    "        Lmax = mask.sum(-1).max()\n",
    "        \n",
    "        x = self.extractor(x0, Lmax-1)\n",
    "        cls_token = self.cls_token.weight.unsqueeze(0).expand(B,-1,-1)\n",
    "        x = torch.cat([cls_token,x],1)\n",
    "        x,mask,attn_mask = x[:,:Lmax], mask[:,:Lmax], attn_mask[:,:Lmax]\n",
    "        \n",
    "        #Lmax = mask.max(0)[0].sum()\n",
    "        Lmax = mask.sum(-1).max()\n",
    "        x,mask,attn_mask = x[:,:Lmax], mask[:,:Lmax], attn_mask[:,:Lmax]\n",
    "        #print(Lmax)\n",
    "        \n",
    "        for blk in self.blocks:\n",
    "            if self.use_checkpoint:\n",
    "                x = checkpoint.checkpoint(blk, x, None, attn_mask)\n",
    "            else: x = blk(x, None, attn_mask)\n",
    "                \n",
    "        x = self.proj_out(x[:,0]) #cls token\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03a08fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from loss_functions import VonMisesFisher3DLoss\n",
    "\n",
    "def loss(pred,y):\n",
    "    #print(pred.max())\n",
    "    pred = F.normalize(pred.float(),dim=-1)\n",
    "    \n",
    "    sa2 = torch.sin(y['target'][:,0])\n",
    "    ca2 = torch.cos(y['target'][:,0])\n",
    "    sz2 = torch.sin(y['target'][:,1])\n",
    "    cz2 = torch.cos(y['target'][:,1])\n",
    "    \n",
    "    scalar_prod = (pred[:,0]*sa2*sz2 + pred[:,1]*ca2*sz2 + pred[:,2]*cz2).clip(-1+1e-8,1-1e-8)\n",
    "    return torch.acos(scalar_prod).abs().mean(-1)   \n",
    "\n",
    "def loss_vms(pred,y):\n",
    "    sa2 = torch.sin(y['target'][:,0])\n",
    "    ca2 = torch.cos(y['target'][:,0])\n",
    "    sz2 = torch.sin(y['target'][:,1])\n",
    "    cz2 = torch.cos(y['target'][:,1])\n",
    "    t = torch.stack([sa2*sz2,ca2*sz2,cz2],-1)\n",
    "    \n",
    "    p = pred.float()\n",
    "    l = torch.norm(pred.float(),dim=-1).unsqueeze(-1)\n",
    "    p = torch.cat([pred.float()/l,l],-1)\n",
    "    \n",
    "    loss = VonMisesFisher3DLoss()(p,t)\n",
    "    return loss\n",
    "\n",
    "def get_val(pred):\n",
    "    pred = F.normalize(pred,dim=-1)\n",
    "    zen = torch.acos(pred[:,2].clip(-1,1))\n",
    "    f = F.normalize(pred[:,:2],dim=-1)\n",
    "    az = torch.asin(f[:,0].clip(-1,1))\n",
    "    az = torch.where(f[:,1] > 0, az, math.pi - az)\n",
    "    az = torch.where(az > 0, az, az + 2.0*math.pi)\n",
    "    return torch.stack([az,zen],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3a400ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to(x, device='cuda'):\n",
    "    return {k:x[k].to(device) for k in x}\n",
    "\n",
    "def to_device(x, device='cuda'):\n",
    "    return tuple(dict_to(e,device) for e in x)\n",
    "\n",
    "class DeviceDataLoader:\n",
    "    def __init__(self, dataloader, device='cuda'):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dataloader:\n",
    "            yield tuple(dict_to(x, self.device) for x in batch)\n",
    "            \n",
    "def WrapperAdamW(param_groups,**kwargs):\n",
    "    return OptimWrapper(param_groups,torch.optim.AdamW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f40b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "037a8dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'init5small'\n",
    "\n",
    "ds_train = IceCubeDataset(train=True, reduce_size=0.125, L=L)\n",
    "ds_train_len = IceCubeDataset_len(train=True, reduce_size=0.125, L=L)\n",
    "len_sampler_train = LenMatchBatchSampler(RandomChunkSampler(ds_train_len),batch_size=bs, drop_last=True)\n",
    "dl_train = DeviceDataLoader(DataLoader(ds_train, batch_sampler=len_sampler_train, num_workers=4, \n",
    "                        persistent_workers=True))\n",
    "#dl_train = DeviceDataLoader(DataLoader(ds_train, batch_size=bs, sampler=RandomChunkSampler(ds_train),\n",
    "#                            num_workers=8, persistent_workers=True, drop_last=True))\n",
    "#there is a bug in process pool creation, so persistent_workers and num_workers=0 are important\n",
    "ds_val = IceCubeDataset(train=False, L=L)\n",
    "ds_val_len = IceCubeDataset_len(train=False, L=L)\n",
    "len_sampler_val = LenMatchBatchSampler(RandomChunkSampler(ds_val_len),batch_size=bs, drop_last=False)\n",
    "dl_val = DeviceDataLoader(DataLoader(ds_val, batch_sampler=len_sampler_val, num_workers=0))\n",
    "#dl_val= DeviceDataLoader(DataLoader(ds_val, batch_size=bs, sampler=RandomChunkSampler(ds_val),\n",
    "#                            num_workers=0, drop_last=False))\n",
    "\n",
    "data = DataLoaders(dl_train,dl_val)\n",
    "model = EncoderWithDirectionReconstructionV8()\n",
    "model = model.cuda()\n",
    "learn = Learner(data, model, loss_func=loss_vms,cbs=[GradientClip(3.0),\n",
    "            SaveModelCallback(monitor='loss',comp=np.less,at_end=True),\n",
    "            GradientAccumulation(n_acc=4)],\n",
    "            metrics=[loss], opt_func=partial(WrapperAdamW,eps=1e-7)).to_fp16()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23ff8720-072f-45d0-933f-f4ce9fdc36b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:63: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=3.981071586167673e-06)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f31ace60-f05d-46df-84f8-b9a41aca6268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.629674</td>\n",
       "      <td>1.578753</td>\n",
       "      <td>1.042175</td>\n",
       "      <td>2:42:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.563874</td>\n",
       "      <td>1.540420</td>\n",
       "      <td>1.030785</td>\n",
       "      <td>2:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.539338</td>\n",
       "      <td>1.504885</td>\n",
       "      <td>1.024979</td>\n",
       "      <td>2:44:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.501985</td>\n",
       "      <td>1.488280</td>\n",
       "      <td>1.020265</td>\n",
       "      <td>2:44:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.497736</td>\n",
       "      <td>1.479548</td>\n",
       "      <td>1.012755</td>\n",
       "      <td>2:44:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.443593</td>\n",
       "      <td>1.426972</td>\n",
       "      <td>1.001136</td>\n",
       "      <td>2:44:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.402677</td>\n",
       "      <td>1.397596</td>\n",
       "      <td>0.994404</td>\n",
       "      <td>2:44:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.414280</td>\n",
       "      <td>1.391022</td>\n",
       "      <td>0.991815</td>\n",
       "      <td>2:44:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:63: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with loss value: 1.0421749353408813.\n",
      "Better model found at epoch 1 with loss value: 1.030785083770752.\n",
      "Better model found at epoch 2 with loss value: 1.0249793529510498.\n",
      "Better model found at epoch 3 with loss value: 1.0202646255493164.\n",
      "Better model found at epoch 4 with loss value: 1.012755274772644.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 5 with loss value: 1.001136064529419.\n",
      "Better model found at epoch 6 with loss value: 0.9944040179252625.\n",
      "Better model found at epoch 7 with loss value: 0.9918146729469299.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EncoderWithDirectionReconstructionV8' object has no attribute 'module'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1095484/2941645707.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpct_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#torch.save(learn.model.state_dict(),os.path.join(OUT,f'{fname}_0.pth'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{fname}_0.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1186\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EncoderWithDirectionReconstructionV8' object has no attribute 'module'"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(8, lr_max=5e-4, wd=0.05, pct_start=0.01)\n",
    "torch.save(learn.model.state_dict(),os.path.join(OUT,f'{fname}_0.pth'))\n",
    "#torch.save(learn.model.module.state_dict(),os.path.join(OUT,f'{fname}_0.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b9f78eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(learn.model.state_dict(),os.path.join(OUT,f'{fname}_0.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2c65dd3-b76e-4f29-86f3-71a2d34f3833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'init/init5small_0.pth'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(OUT,f'{fname}_0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea5714f-d3bb-4209-86d5-a6dab3f35114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
