{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp maximdataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Iterator, Optional, Sized\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import os,gc\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.interpolate import interp1d\n",
    "from fastai.vision.all import DataLoaders, OptimWrapper\n",
    "from torch_geometric.nn.pool import knn_graph\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import to_dense_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_mask(L):\n",
    "    mask = np.random.choice([True, False], size=L, p=[0.93, 0.07])\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-17 01:02:08 - get_logger - Writing log to \u001b[1mlogs/graphnet_20230317-010208.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/slh/icecube/')\n",
    "from icecube.models import EncoderWithDirectionReconstructionV10, EncoderWithDirectionReconstructionV11, EncoderWithDirectionReconstructionV13, EncoderWithDirectionReconstructionV12_V2, EncoderWithDirectionReconstructionV14, EncoderWithDirectionReconstructionV11_V2_GLOBAL_LOCAL\n",
    "#from icecube.modelsgraph import PytorchEGNNV0\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "PATH = '/opt/slh/icecube/data/'\n",
    "\n",
    "def flatten(o):\n",
    "    \"Concatenate all collections and items as a generator\"\n",
    "    for item in o:\n",
    "        if isinstance(o, dict): yield o[item]; continue\n",
    "        elif isinstance(item, str): yield item; continue\n",
    "        try: yield from flatten(item)\n",
    "        except TypeError: yield item\n",
    "        \n",
    "        \n",
    "def get_edge_index(pos, time, mask, L, k =8):\n",
    "    xyzt = torch.concat([pos, time.view(-1, 1)], dim=1)[mask]\n",
    "    edge_index = knn_graph(\n",
    "            xyzt[:, [0, 1, 2,3]],  # x, y, z\n",
    "            k=k,\n",
    "            batch=None,\n",
    "            loop=False\n",
    "        )\n",
    "    \n",
    "    total_len = L * k\n",
    "    to_pad = total_len - edge_index.shape[1]\n",
    "    edge_mask = torch.zeros(2, total_len, dtype=torch.bool)\n",
    "    \n",
    "    if to_pad > 0:\n",
    "        edge_mask[:, :edge_index.shape[1]] = True\n",
    "        edge_index = F.pad(edge_index, (0, to_pad), \"constant\", 0) \n",
    "    else:\n",
    "        edge_mask[:] = True\n",
    "    return edge_index, edge_mask\n",
    "        \n",
    "class RandomChunkSampler(torch.utils.data.Sampler[int]):\n",
    "    r\"\"\"Samples elements randomly. If without replacement, then sample from a shuffled dataset.\n",
    "    If with replacement, then user can specify :attr:`num_samples` to draw.\n",
    "    Args:\n",
    "        data_source (Dataset): dataset to sample from\n",
    "        replacement (bool): samples are drawn on-demand with replacement if ``True``, default=``False``\n",
    "        num_samples (int): number of samples to draw, default=`len(dataset)`.\n",
    "        generator (Generator): Generator used in sampling.\n",
    "    \"\"\"\n",
    "    data_source: Sized\n",
    "    replacement: bool\n",
    "\n",
    "    def __init__(self, data_source: Sized, num_samples: Optional[int] = None,\n",
    "                 generator=None, chunk_size=200000, **kwargs) -> None:\n",
    "        self.data_source = data_source\n",
    "        self._num_samples = num_samples\n",
    "        self.generator = generator\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "        if not isinstance(self.num_samples, int) or self.num_samples <= 0:\n",
    "            raise ValueError(\"num_samples should be a positive integer \"\n",
    "                             \"value, but got num_samples={}\".format(self.num_samples))\n",
    "\n",
    "    @property\n",
    "    def num_samples(self) -> int:\n",
    "        # dataset size might change at runtime\n",
    "        if self._num_samples is None:\n",
    "            return len(self.data_source)\n",
    "        return self._num_samples\n",
    "\n",
    "    def __iter__(self) -> Iterator[int]:\n",
    "        n = len(self.data_source)\n",
    "        if self.generator is None:\n",
    "            seed = int(torch.empty((), dtype=torch.int64).random_().item())\n",
    "            generator = torch.Generator()\n",
    "            generator.manual_seed(seed)\n",
    "        else:\n",
    "            generator = self.generator\n",
    "\n",
    "        chunk_list = torch.randperm(self.num_samples // self.chunk_size, generator=generator).tolist()\n",
    "        for i in range(self.num_samples // self.chunk_size):\n",
    "            chunk = chunk_list[i]\n",
    "            yield from (chunk*self.chunk_size + torch.randperm(self.chunk_size, generator=generator)).tolist()\n",
    "        #yield from ((self.num_samples // self.chunk_size)*self.chunk_size + \n",
    "        #    torch.randperm(self.num_samples%self.chunk_size, generator=generator)).tolist()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.num_samples\n",
    "    \n",
    "class LenMatchBatchSampler(torch.utils.data.BatchSampler):\n",
    "    def __iter__(self):\n",
    "        buckets = [[]] * 100\n",
    "        yielded = 0\n",
    "\n",
    "        for idx in self.sampler:\n",
    "            s = self.sampler.data_source[idx]\n",
    "            if isinstance(s,tuple): L = s[0][\"mask\"].sum()\n",
    "            else: L = s[\"mask\"].sum()\n",
    "            #if torch.rand(1).item() < 0.1: L = int(1.5*L)\n",
    "            L = L // 16 \n",
    "            if len(buckets[L]) == 0:  buckets[L] = []\n",
    "            buckets[L].append(idx)\n",
    "            \n",
    "            if len(buckets[L]) == self.batch_size:\n",
    "                batch = list(buckets[L])\n",
    "                yield batch\n",
    "                yielded += 1\n",
    "                buckets[L] = []\n",
    "                \n",
    "        batch = []\n",
    "        leftover = [idx for bucket in buckets for idx in bucket]\n",
    "\n",
    "        for idx in leftover:\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yielded += 1\n",
    "                yield batch\n",
    "                batch = []\n",
    "\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yielded += 1\n",
    "            yield batch\n",
    "            \n",
    "def prepare_sensors(path=PATH):\n",
    "    sensors = pd.read_csv(os.path.join(path,'sensor_geometry.csv')).astype(\n",
    "        {\n",
    "            \"sensor_id\": np.int16,\n",
    "            \"x\": np.float32,\n",
    "            \"y\": np.float32,\n",
    "            \"z\": np.float32,\n",
    "        }\n",
    "    )\n",
    "    sensors[\"string\"] = 0\n",
    "    sensors[\"qe\"] = 0#1\n",
    "\n",
    "    for i in range(len(sensors) // 60):\n",
    "        start, end = i * 60, (i * 60) + 60\n",
    "        sensors.loc[start:end, \"string\"] = i\n",
    "\n",
    "        # High Quantum Efficiency in the lower 50 DOMs - https://arxiv.org/pdf/2209.03042.pdf (Figure 1)\n",
    "        if i in range(78, 86):\n",
    "            start_veto, end_veto = i * 60, (i * 60) + 10\n",
    "            start_core, end_core = end_veto + 1, (i * 60) + 60\n",
    "            sensors.loc[start_core:end_core, \"qe\"] = 1# 1.35\n",
    "\n",
    "    # https://github.com/graphnet-team/graphnet/blob/b2bad25528652587ab0cdb7cf2335ee254cfa2db/src/graphnet/models/detector/icecube.py#L33-L41\n",
    "    # Assume that \"rde\" (relative dom efficiency) is equivalent to QE\n",
    "    sensors[\"x\"] /= 500\n",
    "    sensors[\"y\"] /= 500\n",
    "    sensors[\"z\"] /= 500\n",
    "    #sensors[\"qe\"] -= 1.25\n",
    "    #sensors[\"qe\"] /= 0.25\n",
    "\n",
    "    return sensors\n",
    "\n",
    "def ice_transparency(path=PATH, datum=1950):\n",
    "    # Data from page 31 of https://arxiv.org/pdf/1301.5361.pdf\n",
    "    # Datum is from footnote 8 of page 29\n",
    "    df = pd.read_csv(os.path.join(path,'ice_transparency.txt'), delim_whitespace=True)\n",
    "    df[\"z\"] = df[\"depth\"] - datum\n",
    "    df[\"z_norm\"] = df[\"z\"] / 500\n",
    "    df[[\"scattering_len_norm\", \"absorption_len_norm\"]] = RobustScaler().fit_transform(\n",
    "        df[[\"scattering_len\", \"absorption_len\"]])\n",
    "\n",
    "    # These are both roughly equivalent after scaling\n",
    "    f_scattering = interp1d(df[\"z_norm\"], df[\"scattering_len_norm\"])\n",
    "    f_absorption = interp1d(df[\"z_norm\"], df[\"absorption_len_norm\"])\n",
    "    return f_scattering, f_absorption\n",
    "\n",
    "class IceCubeDataset(Dataset):\n",
    "    def __init__(self, path=PATH, chunk_size=200000, L=256, buf_size=4, train=True, reduce_size=-1):\n",
    "        #path_geometry=PATH_GEOMETRY, /sensor_geometry.csv\n",
    "        self.path = os.path.join(path,'train')\n",
    "        self.files = [p for p in sorted(os.listdir(self.path)) if p!='batch_660.parquet'] #660 is shorter\n",
    "        val_fnames = ['batch_655.parquet','batch_656.parquet','batch_657.parquet','batch_658.parquet',\n",
    "                      'batch_659.parquet']\n",
    "        if not train: self.files = val_fnames\n",
    "        else: self.files = sorted(set(self.files) - set(val_fnames))\n",
    "        self.chunk_size = chunk_size\n",
    "        self.buf = OrderedDict()\n",
    "        self.L,self.buf_size = L,buf_size\n",
    "        sensors = prepare_sensors(path)\n",
    "        self.geometry = torch.from_numpy(sensors[['x','y','z']].values.astype(np.float32))\n",
    "        self.qe = sensors['qe'].values\n",
    "        self.ice_properties = ice_transparency(path)\n",
    "        self.train = train\n",
    "        \n",
    "        df = pd.read_parquet(os.path.join(path,'train_meta.parquet'))\n",
    "        df = df[['event_id','azimuth','zenith']]\n",
    "        df['azimuth'] = df['azimuth'].astype(np.float32)\n",
    "        df['zenith'] = df['zenith'].astype(np.float32)\n",
    "        df['event_id'] = df['event_id'].astype(np.int32)\n",
    "        df = df.set_index('event_id',drop=True)\n",
    "        self.target = df\n",
    "        gc.collect()\n",
    "        self.reduce_size = reduce_size\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)*self.chunk_size if self.reduce_size < 0 \\\n",
    "                else int(self.reduce_size*len(self.files))*self.chunk_size\n",
    "        \n",
    "    def __getitem__(self, idx0):\n",
    "        fname = self.files[idx0//self.chunk_size]\n",
    "        if fname not in self.buf:\n",
    "            df = pl.read_parquet(os.path.join(self.path,fname))\n",
    "            df = df.groupby(\"event_id\").agg([\n",
    "                pl.count(),\n",
    "                pl.col(\"sensor_id\").list(),\n",
    "                pl.col(\"time\").list(),\n",
    "                pl.col(\"charge\").list(),\n",
    "                pl.col(\"auxiliary\").list(),])\n",
    "            self.buf[fname] = df.sort('event_id')\n",
    "            if len(self.buf) > self.buf_size: del self.buf[list(self.buf.keys())[0]]\n",
    "        \n",
    "        idx = idx0%self.chunk_size\n",
    "        df = self.buf[fname]\n",
    "        sensor_id =  df[idx]['sensor_id'][0].item().to_numpy()\n",
    "        time =  df[idx]['time'][0].item().to_numpy()\n",
    "        charge = df[idx]['charge'][0].item().to_numpy()\n",
    "        auxiliary = df[idx]['auxiliary'][0].item().to_numpy()\n",
    "        event_idx = df[idx]['event_id'].item()\n",
    "        \n",
    "        if self.train and np.random.rand() < 0.9:\n",
    "            filter_mask = generate_mask(time.shape[0])\n",
    "            sensor_id =  sensor_id[filter_mask]\n",
    "            time =  time[filter_mask]\n",
    "            charge = charge[filter_mask]\n",
    "            auxiliary = auxiliary[filter_mask]\n",
    "\n",
    "            \n",
    "        #sensor_id = sensor_id[~auxiliary]\n",
    "        #time = time[~auxiliary]\n",
    "        #charge = charge[~auxiliary]\n",
    "        \n",
    "        time = (time - 1e4)/3e4\n",
    "        charge = np.log10(charge)/3.0 #np.log(charge)\n",
    "        \n",
    "        L = len(sensor_id)\n",
    "        if L < self.L:\n",
    "            sensor_id = np.pad(sensor_id,(0,max(0,self.L-L)))\n",
    "            time = np.pad(time,(0,max(0,self.L-L)))\n",
    "            charge = np.pad(charge,(0,max(0,self.L-L)))\n",
    "            auxiliary = np.pad(auxiliary,(0,max(0,self.L-L)))\n",
    "        else:\n",
    "            ids = torch.randperm(L).numpy()\n",
    "            auxiliary_n = np.where(~auxiliary)[0]\n",
    "            auxiliary_p = np.where(auxiliary)[0]\n",
    "            ids_n = ids[auxiliary_n][:min(self.L,len(auxiliary_n))]\n",
    "            ids_p = ids[auxiliary_p][:min(self.L-len(ids_n),len(auxiliary_p))]\n",
    "            ids = np.concatenate([ids_n,ids_p])\n",
    "            ids.sort()\n",
    "            L = len(ids)\n",
    "            \n",
    "            sensor_id = sensor_id[ids]\n",
    "            time = time[ids]\n",
    "            charge = charge[ids]\n",
    "            auxiliary = auxiliary[ids]\n",
    "            L = len(ids)\n",
    "            \n",
    "        attn_mask = torch.zeros(self.L, dtype=torch.bool)\n",
    "        attn_mask[:L] = True\n",
    "        sensor_id = torch.from_numpy(sensor_id).long()\n",
    "        pos = self.geometry[sensor_id]\n",
    "        pos[L:] = 0\n",
    "        qe = self.qe[sensor_id]\n",
    "        qe[L:] = 0\n",
    "        ice_properties = np.stack([self.ice_properties[0](pos[:L,2]),\n",
    "                                   self.ice_properties[1](pos[:L,2])],-1)\n",
    "        ice_properties = np.pad(ice_properties,((0,max(0,self.L-L)),(0,0)))\n",
    "        ice_properties = torch.from_numpy(ice_properties).float()\n",
    "        \n",
    "        target = self.target.loc[event_idx].values\n",
    "        edge_index, edge_mask = get_edge_index(pos, torch.from_numpy(time).float(), attn_mask, L=self.L)\n",
    "\n",
    "        return {'sensor_id': sensor_id, \n",
    "                'time': torch.from_numpy(time).float(),\n",
    "                'charge': torch.from_numpy(charge).float(), \n",
    "                'pos':pos,\n",
    "                'mask':attn_mask,\n",
    "                'idx':event_idx,\n",
    "                'auxiliary':torch.from_numpy(auxiliary).long(),\n",
    "                'qe':qe, \n",
    "                'ice_properties':ice_properties,\n",
    "                \"edge_index\": edge_index, \n",
    "                'edge_mask': edge_mask}, {'target': torch.from_numpy(target).float() }\n",
    "    \n",
    "    \n",
    "class IceCubeDataset_len(Dataset):\n",
    "    def __init__(self, path=PATH, chunk_size=200000, L=256, buf_size=2, train=True, reduce_size=-1):\n",
    "        #path_geometry=PATH_GEOMETRY, /sensor_geometry.csv\n",
    "        self.path = os.path.join(path,'train')\n",
    "        self.files = [p for p in sorted(os.listdir(self.path)) if p!='batch_660.parquet'] #660 is shorter\n",
    "        val_fnames = ['batch_655.parquet','batch_656.parquet','batch_657.parquet','batch_658.parquet',\n",
    "                      'batch_659.parquet']\n",
    "        if not train: self.files = val_fnames\n",
    "        else: self.files = sorted(set(self.files) - set(val_fnames))\n",
    "        self.chunk_size = chunk_size\n",
    "        self.buf = OrderedDict()\n",
    "        self.L,self.buf_size = L,buf_size\n",
    "        sensors = prepare_sensors(path)\n",
    "        self.geometry = torch.from_numpy(sensors[['x','y','z']].values.astype(np.float32))\n",
    "        self.qe = sensors['qe'].values\n",
    "        self.ice_properties = ice_transparency(path)\n",
    "        \n",
    "        gc.collect()\n",
    "        self.reduce_size = reduce_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)*self.chunk_size if self.reduce_size < 0 \\\n",
    "                else int(self.reduce_size*len(self.files))*self.chunk_size\n",
    "        \n",
    "    def __getitem__(self, idx0):\n",
    "        fname = self.files[idx0//self.chunk_size]\n",
    "        if fname not in self.buf:\n",
    "            df = pl.read_parquet(os.path.join(self.path,fname))\n",
    "            df = df.groupby(\"event_id\").agg([\n",
    "                pl.count(),\n",
    "                pl.col(\"sensor_id\").list(),\n",
    "                pl.col(\"time\").list(),\n",
    "                pl.col(\"charge\").list(),\n",
    "                pl.col(\"auxiliary\").list(),])\n",
    "            self.buf[fname] = df.sort('event_id')\n",
    "            if len(self.buf) > self.buf_size: del self.buf[list(self.buf.keys())[0]]\n",
    "        \n",
    "        idx = idx0%self.chunk_size\n",
    "        df = self.buf[fname]\n",
    "        sensor_id =  df[idx]['sensor_id'][0].item().to_numpy()\n",
    "        mask = torch.ones(min(len(sensor_id),self.L), dtype=torch.long)\n",
    "        return {'mask':mask},{}\n",
    "    \n",
    "    \n",
    "def dict_to(x, device='cpu'):\n",
    "    return {k:x[k].to(device) for k in x}\n",
    "\n",
    "def to_device(x, device='cpu'):\n",
    "    return tuple(dict_to(e,device) for e in x)\n",
    "\n",
    "class DeviceDataLoader:\n",
    "    def __init__(self, dataloader, device='cpu'):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dataloader:\n",
    "            yield tuple(dict_to(x, self.device) for x in batch)\n",
    "            \n",
    "def WrapperAdamW(param_groups,**kwargs):\n",
    "    return OptimWrapper(param_groups,torch.optim.AdamW)\n",
    "\n",
    "def get_dataloaders(bs, L=192, NUM_WORKERS = 4, SEED = 2023, reduce_size=0.125):\n",
    "    ds_train = IceCubeDataset(train=True,\n",
    "                              reduce_size=reduce_size,\n",
    "                              L=L)\n",
    "    ds_train_len = IceCubeDataset_len(train=True, \n",
    "                                      reduce_size=reduce_size,\n",
    "                                      L=L)\n",
    "    len_sampler_train = LenMatchBatchSampler(\n",
    "        RandomChunkSampler(ds_train_len),\n",
    "        batch_size=bs, \n",
    "        drop_last=True)\n",
    "    dl_train = DeviceDataLoader(DataLoader(ds_train, \n",
    "                                           batch_sampler=len_sampler_train, \n",
    "                                           num_workers=NUM_WORKERS, \n",
    "                                            persistent_workers=True))\n",
    "    ds_val = IceCubeDataset(train=False, L=L)\n",
    "    ds_val_len = IceCubeDataset_len(train=False, L=L)\n",
    "    len_sampler_val = LenMatchBatchSampler(\n",
    "                RandomChunkSampler(ds_val_len),\n",
    "                batch_size=bs, \n",
    "                drop_last=False)\n",
    "    dl_val = DeviceDataLoader(DataLoader(ds_val, batch_sampler=len_sampler_val, num_workers=0))\n",
    "\n",
    "    data = DataLoaders(dl_train,dl_val)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dataloaders(bs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:92: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dls[0]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = EncoderWithDirectionReconstructionV11_V2_GLOBAL_LOCAL().eval()\n",
    "with torch.no_grad():\n",
    "    out = md(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5190,  0.2055,  0.0148],\n",
       "        [ 0.4513,  0.2232,  0.0329],\n",
       "        [ 0.5047,  0.2023,  0.0615],\n",
       "        [ 0.4949,  0.2037,  0.0368],\n",
       "        [ 0.4708,  0.1509,  0.0718],\n",
       "        [ 0.4988,  0.1689, -0.0097],\n",
       "        [ 0.5313,  0.2010, -0.0042],\n",
       "        [ 0.4253,  0.1354,  0.0871],\n",
       "        [ 0.5034,  0.1713,  0.0767],\n",
       "        [ 0.4707,  0.2085,  0.0785]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = batch[\"mask\"]\n",
    "# Lmax = mask.sum(-1).max()\n",
    "# fe = ExtractorV0(dim=256, dim_base=96).cuda()\n",
    "# x = fe(batch, Lmax)\n",
    "# mask = mask[:,:Lmax]\n",
    "# #ptr = torch.cat([torch.zeros(1, dtype=torch.long, device=batch.device), mask.sum(1).cumsum(0)])\n",
    "# x = x[mask]\n",
    "# batch_index = mask.nonzero()[:, 0]\n",
    "# pos = batch['pos'][:,:Lmax][mask]\n",
    "# edge_index = knn_graph(\n",
    "#                 x=pos,\n",
    "#                 k=8,\n",
    "#                 batch=batch_index,\n",
    "#             ).to(mask.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.random.choice([True, False], size=len, p=[0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_mask(100).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
