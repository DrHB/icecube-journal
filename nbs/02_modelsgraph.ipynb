{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp modelsgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-02-13 00:35:47 - get_logger - Writing log to \u001b[1mlogs/graphnet_20230213-003547.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import sys\n",
    "sys.path.append('/opt/slh/archive/software/graphnet/src')\n",
    "import torch\n",
    "from x_transformers import ContinuousTransformerWrapper, Encoder, Decoder\n",
    "from torch import nn\n",
    "from graphnet.models.task.reconstruction import (\n",
    "    DirectionReconstructionWithKappa,\n",
    "    AzimuthReconstructionWithKappa,\n",
    "    ZenithReconstruction,\n",
    ")\n",
    "\n",
    "from graphnet.training.loss_functions import VonMisesFisher3DLoss,  VonMisesFisher2DLoss, EuclideanDistanceLoss\n",
    "from graphnet.models.gnn.gnn import GNN\n",
    "from graphnet.models.utils import calculate_xyzt_homophily\n",
    "from graphnet.utilities.config import save_model_config\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import EdgeConv\n",
    "from torch_geometric.nn.pool import knn_graph\n",
    "from torch_geometric.typing import Adj\n",
    "from torch_scatter import scatter_max, scatter_mean, scatter_min, scatter_sum\n",
    "from typing import Any, Callable, List, Optional, Sequence, Tuple, Union\n",
    "from torch import Tensor, LongTensor\n",
    "from torch_geometric.nn import MessagePassing, global_add_pool, global_mean_pool\n",
    "from torch.nn import Linear, ReLU, SiLU, Sequential\n",
    "from torch_scatter import scatter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys.path.append('/opt/slh/icecube/')\n",
    "from icecube.graphdataset import GraphDasetV0\n",
    "from datasets import  load_from_disk\n",
    "from torch_geometric.loader import DataLoader as gDataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MeanPoolingWithMask(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPoolingWithMask, self).__init__()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # Multiply the mask with the input tensor to zero out the padded values\n",
    "        x = x * mask.unsqueeze(-1)\n",
    "\n",
    "        # Sum the values along the sequence dimension\n",
    "        x = torch.sum(x, dim=1)\n",
    "\n",
    "        # Divide the sum by the number of non-padded values (i.e. the sum of the mask)\n",
    "        x = x / torch.sum(mask, dim=1, keepdim=True)\n",
    "\n",
    "        return x\n",
    "    \n",
    "loss_fn_azi = VonMisesFisher2DLoss()\n",
    "loss_fn_zen = nn.L1Loss()\n",
    "\n",
    "class CombineLossV0(nn.Module):\n",
    "    def __init__(self, loss_fn_azi=loss_fn_azi, loss_fn_zen=loss_fn_zen):\n",
    "        super().__init__()\n",
    "        self.loss_fn_azi = loss_fn_azi\n",
    "        self.loss_fn_zen = loss_fn_zen\n",
    "        \n",
    "    def forward(self, batch, output):\n",
    "        target = batch['label']\n",
    "        azi_pred, zen_pred = output.split(2, 1)\n",
    "        azi_loss = self.loss_fn_azi(azi_pred, target)\n",
    "        zen_loss = self.loss_fn_zen(zen_pred, target[:, -1].unsqueeze(-1))\n",
    "        return azi_loss + zen_loss\n",
    "\n",
    "    \n",
    "class EncoderWithReconstructionLossV0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = ContinuousTransformerWrapper(\n",
    "            dim_in=8,\n",
    "            dim_out=128,\n",
    "            max_seq_len=150,\n",
    "            attn_layers=Encoder(dim=128, depth=6, heads=8),\n",
    "        )\n",
    "\n",
    "        self.pool = MeanPoolingWithMask()\n",
    "        self.az = AzimuthReconstructionWithKappa(\n",
    "            hidden_size=128,\n",
    "            loss_function=loss_fn_azi,\n",
    "            target_labels=[\"azimuth\", \"kappa\"],\n",
    "        )\n",
    "        self.zn =  ZenithReconstruction(\n",
    "            hidden_size=128,\n",
    "            loss_function=loss_fn_zen,\n",
    "            target_labels=[\"zenith\"],\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x, mask = batch['event'], batch['mask']\n",
    "        x = self.encoder(x, mask=mask)\n",
    "        x = self.pool(x, mask)\n",
    "        az = self.az(x)\n",
    "        zn = self.zn(x)\n",
    "        return torch.concat([az, zn], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderWithReconstructionLossV0().eval()\n",
    "event = torch.rand(10, 100, 8)\n",
    "mask = torch.ones(10, 100, dtype=torch.bool)\n",
    "sensor_id = torch.randint(0, 5161, (10, 100))\n",
    "label = torch.rand(10, 2)\n",
    "input = dict(event=event, mask=mask, sensor_id=sensor_id, label=label)\n",
    "with torch.no_grad():\n",
    "    y = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "class EuclideanDistanceLossG(torch.nn.Module):\n",
    "    def __init__(self, eps=1e-6, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, prediction, target):\n",
    "        diff = prediction - target\n",
    "        loss = torch.norm(diff, dim=1) + self.eps\n",
    "        if self.reduction == 'mean':\n",
    "            loss = torch.mean(loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            loss = torch.sum(loss)\n",
    "        return loss\n",
    "\n",
    "class gVonMisesFisher3DLossEcludeLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.vonmis = VonMisesFisher3DLoss()\n",
    "        self.cosine = EuclideanDistanceLossG()\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_true = y_true.reshape(-1, 3)\n",
    "        return (self.vonmis(y_pred, y_true) + self.cosine(y_pred[:, :3], y_true))/2\n",
    "    \n",
    "    \n",
    "class gVonMisesFisher3DLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.vonmis = VonMisesFisher3DLoss()\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_true = y_true.reshape(-1, 3)\n",
    "        return self.vonmis(y_pred, y_true)\n",
    "    \n",
    "class gVonMisesFisher3DLossCosineSimularityLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.vonmis = VonMisesFisher3DLoss()\n",
    "        self.cosine = nn.CosineSimilarity(dim=1, eps=eps)\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_true = y_true.reshape(-1, 3)\n",
    "        return (self.vonmis(y_pred, y_true) + (1-self.cosine(y_pred[:, :3], y_true).mean()))/2\n",
    "    \n",
    "    \n",
    "GLOBAL_POOLINGS = {\n",
    "    \"min\": scatter_min,\n",
    "    \"max\": scatter_max,\n",
    "    \"sum\": scatter_sum,\n",
    "    \"mean\": scatter_mean,\n",
    "}\n",
    "\n",
    "class DynEdgeConv(EdgeConv):\n",
    "    \"\"\"Dynamical edge convolution layer.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        nn: Callable,\n",
    "        aggr: str = \"max\",\n",
    "        nb_neighbors: int = 8,\n",
    "        features_subset: Optional[Union[Sequence[int], slice]] = None,\n",
    "        **kwargs: Any,\n",
    "    ):\n",
    "        \"\"\"Construct `DynEdgeConv`.\n",
    "        Args:\n",
    "            nn: The MLP/torch.Module to be used within the `EdgeConv`.\n",
    "            aggr: Aggregation method to be used with `EdgeConv`.\n",
    "            nb_neighbors: Number of neighbours to be clustered after the\n",
    "                `EdgeConv` operation.\n",
    "            features_subset: Subset of features in `Data.x` that should be used\n",
    "                when dynamically performing the new graph clustering after the\n",
    "                `EdgeConv` operation. Defaults to all features.\n",
    "            **kwargs: Additional features to be passed to `EdgeConv`.\n",
    "        \"\"\"\n",
    "        # Check(s)\n",
    "        if features_subset is None:\n",
    "            features_subset = slice(None)  # Use all features\n",
    "        assert isinstance(features_subset, (list, slice))\n",
    "\n",
    "        # Base class constructor\n",
    "        super().__init__(nn=nn, aggr=aggr, **kwargs)\n",
    "\n",
    "        # Additional member variables\n",
    "        self.nb_neighbors = nb_neighbors\n",
    "        self.features_subset = features_subset\n",
    "\n",
    "    def forward(\n",
    "        self, x: Tensor, edge_index: Adj, batch: Optional[Tensor] = None\n",
    "    ) -> Tensor:\n",
    "\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        # Standard EdgeConv forward pass\n",
    "        x = super().forward(x, edge_index)\n",
    "        dev = x.device\n",
    "\n",
    "        # Recompute adjacency\n",
    "        edge_index = knn_graph(\n",
    "            x=x[:, self.features_subset],\n",
    "            k=self.nb_neighbors,\n",
    "            batch=batch,\n",
    "        ).to(dev)\n",
    "\n",
    "        return x, edge_index\n",
    "\n",
    "\n",
    "class DynEdge(GNN):\n",
    "    \"\"\"DynEdge (dynamical edge convolutional) model.\"\"\"\n",
    "\n",
    "    @save_model_config\n",
    "    def __init__(\n",
    "        self,\n",
    "        nb_inputs: int,\n",
    "        *,\n",
    "        nb_neighbours: int = 8,\n",
    "        features_subset: Optional[Union[List[int], slice]] = None,\n",
    "        dynedge_layer_sizes: Optional[List[Tuple[int, ...]]] = None,\n",
    "        post_processing_layer_sizes: Optional[List[int]] = None,\n",
    "        readout_layer_sizes: Optional[List[int]] = None,\n",
    "        global_pooling_schemes: Optional[Union[str, List[str]]] = None,\n",
    "        add_global_variables_after_pooling: bool = False,\n",
    "    ):\n",
    "        \"\"\"Construct `DynEdge`.\n",
    "        Args:\n",
    "            nb_inputs: Number of input features on each node.\n",
    "            nb_neighbours: Number of neighbours to used in the k-nearest\n",
    "                neighbour clustering which is performed after each (dynamical)\n",
    "                edge convolution.\n",
    "            features_subset: The subset of latent features on each node that\n",
    "                are used as metric dimensions when performing the k-nearest\n",
    "                neighbours clustering. Defaults to [0,1,2].\n",
    "            dynedge_layer_sizes: The layer sizes, or latent feature dimenions,\n",
    "                used in the `DynEdgeConv` layer. Each entry in\n",
    "                `dynedge_layer_sizes` corresponds to a single `DynEdgeConv`\n",
    "                layer; the integers in the corresponding tuple corresponds to\n",
    "                the layer sizes in the multi-layer perceptron (MLP) that is\n",
    "                applied within each `DynEdgeConv` layer. That is, a list of\n",
    "                size-two tuples means that all `DynEdgeConv` layers contain a\n",
    "                two-layer MLP.\n",
    "                Defaults to [(128, 256), (336, 256), (336, 256), (336, 256)].\n",
    "            post_processing_layer_sizes: Hidden layer sizes in the MLP\n",
    "                following the skip-concatenation of the outputs of each\n",
    "                `DynEdgeConv` layer. Defaults to [336, 256].\n",
    "            readout_layer_sizes: Hidden layer sizes in the MLP following the\n",
    "                post-processing _and_ optional global pooling. As this is the\n",
    "                last layer(s) in the model, the last layer in the read-out\n",
    "                yields the output of the `DynEdge` model. Defaults to [128,].\n",
    "            global_pooling_schemes: The list global pooling schemes to use.\n",
    "                Options are: \"min\", \"max\", \"mean\", and \"sum\".\n",
    "            add_global_variables_after_pooling: Whether to add global variables\n",
    "                after global pooling. The alternative is to  added (distribute)\n",
    "                them to the individual nodes before any convolutional\n",
    "                operations.\n",
    "        \"\"\"\n",
    "        # Latent feature subset for computing nearest neighbours in DynEdge.\n",
    "        if features_subset is None:\n",
    "            features_subset = slice(0, 3)\n",
    "\n",
    "        # DynEdge layer sizes\n",
    "        if dynedge_layer_sizes is None:\n",
    "            dynedge_layer_sizes = [\n",
    "                (\n",
    "                    128,\n",
    "                    256,\n",
    "                ),\n",
    "                (\n",
    "                    336,\n",
    "                    256,\n",
    "                ),\n",
    "                (\n",
    "                    336,\n",
    "                    256,\n",
    "                ),\n",
    "                (\n",
    "                    336,\n",
    "                    256,\n",
    "                ),\n",
    "            ]\n",
    "\n",
    "        assert isinstance(dynedge_layer_sizes, list)\n",
    "        assert len(dynedge_layer_sizes)\n",
    "        assert all(isinstance(sizes, tuple) for sizes in dynedge_layer_sizes)\n",
    "        assert all(len(sizes) > 0 for sizes in dynedge_layer_sizes)\n",
    "        assert all(all(size > 0 for size in sizes) for sizes in dynedge_layer_sizes)\n",
    "\n",
    "        self._dynedge_layer_sizes = dynedge_layer_sizes\n",
    "\n",
    "        # Post-processing layer sizes\n",
    "        if post_processing_layer_sizes is None:\n",
    "            post_processing_layer_sizes = [\n",
    "                336,\n",
    "                256,\n",
    "            ]\n",
    "\n",
    "        assert isinstance(post_processing_layer_sizes, list)\n",
    "        assert len(post_processing_layer_sizes)\n",
    "        assert all(size > 0 for size in post_processing_layer_sizes)\n",
    "\n",
    "        self._post_processing_layer_sizes = post_processing_layer_sizes\n",
    "\n",
    "        # Read-out layer sizes\n",
    "        if readout_layer_sizes is None:\n",
    "            readout_layer_sizes = [\n",
    "                128,\n",
    "            ]\n",
    "\n",
    "        assert isinstance(readout_layer_sizes, list)\n",
    "        assert len(readout_layer_sizes)\n",
    "        assert all(size > 0 for size in readout_layer_sizes)\n",
    "\n",
    "        self._readout_layer_sizes = readout_layer_sizes\n",
    "\n",
    "        # Global pooling scheme(s)\n",
    "        if isinstance(global_pooling_schemes, str):\n",
    "            global_pooling_schemes = [global_pooling_schemes]\n",
    "\n",
    "        if isinstance(global_pooling_schemes, list):\n",
    "            for pooling_scheme in global_pooling_schemes:\n",
    "                assert (\n",
    "                    pooling_scheme in GLOBAL_POOLINGS\n",
    "                ), f\"Global pooling scheme {pooling_scheme} not supported.\"\n",
    "        else:\n",
    "            assert global_pooling_schemes is None\n",
    "\n",
    "        self._global_pooling_schemes = global_pooling_schemes\n",
    "\n",
    "        if add_global_variables_after_pooling:\n",
    "            assert self._global_pooling_schemes, (\n",
    "                \"No global pooling schemes were request, so cannot add global\"\n",
    "                \" variables after pooling.\"\n",
    "            )\n",
    "        self._add_global_variables_after_pooling = add_global_variables_after_pooling\n",
    "\n",
    "        # Base class constructor\n",
    "        super().__init__(nb_inputs, self._readout_layer_sizes[-1])\n",
    "\n",
    "        # Remaining member variables()\n",
    "        self._activation = torch.nn.GELU()\n",
    "        self._nb_inputs = nb_inputs\n",
    "        self._nb_global_variables = 5 + nb_inputs\n",
    "        self._nb_neighbours = nb_neighbours\n",
    "        self._features_subset = features_subset\n",
    "\n",
    "        self._construct_layers()\n",
    "\n",
    "    def _construct_layers(self) -> None:\n",
    "        \"\"\"Construct layers (torch.nn.Modules).\"\"\"\n",
    "        # Convolutional operations\n",
    "        nb_input_features = self._nb_inputs\n",
    "        if not self._add_global_variables_after_pooling:\n",
    "            nb_input_features += self._nb_global_variables\n",
    "\n",
    "        self._conv_layers = torch.nn.ModuleList()\n",
    "        nb_latent_features = nb_input_features\n",
    "        for sizes in self._dynedge_layer_sizes:\n",
    "            layers = []\n",
    "            layer_sizes = [nb_latent_features] + list(sizes)\n",
    "            for ix, (nb_in, nb_out) in enumerate(\n",
    "                zip(layer_sizes[:-1], layer_sizes[1:])\n",
    "            ):\n",
    "                if ix == 0:\n",
    "                    nb_in *= 2\n",
    "                layers.append(torch.nn.Linear(nb_in, nb_out))\n",
    "                layers.append(nn.BatchNorm1d(nb_out))\n",
    "                layers.append(self._activation)\n",
    "\n",
    "            conv_layer = DynEdgeConv(\n",
    "                torch.nn.Sequential(*layers),\n",
    "                aggr=\"add\",\n",
    "                nb_neighbors=self._nb_neighbours,\n",
    "                features_subset=self._features_subset,\n",
    "            )\n",
    "            self._conv_layers.append(conv_layer)\n",
    "\n",
    "            nb_latent_features = nb_out\n",
    "\n",
    "        # Post-processing operations\n",
    "        nb_latent_features = (\n",
    "            sum(sizes[-1] for sizes in self._dynedge_layer_sizes) + nb_input_features\n",
    "        )\n",
    "\n",
    "        post_processing_layers = []\n",
    "        layer_sizes = [nb_latent_features] + list(self._post_processing_layer_sizes)\n",
    "        for nb_in, nb_out in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "            post_processing_layers.append(torch.nn.Linear(nb_in, nb_out))\n",
    "            post_processing_layers.append(nn.BatchNorm1d(nb_out))\n",
    "            post_processing_layers.append(self._activation)\n",
    "\n",
    "        self._post_processing = torch.nn.Sequential(*post_processing_layers)\n",
    "\n",
    "        # Read-out operations\n",
    "        nb_poolings = (\n",
    "            len(self._global_pooling_schemes) if self._global_pooling_schemes else 1\n",
    "        )\n",
    "        nb_latent_features = nb_out * nb_poolings\n",
    "        if self._add_global_variables_after_pooling:\n",
    "            nb_latent_features += self._nb_global_variables\n",
    "\n",
    "        readout_layers = []\n",
    "        layer_sizes = [nb_latent_features] + list(self._readout_layer_sizes)\n",
    "        for nb_in, nb_out in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "            readout_layers.append(torch.nn.Linear(nb_in, nb_out))\n",
    "            readout_layers.append(nn.BatchNorm1d(nb_out))\n",
    "            readout_layers.append(self._activation)\n",
    "\n",
    "        self._readout = torch.nn.Sequential(*readout_layers)\n",
    "\n",
    "    def _global_pooling(self, x: Tensor, batch: LongTensor) -> Tensor:\n",
    "        \"\"\"Perform global pooling.\"\"\"\n",
    "        assert self._global_pooling_schemes\n",
    "        pooled = []\n",
    "        for pooling_scheme in self._global_pooling_schemes:\n",
    "            pooling_fn = GLOBAL_POOLINGS[pooling_scheme]\n",
    "            pooled_x = pooling_fn(x, index=batch, dim=0)\n",
    "            if isinstance(pooled_x, tuple) and len(pooled_x) == 2:\n",
    "                # `scatter_{min,max}`, which return also an argument, vs.\n",
    "                # `scatter_{mean,sum}`\n",
    "                pooled_x, _ = pooled_x\n",
    "            pooled.append(pooled_x)\n",
    "\n",
    "        return torch.cat(pooled, dim=1)\n",
    "\n",
    "    def _calculate_global_variables(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        edge_index: LongTensor,\n",
    "        batch: LongTensor,\n",
    "        *additional_attributes: Tensor,\n",
    "    ) -> Tensor:\n",
    "        \"\"\"Calculate global variables.\"\"\"\n",
    "        # Calculate homophily (scalar variables)\n",
    "        h_x, h_y, h_z, h_t = calculate_xyzt_homophily(x, edge_index, batch)\n",
    "\n",
    "        # Calculate mean features\n",
    "        global_means = scatter_mean(x, batch, dim=0)\n",
    "\n",
    "        # Add global variables\n",
    "        global_variables = torch.cat(\n",
    "            [\n",
    "                global_means,\n",
    "                h_x,\n",
    "                h_y,\n",
    "                h_z,\n",
    "                h_t,\n",
    "            ]\n",
    "            + [attr.unsqueeze(dim=1) for attr in additional_attributes],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        return global_variables\n",
    "\n",
    "    def forward(self, data: Data) -> Tensor:\n",
    "        \"\"\"Apply learnable forward pass.\"\"\"\n",
    "        # Convenience variables\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        global_variables = self._calculate_global_variables(\n",
    "            x,\n",
    "            edge_index,\n",
    "            batch,\n",
    "            torch.log10(data.n_pulses),\n",
    "        )\n",
    "\n",
    "        # Distribute global variables out to each node\n",
    "        if not self._add_global_variables_after_pooling:\n",
    "            distribute = (\n",
    "                batch.unsqueeze(dim=1) == torch.unique(batch).unsqueeze(dim=0)\n",
    "            ).type(torch.float)\n",
    "\n",
    "            global_variables_distributed = torch.sum(\n",
    "                distribute.unsqueeze(dim=2) * global_variables.unsqueeze(dim=0),\n",
    "                dim=1,\n",
    "            )\n",
    "\n",
    "            x = torch.cat((x, global_variables_distributed), dim=1)\n",
    "\n",
    "        # DynEdge-convolutions\n",
    "        skip_connections = [x]\n",
    "        for conv_layer in self._conv_layers:\n",
    "            x, edge_index = conv_layer(x, edge_index, batch)\n",
    "            skip_connections.append(x)\n",
    "\n",
    "        # Skip-cat\n",
    "        x = torch.cat(skip_connections, dim=1)\n",
    "\n",
    "        # Post-processing\n",
    "        x = self._post_processing(x)\n",
    "\n",
    "        # (Optional) Global pooling\n",
    "        if self._global_pooling_schemes:\n",
    "            x = self._global_pooling(x, batch=batch)\n",
    "            if self._add_global_variables_after_pooling:\n",
    "                x = torch.cat(\n",
    "                    [\n",
    "                        x,\n",
    "                        global_variables,\n",
    "                    ],\n",
    "                    dim=1,\n",
    "                )\n",
    "\n",
    "        # Read-out\n",
    "        x = self._readout(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class DynEdgeV0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = DynEdge(\n",
    "            nb_inputs=9,\n",
    "            nb_neighbours=8,\n",
    "            global_pooling_schemes=[\"min\", \"max\", \"mean\", \"sum\"],\n",
    "            features_subset=slice(0, 4),  # NN search using xyzt\n",
    "        )\n",
    "\n",
    "        self.out = DirectionReconstructionWithKappa(\n",
    "            hidden_size=self.encoder.nb_outputs,\n",
    "            target_labels='direction',\n",
    "            loss_function=VonMisesFisher3DLoss(),\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x = self.encoder(batch)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "class DynEdgeV1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = DynEdge(\n",
    "            nb_inputs=9,\n",
    "            nb_neighbours=8,\n",
    "            global_pooling_schemes=[\"min\", \"max\", \"mean\", \"sum\"],\n",
    "            features_subset=slice(0, 3),  # NN search using xyz3\n",
    "        )\n",
    "\n",
    "        self.out = DirectionReconstructionWithKappa(\n",
    "            hidden_size=self.encoder.nb_outputs,\n",
    "            target_labels='direction',\n",
    "            loss_function=VonMisesFisher3DLoss(),\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x = self.encoder(batch)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class EGNNLayer(MessagePassing):\n",
    "    def __init__(self, emb_dim, activation=\"relu\", norm=\"layer\", aggr=\"add\"):\n",
    "        \"\"\"E(n) Equivariant GNN Layer\n",
    "        Paper: E(n) Equivariant Graph Neural Networks, Satorras et al.\n",
    "        \n",
    "        Args:\n",
    "            emb_dim: (int) - hidden dimension `d`\n",
    "            activation: (str) - non-linearity within MLPs (swish/relu)\n",
    "            norm: (str) - normalisation layer (layer/batch)\n",
    "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
    "        \"\"\"\n",
    "        # Set the aggregation function\n",
    "        super().__init__(aggr=aggr)\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.activation = {\"swish\": SiLU(), \"relu\": ReLU()}[activation]\n",
    "        self.norm = {\"layer\": torch.nn.LayerNorm, \"batch\": torch.nn.BatchNorm1d}[norm]\n",
    "\n",
    "        # MLP `\\psi_h` for computing messages `m_ij`\n",
    "        self.mlp_msg = Sequential(\n",
    "            Linear(2 * emb_dim + 1, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "            Linear(emb_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "        )\n",
    "        # MLP `\\psi_x` for computing messages `\\overrightarrow{m}_ij`\n",
    "        self.mlp_pos = Sequential(\n",
    "            Linear(emb_dim, emb_dim), self.norm(emb_dim), self.activation, Linear(emb_dim, 1)\n",
    "        )\n",
    "        # MLP `\\phi` for computing updated node features `h_i^{l+1}`\n",
    "        self.mlp_upd = Sequential(\n",
    "            Linear(2 * emb_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "            Linear(emb_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "        )\n",
    "\n",
    "    def forward(self, h, pos, edge_index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            h: (n, d) - initial node features\n",
    "            pos: (n, 3) - initial node coordinates\n",
    "            edge_index: (e, 2) - pairs of edges (i, j)\n",
    "        Returns:\n",
    "            out: [(n, d),(n,3)] - updated node features\n",
    "        \"\"\"\n",
    "        out = self.propagate(edge_index, h=h, pos=pos)\n",
    "        return out\n",
    "\n",
    "    def message(self, h_i, h_j, pos_i, pos_j):\n",
    "        # Compute messages\n",
    "        pos_diff = pos_i - pos_j\n",
    "        dists = torch.norm(pos_diff, dim=-1).unsqueeze(1)\n",
    "        msg = torch.cat([h_i, h_j, dists], dim=-1)\n",
    "        msg = self.mlp_msg(msg)\n",
    "        # Scale magnitude of displacement vector\n",
    "        pos_diff = pos_diff * self.mlp_pos(msg)  # torch.clamp(updates, min=-100, max=100)\n",
    "        return msg, pos_diff\n",
    "\n",
    "    def aggregate(self, inputs, index):\n",
    "        msgs, pos_diffs = inputs\n",
    "        # Aggregate messages\n",
    "        msg_aggr = scatter(msgs, index, dim=self.node_dim, reduce=self.aggr)\n",
    "        # Aggregate displacement vectors\n",
    "        pos_aggr = scatter(pos_diffs, index, dim=self.node_dim, reduce=\"mean\")\n",
    "        return msg_aggr, pos_aggr\n",
    "\n",
    "    def update(self, aggr_out, h, pos):\n",
    "        msg_aggr, pos_aggr = aggr_out\n",
    "        upd_out = self.mlp_upd(torch.cat([h, msg_aggr], dim=-1))\n",
    "        upd_pos = pos + pos_aggr\n",
    "        return upd_out, upd_pos\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})\"\n",
    "    \n",
    "    \n",
    "class EGNNModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers=5,\n",
    "        emb_dim=128,\n",
    "        in_dim=9,\n",
    "        activation=\"relu\",\n",
    "        norm=\"layer\",\n",
    "        aggr=\"sum\",\n",
    "        pool=\"sum\",\n",
    "        residual=True\n",
    "    ):\n",
    "        \"\"\"E(n) Equivariant GNN model \n",
    "        \n",
    "        Args:\n",
    "            num_layers: (int) - number of message passing layers\n",
    "            emb_dim: (int) - hidden dimension\n",
    "            in_dim: (int) - initial node feature dimension\n",
    "            out_dim: (int) - output number of classes\n",
    "            activation: (str) - non-linearity within MLPs (swish/relu)\n",
    "            norm: (str) - normalisation layer (layer/batch)\n",
    "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
    "            pool: (str) - global pooling function (sum/mean)\n",
    "            residual: (bool) - whether to use residual connections\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding lookup for initial node features\n",
    "        self.emb_in = nn.Linear(in_dim, emb_dim)\n",
    "\n",
    "        # Stack of GNN layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.convs.append(EGNNLayer(emb_dim, activation, norm, aggr))\n",
    "\n",
    "        # Global pooling/readout function\n",
    "        self.pool = {\"mean\": global_mean_pool, \"sum\": global_add_pool}[pool]\n",
    "\n",
    "        # Predictor MLP\n",
    "        self.postpool = torch.nn.Sequential(\n",
    "            torch.nn.Linear(emb_dim, emb_dim),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.out = DirectionReconstructionWithKappa(\n",
    "            hidden_size=emb_dim,\n",
    "            target_labels='direction',\n",
    "            loss_function=VonMisesFisher3DLoss(),\n",
    "        )\n",
    "\n",
    "        self.residual = residual\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \n",
    "        h = self.emb_in(batch.x)  # (n,) -> (n, d)\n",
    "        pos = batch.pos  # (n, 3)\n",
    "\n",
    "        for conv in self.convs:\n",
    "            # Message passing layer\n",
    "            h_update, pos_update = conv(h, pos, batch.edge_index)\n",
    "\n",
    "            # Update node features (n, d) -> (n, d)\n",
    "            h = h + h_update if self.residual else h_update \n",
    "\n",
    "            # Update node coordinates (no residual) (n, 3) -> (n, 3)\n",
    "            pos = pos_update\n",
    "\n",
    "        out = self.pool(h, batch.batch)  # (n, d) -> (batch_size, d)\n",
    "        out = self.postpool(out) \n",
    "        out = self.out(out)  # (batch_size, d) -> (batch_size, 1)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py:1536: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "model = EGNNModel().eval()\n",
    "ds = GraphDasetV0(load_from_disk('/opt/slh/icecube/data/hf_cashe/batch_1.parquet'))\n",
    "dl = gDataLoader(ds, batch_size=10, shuffle=False)\n",
    "batch = next(iter(dl))\n",
    "with torch.no_grad():\n",
    "    out = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EGNNModel(\n",
       "  (emb_in): Linear(in_features=9, out_features=128, bias=True)\n",
       "  (convs): ModuleList(\n",
       "    (0): EGNNLayer(emb_dim=128, aggr=sum)\n",
       "    (1): EGNNLayer(emb_dim=128, aggr=sum)\n",
       "    (2): EGNNLayer(emb_dim=128, aggr=sum)\n",
       "    (3): EGNNLayer(emb_dim=128, aggr=sum)\n",
       "    (4): EGNNLayer(emb_dim=128, aggr=sum)\n",
       "  )\n",
       "  (postpool): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (out): DirectionReconstructionWithKappa(\n",
       "    (_loss_function): VonMisesFisher3DLoss()\n",
       "    (_affine): Linear(in_features=128, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
