{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp modelsgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-02-05 15:47:09 - get_logger - Writing log to \u001b[1mlogs/graphnet_20230205-154709.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import sys\n",
    "sys.path.append('/opt/slh/graphnet-main/src')\n",
    "import torch\n",
    "from x_transformers import ContinuousTransformerWrapper, Encoder, Decoder\n",
    "from torch import nn\n",
    "from graphnet.training.loss_functions import VonMisesFisher2DLoss\n",
    "from graphnet.models.task.reconstruction import (\n",
    "    AzimuthReconstructionWithKappa,\n",
    "    ZenithReconstruction,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDA.ipynb  graphnet-main  leetcode.ipynb  packages\n",
      "geom\t   icecube\t  logs\t\t  test.py\n"
     ]
    }
   ],
   "source": [
    "!ls ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MeanPoolingWithMask(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPoolingWithMask, self).__init__()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # Multiply the mask with the input tensor to zero out the padded values\n",
    "        x = x * mask.unsqueeze(-1)\n",
    "\n",
    "        # Sum the values along the sequence dimension\n",
    "        x = torch.sum(x, dim=1)\n",
    "\n",
    "        # Divide the sum by the number of non-padded values (i.e. the sum of the mask)\n",
    "        x = x / torch.sum(mask, dim=1, keepdim=True)\n",
    "\n",
    "        return x\n",
    "    \n",
    "loss_fn_azi = VonMisesFisher2DLoss()\n",
    "loss_fn_zen = nn.L1Loss()\n",
    "\n",
    "class CombineLossV0(nn.Module):\n",
    "    def __init__(self, loss_fn_azi=loss_fn_azi, loss_fn_zen=loss_fn_zen):\n",
    "        super().__init__()\n",
    "        self.loss_fn_azi = loss_fn_azi\n",
    "        self.loss_fn_zen = loss_fn_zen\n",
    "        \n",
    "    def forward(self, batch, output):\n",
    "        target = batch['label']\n",
    "        azi_pred, zen_pred = output.split(2, 1)\n",
    "        azi_loss = self.loss_fn_azi(azi_pred, target)\n",
    "        zen_loss = self.loss_fn_zen(zen_pred, target[:, -1].unsqueeze(-1))\n",
    "        return azi_loss + zen_loss\n",
    "\n",
    "    \n",
    "class EncoderWithReconstructionLossV0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = ContinuousTransformerWrapper(\n",
    "            dim_in=8,\n",
    "            dim_out=128,\n",
    "            max_seq_len=150,\n",
    "            attn_layers=Encoder(dim=128, depth=6, heads=8),\n",
    "        )\n",
    "\n",
    "        self.pool = MeanPoolingWithMask()\n",
    "        self.az = AzimuthReconstructionWithKappa(\n",
    "            hidden_size=128,\n",
    "            loss_function=loss_fn_azi,\n",
    "            target_labels=[\"azimuth\", \"kappa\"],\n",
    "        )\n",
    "        self.zn =  ZenithReconstruction(\n",
    "            hidden_size=128,\n",
    "            loss_function=loss_fn_zen,\n",
    "            target_labels=[\"zenith\"],\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x, mask = batch['event'], batch['mask']\n",
    "        x = self.encoder(x, mask=mask)\n",
    "        x = self.pool(x, mask)\n",
    "        az = self.az(x)\n",
    "        zn = self.zn(x)\n",
    "        return torch.concat([az, zn], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderWithReconstructionLossV0().eval()\n",
    "event = torch.rand(10, 100, 8)\n",
    "mask = torch.ones(10, 100, dtype=torch.bool)\n",
    "sensor_id = torch.randint(0, 5161, (10, 100))\n",
    "label = torch.rand(10, 2)\n",
    "input = dict(event=event, mask=mask, sensor_id=sensor_id, label=label)\n",
    "with torch.no_grad():\n",
    "    y = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5121)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CombineLossV0()(input, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
