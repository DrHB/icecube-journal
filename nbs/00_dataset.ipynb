{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from datasets import  load_from_disk\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import sys\n",
    "sys.path.append('/opt/slh/icecube/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb import set_trace\n",
    "import seaborn as sns\n",
    "class CFG:\n",
    "    CACHE_PATH = Path('../data/cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = list((CFG.CACHE_PATH/'batch_3').glob('*.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# function that loads the data from the pth file and return the data and the label as pd.DataFrame\n",
    "def load_data(\n",
    "    fn: Path,\n",
    "    columns_event: str = [\"time\", \"charge\", \"auxiliary\", \"x\", \"y\", \"z\"],\n",
    "    columns_label: str = [\"azimuth\", \"zenith\"],\n",
    "    keep_auxiliary_event: bool = False,\n",
    "):\n",
    "    data = torch.load(fn)\n",
    "    event = pd.DataFrame.from_records(data[\"event\"])[columns_event]\n",
    "    if keep_auxiliary_event:\n",
    "        event = event.query(\"auxiliary == True\")\n",
    "    label = pd.DataFrame.from_records(data[\"target\"])[columns_label]\n",
    "    return event.astype(np.float32), label\n",
    "\n",
    "\n",
    "class IceCubeCasheDatasetV0(Dataset):\n",
    "    def __init__(self, fns, max_events=100):\n",
    "        self.fns = fns\n",
    "        self.max_events = max_events\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fn = self.fns[idx]\n",
    "        event, label = load_data(fn)\n",
    "\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = torch.tensor(event.values)\n",
    "        mask = torch.ones(len(event), dtype=torch.bool)\n",
    "        label = torch.tensor(label.values, dtype=torch.float32)\n",
    "\n",
    "        return {\"event\": event, \"mask\": mask, \"label\": label}\n",
    "\n",
    "\n",
    "class IceCubeCasheDatasetV1(Dataset):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        Dataset (_type_): Same as IceCubeCasheDatasetV0 but with the option to keep the auxiliary events\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fns, max_events=100, keep_auxiliary_event: bool = True):\n",
    "        self.fns = fns\n",
    "        self.max_events = max_events\n",
    "        self.keep_auxiliary_event = keep_auxiliary_event\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fn = self.fns[idx]\n",
    "        event, label = load_data(fn, keep_auxiliary_event=self.keep_auxiliary_event)\n",
    "\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = torch.tensor(event.values)\n",
    "        mask = torch.ones(len(event), dtype=torch.bool)\n",
    "        label = torch.tensor(label.values, dtype=torch.float32)\n",
    "\n",
    "        return {\"event\": event, \"mask\": mask, \"label\": label}\n",
    "\n",
    "\n",
    "# collate_fn that pads the event and mask to the max length in the batch using pythorch pad_sequence\n",
    "class HuggingFaceDatasetV0(Dataset):\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = event.values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "# function to normalize input between 1 and 0\n",
    "def normalize(x):\n",
    "    return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV1(Dataset):\n",
    "    \"\"\"\n",
    "    Same as HuggingFaceDatasetV0 but returns sensor_id as well\n",
    "    in addition it adds + 1 to make the sensor_id start from 1 instead of 0,\n",
    "    0 is ignore index\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        # this is done in order to shift sensor id from 0 to 1\n",
    "        # since paddding index is 0\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "\n",
    "        # feature engineering\n",
    "        event[\"w1\"] = event[\"charge\"] * event[\"time\"]\n",
    "        event[\"w0\"] = event[\"charge\"] - event[\"w1\"]\n",
    "\n",
    "        event[\"wx0\"] = event.x * event.w0\n",
    "        event[\"wy0\"] = event.y * event.w0\n",
    "        event[\"wz0\"] = event.z * event.w0\n",
    "        event[\"wx1\"] = event.x * event.w1\n",
    "        event[\"wy1\"] = event.y * event.w1\n",
    "        event[\"wz1\"] = event.z * event.w1\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"w1\",\n",
    "                \"w0\",\n",
    "                \"wx0\",\n",
    "                \"wy0\",\n",
    "                \"wz0\",\n",
    "                \"wx1\",\n",
    "                \"wy1\",\n",
    "                \"wz1\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV2(Dataset):\n",
    "    \"\"\"\n",
    "    Same as HuggingFaceDatasetV0 but returns sensor_id as well\n",
    "    in addition it adds + 1 to make the sensor_id start from 1 instead of 0,\n",
    "    0 is ignore index\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        # this is done in order to shift sensor id from 0 to 1\n",
    "        # since paddding index is 0\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV3(Dataset):\n",
    "    \"\"\"\n",
    "    Same as HuggingFaceDatasetV0 but returns sensor_id as well\n",
    "    in addition it adds + 1 to make the sensor_id start from 1 instead of 0,\n",
    "    0 is ignore index\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        # this is done in order to shift sensor id from 0 to 1\n",
    "        # since paddding index is 0\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "class HuggingFaceDatasetV4(Dataset):\n",
    "    \"\"\"\n",
    "    Same as HuggingFaceDatasetV0 but returns sensor_id as well\n",
    "    in addition it adds + 1 to make the sensor_id start from 1 instead of 0,\n",
    "    0 is ignore index\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=160):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        # this is done in order to shift sensor id from 0 to 1\n",
    "        # since paddding index is 0\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "def event_filtering_v1(batch, max_pulse_count=128, t_valid_length=6199.700247193777):\n",
    "    col = batch.columns\n",
    "    t_peak = batch[\"time\"][batch[\"charge\"].argmax()]\n",
    "    t_valid_min = t_peak - t_valid_length\n",
    "    t_valid_max = t_peak + t_valid_length\n",
    "    t_valid = (batch[\"time\"] > t_valid_min) * (batch[\"time\"] < t_valid_max)\n",
    "    batch[\"rank\"] = 2 * (1 - batch[\"auxiliary\"]) + (t_valid)\n",
    "    batch = batch.sort_values(by=[\"rank\", \"charge\"])\n",
    "    # pick-up from backward\n",
    "    batch = batch[-max_pulse_count:]\n",
    "        # resort by time\n",
    "    batch = batch.sort_values(by=\"time\")\n",
    "    return batch[col]\n",
    "\n",
    "def event_filtering_v2(batch, max_pulse_count=128, t_valid_length=6199.700247193777):\n",
    "    \"same as v1 but we add rank column to every entry and sort only if lenth is more then max_pulse_count\"\n",
    "    t_peak = batch[\"time\"][batch[\"charge\"].argmax()]\n",
    "    t_valid_min = t_peak - t_valid_length\n",
    "    t_valid_max = t_peak + t_valid_length\n",
    "    t_valid = (batch[\"time\"] > t_valid_min) * (batch[\"time\"] < t_valid_max)\n",
    "    batch[\"rank\"] = 2 * (1 - batch[\"auxiliary\"]) + (t_valid)\n",
    "    if batch.shape[0] > max_pulse_count:\n",
    "        batch = batch.sort_values(by=[\"rank\", \"charge\"])\n",
    "        # pick-up from backward\n",
    "        batch = batch[-max_pulse_count:]\n",
    "            # resort by time\n",
    "        batch = batch.sort_values(by=\"time\")\n",
    "    return batch\n",
    "        \n",
    "        \n",
    "\n",
    "class HuggingFaceDatasetV5(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        \n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = IceCubeCasheDatasetV1(fns)\n",
    "#dl = DataLoader(ds, batch_size=64, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "# for x in dl:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = HuggingFaceDatasetV5(load_from_disk('/opt/slh/icecube/data/hf_cashe/batch_1.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ice_transparency(\n",
    "    data_path=\"/opt/slh/icecube/data/ice_transparency.txt\", datum=1950\n",
    "):\n",
    "    # Data from page 31 of https://arxiv.org/pdf/1301.5361.pdf\n",
    "    # Datum is from footnote 8 of page 29\n",
    "    df = pd.read_csv(data_path, delim_whitespace=True)\n",
    "    df[\"z\"] = df[\"depth\"] - datum\n",
    "    df[\"z_norm\"] = df[\"z\"] / 500\n",
    "    df[[\"scattering_len_norm\", \"absorption_len_norm\"]] = RobustScaler().fit_transform(\n",
    "        df[[\"scattering_len\", \"absorption_len\"]]\n",
    "    )\n",
    "\n",
    "    # These are both roughly equivalent after scaling\n",
    "    f_scattering = interp1d(df[\"z_norm\"], df[\"scattering_len_norm\"])\n",
    "    f_absorption = interp1d(df[\"z_norm\"], df[\"absorption_len_norm\"])\n",
    "    return f_scattering, f_absorption\n",
    "\n",
    "def prepare_sensors():\n",
    "    sensors = pd.read_csv('/opt/slh/icecube/data/sensor_geometry.csv').astype(\n",
    "        {\n",
    "            \"sensor_id\": np.int16,\n",
    "            \"x\": np.float32,\n",
    "            \"y\": np.float32,\n",
    "            \"z\": np.float32,\n",
    "        }\n",
    "    )\n",
    "    sensors[\"string\"] = 0\n",
    "    sensors[\"qe\"] = 1\n",
    "\n",
    "    for i in range(len(sensors) // 60):\n",
    "        start, end = i * 60, (i * 60) + 60\n",
    "        sensors.loc[start:end, \"string\"] = i\n",
    "\n",
    "        # High Quantum Efficiency in the lower 50 DOMs - https://arxiv.org/pdf/2209.03042.pdf (Figure 1)\n",
    "        if i in range(78, 86):\n",
    "            start_veto, end_veto = i * 60, (i * 60) + 10\n",
    "            start_core, end_core = end_veto + 1, (i * 60) + 60\n",
    "            sensors.loc[start_core:end_core, \"qe\"] = 1.35\n",
    "\n",
    "    # https://github.com/graphnet-team/graphnet/blob/b2bad25528652587ab0cdb7cf2335ee254cfa2db/src/graphnet/models/detector/icecube.py#L33-L41\n",
    "    # Assume that \"rde\" (relative dom efficiency) is equivalent to QE\n",
    "    sensors[\"x\"] /= 500\n",
    "    sensors[\"y\"] /= 500\n",
    "    sensors[\"z\"] /= 500\n",
    "    sensors[\"qe\"] -= 1.25\n",
    "    sensors[\"qe\"] /= 0.25\n",
    "\n",
    "    return sensors.set_index(\"sensor_id\")[['qe']]\n",
    "\n",
    "\n",
    "def convert_to_3d(azimuth, zenith):\n",
    "    \"\"\"Converts zenith and azimuth to 3D direction vectors\"\"\"\n",
    "    x = np.cos(azimuth) * np.sin(zenith)\n",
    "    y = np.sin(azimuth) * np.sin(zenith)\n",
    "    z = np.cos(zenith)\n",
    "    return np.array([x, y, z], dtype=np.float32)\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV6(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV7(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV8(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=148):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV9(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event[\"absorption\"] = self.f_absorption(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "                \"absorption\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "    \n",
    "class HuggingFaceDatasetV10(Dataset):\n",
    "    \"\"\"\n",
    "    same as V9 but with 148 \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=148):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event[\"absorption\"] = self.f_absorption(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "                \"absorption\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "    \n",
    "class HuggingFaceDatasetV11(Dataset):\n",
    "    \"\"\"\n",
    "    same as V9 but with added sensoor ids \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event[\"absorption\"] = self.f_absorption(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "                \"absorption\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "class HuggingFaceDatasetV12(Dataset):\n",
    "    \"\"\"\n",
    "    same as V9 but with added sensoor ids , same as V11 but with 160 `max_len`\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=160):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event[\"absorption\"] = self.f_absorption(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "                \"absorption\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "    \n",
    "    \n",
    "class HuggingFaceDatasetV13(Dataset):\n",
    "    \"\"\"\n",
    "    same as V9 but with added sensoor ids , same as V11 but with 196 `max_len`\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=196):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event[\"absorption\"] = self.f_absorption(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "                \"absorption\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "    \n",
    "    \n",
    "class HuggingFaceDatasetV14(Dataset):\n",
    "    \"\"\"\n",
    "    same as V9 but with 148, returning qe and aux as long tesnors \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=148):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "\n",
    "        event = event_filtering_v2(event, max_pulse_count=self.max_events)\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event[\"absorption\"] = self.f_absorption(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] =  self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\" : torch.tensor(event[[\"x\", \"y\", \"z\", \"time\", \"charge\", \"scattering\", \"absorption\"]].values, dtype=torch.float32),\n",
    "                \"rank\": torch.tensor(event['rank'].values, dtype=torch.long),\n",
    "                \"qe\": torch.tensor(event['qe'].values + 1, dtype=torch.long),\n",
    "                \"aux\": torch.tensor(event['auxiliary'].values, dtype=torch.long,),\n",
    "                \"label\": torch.tensor(label),\n",
    "                \"mask\": torch.tensor(mask)\n",
    "            }\n",
    "        )\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = HuggingFaceDatasetV14(load_from_disk('/opt/slh/icecube/data/hf_cashe/batch_1.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from icecube.utils import collate_fn_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "# pytorch function that takes [n, x, y, z] tensor and calculates the distance between each point and returns [n x n] matrix using torch.cdist\n",
    "def get_distance_matrix(xyz):\n",
    "    return torch.cdist(xyz, xyz)\n",
    "\n",
    "\n",
    "def get_distance_matrix_for_indices(dm, indices):\n",
    "    return dm[indices][:, indices]\n",
    "\n",
    "\n",
    "def get_distance_matrix_from_csv(\n",
    "    path_to_geom=\"/opt/slh/icecube/data/sensor_geometry.csv\",\n",
    "):\n",
    "    geom = pd.read_csv(path_to_geom)[[\"x\", \"y\", \"z\"]]\n",
    "    geom = torch.tensor(geom.values, dtype=torch.float32)\n",
    "    geom = get_distance_matrix(geom)\n",
    "    # nromalize goematry matrix\n",
    "    geom = geom / geom.max()\n",
    "    return geom\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetGraphV0(Dataset):\n",
    "    def __init__(self, ds, min_adj_distance=0.015, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "        self.mad = min_adj_distance\n",
    "        self.distance_matrix_ = get_distance_matrix_from_csv()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        # getting distance matrix for event\n",
    "        distance_matrix = get_distance_matrix_for_indices(\n",
    "            self.distance_matrix_, event[\"sensor_id\"].values\n",
    "        )\n",
    "\n",
    "        dmx = torch.zeros((self.max_events, self.max_events), dtype=torch.float32)\n",
    "        dmx[: distance_matrix.shape[0], : distance_matrix.shape[1]] = distance_matrix\n",
    "        adjecent_matrix = (dmx < self.mad).type(torch.float32)\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"distance_matrix\": dmx,\n",
    "                \"adjecent_matrix\": adjecent_matrix,\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetGraphV1(Dataset):\n",
    "    def __init__(self, ds, min_adj_distance=0.05, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.mad = min_adj_distance\n",
    "        self.distance_matrix_ = get_distance_matrix_from_csv()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = (event['time'] - 1.0e04) / 3.0e4\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event['x'] /=500\n",
    "        event['y'] /=500\n",
    "        event['z'] /=500\n",
    "\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])/3.0\n",
    "\n",
    "        # getting distance matrix for event\n",
    "        distance_matrix = get_distance_matrix_for_indices(\n",
    "            self.distance_matrix_, event[\"sensor_id\"].values\n",
    "        )\n",
    "\n",
    "        dmx = torch.zeros((self.max_events, self.max_events), dtype=torch.float32)\n",
    "        dmx[: distance_matrix.shape[0], : distance_matrix.shape[1]] = distance_matrix\n",
    "        adjecent_matrix = (dmx < self.mad).type(torch.float32)\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"time\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"distance_matrix\": dmx,\n",
    "                \"adjecent_matrix\": adjecent_matrix,\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = HuggingFaceDatasetGraphV1(load_from_disk('/opt/slh/icecube/data/hf_cashe/batch_1.parquet'))\n",
    "sns.heatmap(ds[np.random.randint(0, len(ds))]['adjecent_matrix'].numpy())\n",
    "#dl = DataLoader(ds, batch_size=64, shuffle=True, num_workers=4, collate_fn=collate_fn_graphv0)\n",
    "#for x in dl:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def good_luck():\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class IceCubeKaggle():\n",
    "#     \"\"\"`Detector` class for Kaggle Competition.\"\"\"\n",
    "\n",
    "#     # Implementing abstract class attribute\n",
    "\n",
    "#     def _forward(self, data: Data) -> Data:\n",
    "#         \"\"\"Ingest data, build graph, and preprocess features.\n",
    "#         Args:\n",
    "#             data: Input graph data.\n",
    "#         Returns:\n",
    "#             Connected and preprocessed graph data.\n",
    "#         \"\"\"\n",
    "#         # Check(s)\n",
    "#         self._validate_features(data)\n",
    "\n",
    "#         # Preprocessing\n",
    "#         data.x[:, 0] /= 500.0  # x\n",
    "#         data.x[:, 1] /= 500.0  # y\n",
    "#         data.x[:, 2] /= 500.0  # z\n",
    "#         data.x[:, 3] = (data.x[:, 3] - 1.0e04) / 3.0e4  # time\n",
    "#         data.x[:, 4] = torch.log10(data.x[:, 4]) / 3.0  # charge\n",
    "\n",
    "#         return data\n",
    "\n",
    "# class Direction(Label):\n",
    "#     \"\"\"Class for producing particle direction/pointing label.\"\"\"\n",
    "\n",
    "#     def __init__(\n",
    "#         self, azimuth_key: str = \"azimuth\", zenith_key: str = \"zenith\"\n",
    "#     ):\n",
    "#         \"\"\"Construct `Direction`.\"\"\"\n",
    "#         self._azimuth_key = azimuth_key\n",
    "#         self._zenith_key = zenith_key\n",
    "\n",
    "#     def __call__(self, graph: Data) -> torch.tensor:\n",
    "#         \"\"\"Compute label for `graph`.\"\"\"\n",
    "#         x = torch.cos(graph[self._azimuth_key]) * torch.sin(\n",
    "#             graph[self._zenith_key]\n",
    "#         ).reshape(-1, 1)\n",
    "#         y = torch.sin(graph[self._azimuth_key]) * torch.sin(\n",
    "#             graph[self._zenith_key]\n",
    "#         ).reshape(-1, 1)\n",
    "#         z = torch.cos(graph[self._zenith_key]).reshape(-1, 1)\n",
    "#         return torch.cat((x, y, z), dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
