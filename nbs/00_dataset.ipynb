{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from datasets import  load_from_disk\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import sys\n",
    "sys.path.append('/opt/slh/icecube/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb import set_trace\n",
    "import seaborn as sns\n",
    "class CFG:\n",
    "    CACHE_PATH = Path('../data/cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = list((CFG.CACHE_PATH/'batch_3').glob('*.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# function that loads the data from the pth file and return the data and the label as pd.DataFrame\n",
    "def load_data(\n",
    "    fn: Path,\n",
    "    columns_event: str = [\"time\", \"charge\", \"auxiliary\", \"x\", \"y\", \"z\"],\n",
    "    columns_label: str = [\"azimuth\", \"zenith\"],\n",
    "    keep_auxiliary_event: bool = False,\n",
    "):\n",
    "    data = torch.load(fn)\n",
    "    event = pd.DataFrame.from_records(data[\"event\"])[columns_event]\n",
    "    if keep_auxiliary_event:\n",
    "        event = event.query(\"auxiliary == True\")\n",
    "    label = pd.DataFrame.from_records(data[\"target\"])[columns_label]\n",
    "    return event.astype(np.float32), label\n",
    "\n",
    "\n",
    "class IceCubeCasheDatasetV0(Dataset):\n",
    "    def __init__(self, fns, max_events=100):\n",
    "        self.fns = fns\n",
    "        self.max_events = max_events\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fn = self.fns[idx]\n",
    "        event, label = load_data(fn)\n",
    "\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = torch.tensor(event.values)\n",
    "        mask = torch.ones(len(event), dtype=torch.bool)\n",
    "        label = torch.tensor(label.values, dtype=torch.float32)\n",
    "\n",
    "        return {\"event\": event, \"mask\": mask, \"label\": label}\n",
    "\n",
    "\n",
    "class IceCubeCasheDatasetV1(Dataset):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        Dataset (_type_): Same as IceCubeCasheDatasetV0 but with the option to keep the auxiliary events\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fns, max_events=100, keep_auxiliary_event: bool = True):\n",
    "        self.fns = fns\n",
    "        self.max_events = max_events\n",
    "        self.keep_auxiliary_event = keep_auxiliary_event\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fn = self.fns[idx]\n",
    "        event, label = load_data(fn, keep_auxiliary_event=self.keep_auxiliary_event)\n",
    "\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = torch.tensor(event.values)\n",
    "        mask = torch.ones(len(event), dtype=torch.bool)\n",
    "        label = torch.tensor(label.values, dtype=torch.float32)\n",
    "\n",
    "        return {\"event\": event, \"mask\": mask, \"label\": label}\n",
    "\n",
    "\n",
    "# collate_fn that pads the event and mask to the max length in the batch using pythorch pad_sequence\n",
    "class HuggingFaceDatasetV0(Dataset):\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = event.values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "# function to normalize input between 1 and 0\n",
    "def normalize(x):\n",
    "    return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV1(Dataset):\n",
    "    \"\"\"\n",
    "    Same as HuggingFaceDatasetV0 but returns sensor_id as well\n",
    "    in addition it adds + 1 to make the sensor_id start from 1 instead of 0,\n",
    "    0 is ignore index\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        # this is done in order to shift sensor id from 0 to 1\n",
    "        # since paddding index is 0\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "\n",
    "        # feature engineering\n",
    "        event[\"w1\"] = event[\"charge\"] * event[\"time\"]\n",
    "        event[\"w0\"] = event[\"charge\"] - event[\"w1\"]\n",
    "\n",
    "        event[\"wx0\"] = event.x * event.w0\n",
    "        event[\"wy0\"] = event.y * event.w0\n",
    "        event[\"wz0\"] = event.z * event.w0\n",
    "        event[\"wx1\"] = event.x * event.w1\n",
    "        event[\"wy1\"] = event.y * event.w1\n",
    "        event[\"wz1\"] = event.z * event.w1\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"w1\",\n",
    "                \"w0\",\n",
    "                \"wx0\",\n",
    "                \"wy0\",\n",
    "                \"wz0\",\n",
    "                \"wx1\",\n",
    "                \"wy1\",\n",
    "                \"wz1\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV2(Dataset):\n",
    "    \"\"\"\n",
    "    Same as HuggingFaceDatasetV0 but returns sensor_id as well\n",
    "    in addition it adds + 1 to make the sensor_id start from 1 instead of 0,\n",
    "    0 is ignore index\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        # this is done in order to shift sensor id from 0 to 1\n",
    "        # since paddding index is 0\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV3(Dataset):\n",
    "    \"\"\"\n",
    "    Same as HuggingFaceDatasetV0 but returns sensor_id as well\n",
    "    in addition it adds + 1 to make the sensor_id start from 1 instead of 0,\n",
    "    0 is ignore index\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        # this is done in order to shift sensor id from 0 to 1\n",
    "        # since paddding index is 0\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "class HuggingFaceDatasetV4(Dataset):\n",
    "    \"\"\"\n",
    "    Same as HuggingFaceDatasetV0 but returns sensor_id as well\n",
    "    in addition it adds + 1 to make the sensor_id start from 1 instead of 0,\n",
    "    0 is ignore index\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=160):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        # this is done in order to shift sensor id from 0 to 1\n",
    "        # since paddding index is 0\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "def event_filtering_v1(batch, max_pulse_count=128, t_valid_length=6199.700247193777):\n",
    "    col = batch.columns\n",
    "    t_peak = batch[\"time\"][batch[\"charge\"].argmax()]\n",
    "    t_valid_min = t_peak - t_valid_length\n",
    "    t_valid_max = t_peak + t_valid_length\n",
    "    t_valid = (batch[\"time\"] > t_valid_min) * (batch[\"time\"] < t_valid_max)\n",
    "    batch[\"rank\"] = 2 * (1 - batch[\"auxiliary\"]) + (t_valid)\n",
    "    batch = batch.sort_values(by=[\"rank\", \"charge\"])\n",
    "    # pick-up from backward\n",
    "    batch = batch[-max_pulse_count:]\n",
    "        # resort by time\n",
    "    batch = batch.sort_values(by=\"time\")\n",
    "    return batch[col]\n",
    "\n",
    "def event_filtering_v2(batch, max_pulse_count=128, t_valid_length=6199.700247193777):\n",
    "    \"same as v1 but we add rank column to every entry and sort only if lenth is more then max_pulse_count\"\n",
    "    t_peak = batch[\"time\"][batch[\"charge\"].argmax()]\n",
    "    t_valid_min = t_peak - t_valid_length\n",
    "    t_valid_max = t_peak + t_valid_length\n",
    "    t_valid = (batch[\"time\"] > t_valid_min) * (batch[\"time\"] < t_valid_max)\n",
    "    batch[\"rank\"] = 2 * (1 - batch[\"auxiliary\"]) + (t_valid)\n",
    "    if batch.shape[0] > max_pulse_count:\n",
    "        batch = batch.sort_values(by=[\"rank\", \"charge\"])\n",
    "        # pick-up from backward\n",
    "        batch = batch[-max_pulse_count:]\n",
    "            # resort by time\n",
    "        batch = batch.sort_values(by=\"time\")\n",
    "    return batch\n",
    "        \n",
    "        \n",
    "def event_filtering_v3(batch, max_pulse_count=128, t_valid_length=6199.700247193777):\n",
    "    \"filtering only by auxiliary and then by time\"\n",
    "    t_peak = batch[\"time\"][batch[\"charge\"].argmax()]\n",
    "    t_valid_min = t_peak - t_valid_length\n",
    "    t_valid_max = t_peak + t_valid_length\n",
    "    t_valid = (batch[\"time\"] > t_valid_min) * (batch[\"time\"] < t_valid_max)\n",
    "    batch[\"rank\"] = 2 * (1 - batch[\"auxiliary\"]) + (t_valid)\n",
    "    if batch.shape[0] > max_pulse_count:\n",
    "        batch = batch.sort_values(by=[\"auxiliary\"])\n",
    "        # pick-up from backward\n",
    "        batch = batch[:max_pulse_count]\n",
    "            # resort by time\n",
    "        batch = batch.sort_values(by=\"time\")\n",
    "    return batch\n",
    "        \n",
    "\n",
    "class HuggingFaceDatasetV5(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        \n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = IceCubeCasheDatasetV1(fns)\n",
    "#dl = DataLoader(ds, batch_size=64, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "# for x in dl:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = HuggingFaceDatasetV5(load_from_disk('/opt/slh/icecube/data/hf_cashe/batch_1.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ice_transparency(\n",
    "    data_path=\"/opt/slh/icecube/data/ice_transparency.txt\", datum=1950\n",
    "):\n",
    "    # Data from page 31 of https://arxiv.org/pdf/1301.5361.pdf\n",
    "    # Datum is from footnote 8 of page 29\n",
    "    df = pd.read_csv(data_path, delim_whitespace=True)\n",
    "    df[\"z\"] = df[\"depth\"] - datum\n",
    "    df[\"z_norm\"] = df[\"z\"] / 500\n",
    "    df[[\"scattering_len_norm\", \"absorption_len_norm\"]] = RobustScaler().fit_transform(\n",
    "        df[[\"scattering_len\", \"absorption_len\"]]\n",
    "    )\n",
    "\n",
    "    # These are both roughly equivalent after scaling\n",
    "    f_scattering = interp1d(df[\"z_norm\"], df[\"scattering_len_norm\"])\n",
    "    f_absorption = interp1d(df[\"z_norm\"], df[\"absorption_len_norm\"])\n",
    "    return f_scattering, f_absorption\n",
    "\n",
    "def prepare_sensors():\n",
    "    sensors = pd.read_csv('/opt/slh/icecube/data/sensor_geometry.csv').astype(\n",
    "        {\n",
    "            \"sensor_id\": np.int16,\n",
    "            \"x\": np.float32,\n",
    "            \"y\": np.float32,\n",
    "            \"z\": np.float32,\n",
    "        }\n",
    "    )\n",
    "    sensors[\"string\"] = 0\n",
    "    sensors[\"qe\"] = 1\n",
    "\n",
    "    for i in range(len(sensors) // 60):\n",
    "        start, end = i * 60, (i * 60) + 60\n",
    "        sensors.loc[start:end, \"string\"] = i\n",
    "\n",
    "        # High Quantum Efficiency in the lower 50 DOMs - https://arxiv.org/pdf/2209.03042.pdf (Figure 1)\n",
    "        if i in range(78, 86):\n",
    "            start_veto, end_veto = i * 60, (i * 60) + 10\n",
    "            start_core, end_core = end_veto + 1, (i * 60) + 60\n",
    "            sensors.loc[start_core:end_core, \"qe\"] = 1.35\n",
    "\n",
    "    # https://github.com/graphnet-team/graphnet/blob/b2bad25528652587ab0cdb7cf2335ee254cfa2db/src/graphnet/models/detector/icecube.py#L33-L41\n",
    "    # Assume that \"rde\" (relative dom efficiency) is equivalent to QE\n",
    "    sensors[\"x\"] /= 500\n",
    "    sensors[\"y\"] /= 500\n",
    "    sensors[\"z\"] /= 500\n",
    "    sensors[\"qe\"] -= 1.25\n",
    "    sensors[\"qe\"] /= 0.25\n",
    "\n",
    "    return sensors.set_index(\"sensor_id\")[['qe']]\n",
    "\n",
    "\n",
    "def convert_to_3d(azimuth, zenith):\n",
    "    \"\"\"Converts zenith and azimuth to 3D direction vectors\"\"\"\n",
    "    x = np.cos(azimuth) * np.sin(zenith)\n",
    "    y = np.sin(azimuth) * np.sin(zenith)\n",
    "    z = np.cos(zenith)\n",
    "    return np.array([x, y, z], dtype=np.float32)\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV6(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV7(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV8(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=148):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV9(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event[\"absorption\"] = self.f_absorption(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "                \"absorption\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "    \n",
    "class HuggingFaceDatasetV10(Dataset):\n",
    "    \"\"\"\n",
    "    same as V9 but with 148 \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=148):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event[\"absorption\"] = self.f_absorption(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "                \"absorption\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "    \n",
    "class HuggingFaceDatasetV11(Dataset):\n",
    "    \"\"\"\n",
    "    same as V9 but with added sensoor ids \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event[\"absorption\"] = self.f_absorption(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "                \"absorption\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "class HuggingFaceDatasetV12(Dataset):\n",
    "    \"\"\"\n",
    "    same as V9 but with added sensoor ids , same as V11 but with 160 `max_len`\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=160):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event[\"absorption\"] = self.f_absorption(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "                \"absorption\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "    \n",
    "    \n",
    "class HuggingFaceDatasetV13(Dataset):\n",
    "    \"\"\"\n",
    "    same as V9 but with added sensoor ids , same as V11 but with 196 `max_len`\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=196):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event[\"absorption\"] = self.f_absorption(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "                \"absorption\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "    \n",
    "    \n",
    "class HuggingFaceDatasetV14(Dataset):\n",
    "    \"\"\"\n",
    "    same as V9 but with 148, returning qe and aux as long tesnors \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=148):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "\n",
    "        event = event_filtering_v2(event, max_pulse_count=self.max_events)\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event[\"absorption\"] = self.f_absorption(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] =  self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\" : torch.tensor(event[[\"x\", \"y\", \"z\", \"time\", \"charge\", \"scattering\", \"absorption\"]].values, dtype=torch.float32),\n",
    "                \"rank\": torch.tensor(event['rank'].values, dtype=torch.long),\n",
    "                \"qe\": torch.tensor(event['qe'].values + 1, dtype=torch.long),\n",
    "                \"aux\": torch.tensor(event['auxiliary'].values, dtype=torch.long,),\n",
    "                \"label\": torch.tensor(label),\n",
    "                \"mask\": torch.tensor(mask)\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "    \n",
    "class HuggingFaceDatasetV15(Dataset):\n",
    "    \"\"\"\n",
    "    same as V9 but with 148, returning qe and aux as long tesnors \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=196):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "\n",
    "        event = event_filtering_v3(event, max_pulse_count=self.max_events)\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event[\"absorption\"] = self.f_absorption(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] =  self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\" : torch.tensor(event[[\"x\", \"y\", \"z\", \"time\", \"charge\", \"scattering\", \"absorption\"]].values, dtype=torch.float32),\n",
    "                \"rank\": torch.tensor(event['rank'].values, dtype=torch.long),\n",
    "                \"qe\": torch.tensor(event['qe'].values + 1, dtype=torch.long),\n",
    "                \"aux\": torch.tensor(event['auxiliary'].values, dtype=torch.long,),\n",
    "                \"label\": torch.tensor(label),\n",
    "                \"mask\": torch.tensor(mask)\n",
    "            }\n",
    "        )\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = HuggingFaceDatasetV15(load_from_disk('/opt/slh/icecube/data/hf_cashe/batch_1.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from icecube.utils import collate_fn_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "# pytorch function that takes [n, x, y, z] tensor and calculates the distance between each point and returns [n x n] matrix using torch.cdist\n",
    "def get_distance_matrix(xyz):\n",
    "    return torch.cdist(xyz, xyz)\n",
    "\n",
    "\n",
    "def get_distance_matrix_for_indices(dm, indices):\n",
    "    return dm[indices][:, indices]\n",
    "\n",
    "\n",
    "def get_distance_matrix_from_csv(\n",
    "    path_to_geom=\"/opt/slh/icecube/data/sensor_geometry.csv\",\n",
    "):\n",
    "    geom = pd.read_csv(path_to_geom)[[\"x\", \"y\", \"z\"]]\n",
    "    geom = torch.tensor(geom.values, dtype=torch.float32)\n",
    "    geom = get_distance_matrix(geom)\n",
    "    # nromalize goematry matrix\n",
    "    geom = geom / geom.max()\n",
    "    return geom\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetGraphV0(Dataset):\n",
    "    def __init__(self, ds, min_adj_distance=0.015, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "        self.mad = min_adj_distance\n",
    "        self.distance_matrix_ = get_distance_matrix_from_csv()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        # getting distance matrix for event\n",
    "        distance_matrix = get_distance_matrix_for_indices(\n",
    "            self.distance_matrix_, event[\"sensor_id\"].values\n",
    "        )\n",
    "\n",
    "        dmx = torch.zeros((self.max_events, self.max_events), dtype=torch.float32)\n",
    "        dmx[: distance_matrix.shape[0], : distance_matrix.shape[1]] = distance_matrix\n",
    "        adjecent_matrix = (dmx < self.mad).type(torch.float32)\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"distance_matrix\": dmx,\n",
    "                \"adjecent_matrix\": adjecent_matrix,\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetGraphV1(Dataset):\n",
    "    def __init__(self, ds, min_adj_distance=0.05, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.mad = min_adj_distance\n",
    "        self.distance_matrix_ = get_distance_matrix_from_csv()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = (event['time'] - 1.0e04) / 3.0e4\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event['x'] /=500\n",
    "        event['y'] /=500\n",
    "        event['z'] /=500\n",
    "\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])/3.0\n",
    "\n",
    "        # getting distance matrix for event\n",
    "        distance_matrix = get_distance_matrix_for_indices(\n",
    "            self.distance_matrix_, event[\"sensor_id\"].values\n",
    "        )\n",
    "\n",
    "        dmx = torch.zeros((self.max_events, self.max_events), dtype=torch.float32)\n",
    "        dmx[: distance_matrix.shape[0], : distance_matrix.shape[1]] = distance_matrix\n",
    "        adjecent_matrix = (dmx < self.mad).type(torch.float32)\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"time\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"distance_matrix\": dmx,\n",
    "                \"adjecent_matrix\": adjecent_matrix,\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = HuggingFaceDatasetGraphV1(load_from_disk('/opt/slh/icecube/data/hf_cashe/batch_1.parquet'))\n",
    "sns.heatmap(ds[np.random.randint(0, len(ds))]['adjecent_matrix'].numpy())\n",
    "#dl = DataLoader(ds, batch_size=64, shuffle=True, num_workers=4, collate_fn=collate_fn_graphv0)\n",
    "#for x in dl:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def good_luck():\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class IceCubeKaggle():\n",
    "#     \"\"\"`Detector` class for Kaggle Competition.\"\"\"\n",
    "\n",
    "#     # Implementing abstract class attribute\n",
    "\n",
    "#     def _forward(self, data: Data) -> Data:\n",
    "#         \"\"\"Ingest data, build graph, and preprocess features.\n",
    "#         Args:\n",
    "#             data: Input graph data.\n",
    "#         Returns:\n",
    "#             Connected and preprocessed graph data.\n",
    "#         \"\"\"\n",
    "#         # Check(s)\n",
    "#         self._validate_features(data)\n",
    "\n",
    "#         # Preprocessing\n",
    "#         data.x[:, 0] /= 500.0  # x\n",
    "#         data.x[:, 1] /= 500.0  # y\n",
    "#         data.x[:, 2] /= 500.0  # z\n",
    "#         data.x[:, 3] = (data.x[:, 3] - 1.0e04) / 3.0e4  # time\n",
    "#         data.x[:, 4] = torch.log10(data.x[:, 4]) / 3.0  # charge\n",
    "\n",
    "#         return data\n",
    "\n",
    "# class Direction(Label):\n",
    "#     \"\"\"Class for producing particle direction/pointing label.\"\"\"\n",
    "\n",
    "#     def __init__(\n",
    "#         self, azimuth_key: str = \"azimuth\", zenith_key: str = \"zenith\"\n",
    "#     ):\n",
    "#         \"\"\"Construct `Direction`.\"\"\"\n",
    "#         self._azimuth_key = azimuth_key\n",
    "#         self._zenith_key = zenith_key\n",
    "\n",
    "#     def __call__(self, graph: Data) -> torch.tensor:\n",
    "#         \"\"\"Compute label for `graph`.\"\"\"\n",
    "#         x = torch.cos(graph[self._azimuth_key]) * torch.sin(\n",
    "#             graph[self._zenith_key]\n",
    "#         ).reshape(-1, 1)\n",
    "#         y = torch.sin(graph[self._azimuth_key]) * torch.sin(\n",
    "#             graph[self._zenith_key]\n",
    "#         ).reshape(-1, 1)\n",
    "#         z = torch.cos(graph[self._zenith_key]).reshape(-1, 1)\n",
    "#         return torch.cat((x, y, z), dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
