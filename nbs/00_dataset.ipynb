{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from datasets import  load_from_disk\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb import set_trace\n",
    "import seaborn as sns\n",
    "class CFG:\n",
    "    CACHE_PATH = Path('../data/cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = list((CFG.CACHE_PATH/'batch_3').glob('*.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# function that loads the data from the pth file and return the data and the label as pd.DataFrame\n",
    "def load_data(\n",
    "    fn: Path,\n",
    "    columns_event: str = [\"time\", \"charge\", \"auxiliary\", \"x\", \"y\", \"z\"],\n",
    "    columns_label: str = [\"azimuth\", \"zenith\"],\n",
    "    keep_auxiliary_event: bool = False,\n",
    "):\n",
    "    data = torch.load(fn)\n",
    "    event = pd.DataFrame.from_records(data[\"event\"])[columns_event]\n",
    "    if keep_auxiliary_event:\n",
    "        event = event.query(\"auxiliary == True\")\n",
    "    label = pd.DataFrame.from_records(data[\"target\"])[columns_label]\n",
    "    return event.astype(np.float32), label\n",
    "\n",
    "\n",
    "class IceCubeCasheDatasetV0(Dataset):\n",
    "    def __init__(self, fns, max_events=100):\n",
    "        self.fns = fns\n",
    "        self.max_events = max_events\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fn = self.fns[idx]\n",
    "        event, label = load_data(fn)\n",
    "\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = torch.tensor(event.values)\n",
    "        mask = torch.ones(len(event), dtype=torch.bool)\n",
    "        label = torch.tensor(label.values, dtype=torch.float32)\n",
    "\n",
    "        return {\"event\": event, \"mask\": mask, \"label\": label}\n",
    "\n",
    "\n",
    "class IceCubeCasheDatasetV1(Dataset):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        Dataset (_type_): Same as IceCubeCasheDatasetV0 but with the option to keep the auxiliary events\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fns, max_events=100, keep_auxiliary_event: bool = True):\n",
    "        self.fns = fns\n",
    "        self.max_events = max_events\n",
    "        self.keep_auxiliary_event = keep_auxiliary_event\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fn = self.fns[idx]\n",
    "        event, label = load_data(fn, keep_auxiliary_event=self.keep_auxiliary_event)\n",
    "\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = torch.tensor(event.values)\n",
    "        mask = torch.ones(len(event), dtype=torch.bool)\n",
    "        label = torch.tensor(label.values, dtype=torch.float32)\n",
    "\n",
    "        return {\"event\": event, \"mask\": mask, \"label\": label}\n",
    "\n",
    "\n",
    "# collate_fn that pads the event and mask to the max length in the batch using pythorch pad_sequence\n",
    "class HuggingFaceDatasetV0(Dataset):\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = event.values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "# function to normalize input between 1 and 0\n",
    "def normalize(x):\n",
    "    return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV1(Dataset):\n",
    "    \"\"\"\n",
    "    Same as HuggingFaceDatasetV0 but returns sensor_id as well\n",
    "    in addition it adds + 1 to make the sensor_id start from 1 instead of 0,\n",
    "    0 is ignore index\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        # this is done in order to shift sensor id from 0 to 1\n",
    "        # since paddding index is 0\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "\n",
    "        # feature engineering\n",
    "        event[\"w1\"] = event[\"charge\"] * event[\"time\"]\n",
    "        event[\"w0\"] = event[\"charge\"] - event[\"w1\"]\n",
    "\n",
    "        event[\"wx0\"] = event.x * event.w0\n",
    "        event[\"wy0\"] = event.y * event.w0\n",
    "        event[\"wz0\"] = event.z * event.w0\n",
    "        event[\"wx1\"] = event.x * event.w1\n",
    "        event[\"wy1\"] = event.y * event.w1\n",
    "        event[\"wz1\"] = event.z * event.w1\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"w1\",\n",
    "                \"w0\",\n",
    "                \"wx0\",\n",
    "                \"wy0\",\n",
    "                \"wz0\",\n",
    "                \"wx1\",\n",
    "                \"wy1\",\n",
    "                \"wz1\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV2(Dataset):\n",
    "    \"\"\"\n",
    "    Same as HuggingFaceDatasetV0 but returns sensor_id as well\n",
    "    in addition it adds + 1 to make the sensor_id start from 1 instead of 0,\n",
    "    0 is ignore index\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        # this is done in order to shift sensor id from 0 to 1\n",
    "        # since paddding index is 0\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV3(Dataset):\n",
    "    \"\"\"\n",
    "    Same as HuggingFaceDatasetV0 but returns sensor_id as well\n",
    "    in addition it adds + 1 to make the sensor_id start from 1 instead of 0,\n",
    "    0 is ignore index\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        # this is done in order to shift sensor id from 0 to 1\n",
    "        # since paddding index is 0\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "class HuggingFaceDatasetV4(Dataset):\n",
    "    \"\"\"\n",
    "    Same as HuggingFaceDatasetV0 but returns sensor_id as well\n",
    "    in addition it adds + 1 to make the sensor_id start from 1 instead of 0,\n",
    "    0 is ignore index\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=160):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        # this is done in order to shift sensor id from 0 to 1\n",
    "        # since paddding index is 0\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "def event_filtering_v1(batch, max_pulse_count=128, t_valid_length=6199.700247193777):\n",
    "    col = batch.columns\n",
    "    t_peak = batch[\"time\"][batch[\"charge\"].argmax()]\n",
    "    t_valid_min = t_peak - t_valid_length\n",
    "    t_valid_max = t_peak + t_valid_length\n",
    "    t_valid = (batch[\"time\"] > t_valid_min) * (batch[\"time\"] < t_valid_max)\n",
    "    batch[\"rank\"] = 2 * (1 - batch[\"auxiliary\"]) + (t_valid)\n",
    "    batch = batch.sort_values(by=[\"rank\", \"charge\"])\n",
    "    # pick-up from backward\n",
    "    batch = batch[-max_pulse_count:]\n",
    "        # resort by time\n",
    "    batch = batch.sort_values(by=\"time\")\n",
    "    return batch[col]\n",
    "        \n",
    "\n",
    "class HuggingFaceDatasetV5(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        \n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = IceCubeCasheDatasetV1(fns)\n",
    "#dl = DataLoader(ds, batch_size=64, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "# for x in dl:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py:1536: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "ds = HuggingFaceDatasetV5(load_from_disk('/opt/slh/icecube/data/hf_cashe/batch_1.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ice_transparency(\n",
    "    data_path=\"/opt/slh/icecube/data/ice_transparency.txt\", datum=1950\n",
    "):\n",
    "    # Data from page 31 of https://arxiv.org/pdf/1301.5361.pdf\n",
    "    # Datum is from footnote 8 of page 29\n",
    "    df = pd.read_csv(data_path, delim_whitespace=True)\n",
    "    df[\"z\"] = df[\"depth\"] - datum\n",
    "    df[\"z_norm\"] = df[\"z\"] / 500\n",
    "    df[[\"scattering_len_norm\", \"absorption_len_norm\"]] = RobustScaler().fit_transform(\n",
    "        df[[\"scattering_len\", \"absorption_len\"]]\n",
    "    )\n",
    "\n",
    "    # These are both roughly equivalent after scaling\n",
    "    f_scattering = interp1d(df[\"z_norm\"], df[\"scattering_len_norm\"])\n",
    "    f_absorption = interp1d(df[\"z_norm\"], df[\"absorption_len_norm\"])\n",
    "    return f_scattering, f_absorption\n",
    "\n",
    "def prepare_sensors():\n",
    "    sensors = pd.read_csv('/opt/slh/icecube/data/sensor_geometry.csv').astype(\n",
    "        {\n",
    "            \"sensor_id\": np.int16,\n",
    "            \"x\": np.float32,\n",
    "            \"y\": np.float32,\n",
    "            \"z\": np.float32,\n",
    "        }\n",
    "    )\n",
    "    sensors[\"string\"] = 0\n",
    "    sensors[\"qe\"] = 1\n",
    "\n",
    "    for i in range(len(sensors) // 60):\n",
    "        start, end = i * 60, (i * 60) + 60\n",
    "        sensors.loc[start:end, \"string\"] = i\n",
    "\n",
    "        # High Quantum Efficiency in the lower 50 DOMs - https://arxiv.org/pdf/2209.03042.pdf (Figure 1)\n",
    "        if i in range(78, 86):\n",
    "            start_veto, end_veto = i * 60, (i * 60) + 10\n",
    "            start_core, end_core = end_veto + 1, (i * 60) + 60\n",
    "            sensors.loc[start_core:end_core, \"qe\"] = 1.35\n",
    "\n",
    "    # https://github.com/graphnet-team/graphnet/blob/b2bad25528652587ab0cdb7cf2335ee254cfa2db/src/graphnet/models/detector/icecube.py#L33-L41\n",
    "    # Assume that \"rde\" (relative dom efficiency) is equivalent to QE\n",
    "    sensors[\"x\"] /= 500\n",
    "    sensors[\"y\"] /= 500\n",
    "    sensors[\"z\"] /= 500\n",
    "    sensors[\"qe\"] -= 1.25\n",
    "    sensors[\"qe\"] /= 0.25\n",
    "\n",
    "    return sensors.set_index(\"sensor_id\")[['qe']]\n",
    "\n",
    "\n",
    "def convert_to_3d(azimuth, zenith):\n",
    "    \"\"\"Converts zenith and azimuth to 3D direction vectors\"\"\"\n",
    "    x = np.cos(azimuth) * np.sin(zenith)\n",
    "    y = np.sin(azimuth) * np.sin(zenith)\n",
    "    z = np.cos(zenith)\n",
    "    return np.array([x, y, z], dtype=np.float32)\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV6(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV7(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV8(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=148):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV9(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event[\"absorption\"] = self.f_absorption(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "                \"absorption\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "    \n",
    "class HuggingFaceDatasetV10(Dataset):\n",
    "    \"\"\"\n",
    "    same as V9 but with 148 \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=148):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event[\"absorption\"] = self.f_absorption(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "                \"absorption\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "    \n",
    "class HuggingFaceDatasetV11(Dataset):\n",
    "    \"\"\"\n",
    "    same as V9 but with added sensoor ids \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event[\"absorption\"] = self.f_absorption(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "                \"absorption\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "class HuggingFaceDatasetV12(Dataset):\n",
    "    \"\"\"\n",
    "    same as V9 but with added sensoor ids , same as V11 but with 160 `max_len`\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=160):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event[\"absorption\"] = self.f_absorption(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "                \"absorption\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1289, -0.0369,  0.5000,  0.0237,  0.3584, -0.2548, -1.0000,  0.2957],\n",
       "        [-0.1266, -0.0037,  0.5000,  0.0832,  0.0710, -0.5961,  0.4000,  0.2331],\n",
       "        [-0.0982,  0.0233,  0.5000,  1.0105,  0.5158,  0.0253, -1.0000, -0.4893],\n",
       "        [-0.0864, -0.0801,  0.5000,  0.2264, -0.1209, -0.4764,  0.4000, -0.3048],\n",
       "        [-0.0747, -0.0466,  0.5000,  1.0105,  0.5158, -0.1790, -1.0000, -0.4543]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = HuggingFaceDatasetV8(load_from_disk('/opt/slh/icecube/data/hf_cashe/batch_1.parquet'))\n",
    "ds[100]['event'][:5, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = ds[0]['event'][0]\n",
    "x = ds[0]['event'][3]\n",
    "y = ds[0]['event'][4]\n",
    "z = ds[0]['event'][5]\n",
    "chage = ds[0]['event'][1]\n",
    "magnitude = torch.sqrt(x ** 2 + y ** 2 + z ** 2)\n",
    "distance = magnitude / 3 * 10 ** 8\n",
    "time_of_flight = time + distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([61, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]['event'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "# pytorch function that takes [n, x, y, z] tensor and calculates the distance between each point and returns [n x n] matrix using torch.cdist\n",
    "def get_distance_matrix(xyz):\n",
    "    return torch.cdist(xyz, xyz)\n",
    "\n",
    "\n",
    "def get_distance_matrix_for_indices(dm, indices):\n",
    "    return dm[indices][:, indices]\n",
    "\n",
    "\n",
    "def get_distance_matrix_from_csv(\n",
    "    path_to_geom=\"/opt/slh/icecube/data/sensor_geometry.csv\",\n",
    "):\n",
    "    geom = pd.read_csv(path_to_geom)[[\"x\", \"y\", \"z\"]]\n",
    "    geom = torch.tensor(geom.values, dtype=torch.float32)\n",
    "    geom = get_distance_matrix(geom)\n",
    "    # nromalize goematry matrix\n",
    "    geom = geom / geom.max()\n",
    "    return geom\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetGraphV0(Dataset):\n",
    "    def __init__(self, ds, min_adj_distance=0.015, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "        self.mad = min_adj_distance\n",
    "        self.distance_matrix_ = get_distance_matrix_from_csv()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        # getting distance matrix for event\n",
    "        distance_matrix = get_distance_matrix_for_indices(\n",
    "            self.distance_matrix_, event[\"sensor_id\"].values\n",
    "        )\n",
    "\n",
    "        dmx = torch.zeros((self.max_events, self.max_events), dtype=torch.float32)\n",
    "        dmx[: distance_matrix.shape[0], : distance_matrix.shape[1]] = distance_matrix\n",
    "        adjecent_matrix = (dmx < self.mad).type(torch.float32)\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"distance_matrix\": dmx,\n",
    "                \"adjecent_matrix\": adjecent_matrix,\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetGraphV1(Dataset):\n",
    "    def __init__(self, ds, min_adj_distance=0.05, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.mad = min_adj_distance\n",
    "        self.distance_matrix_ = get_distance_matrix_from_csv()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = (event['time'] - 1.0e04) / 3.0e4\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event['x'] /=500\n",
    "        event['y'] /=500\n",
    "        event['z'] /=500\n",
    "\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])/3.0\n",
    "\n",
    "        # getting distance matrix for event\n",
    "        distance_matrix = get_distance_matrix_for_indices(\n",
    "            self.distance_matrix_, event[\"sensor_id\"].values\n",
    "        )\n",
    "\n",
    "        dmx = torch.zeros((self.max_events, self.max_events), dtype=torch.float32)\n",
    "        dmx[: distance_matrix.shape[0], : distance_matrix.shape[1]] = distance_matrix\n",
    "        adjecent_matrix = (dmx < self.mad).type(torch.float32)\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"time\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"distance_matrix\": dmx,\n",
    "                \"adjecent_matrix\": adjecent_matrix,\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py:1536: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = HuggingFaceDatasetGraphV1(load_from_disk('/opt/slh/icecube/data/hf_cashe/batch_1.parquet'))\n",
    "sns.heatmap(ds[np.random.randint(0, len(ds))]['adjecent_matrix'].numpy())\n",
    "#dl = DataLoader(ds, batch_size=64, shuffle=True, num_workers=4, collate_fn=collate_fn_graphv0)\n",
    "#for x in dl:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def good_luck():\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class IceCubeKaggle():\n",
    "#     \"\"\"`Detector` class for Kaggle Competition.\"\"\"\n",
    "\n",
    "#     # Implementing abstract class attribute\n",
    "\n",
    "#     def _forward(self, data: Data) -> Data:\n",
    "#         \"\"\"Ingest data, build graph, and preprocess features.\n",
    "#         Args:\n",
    "#             data: Input graph data.\n",
    "#         Returns:\n",
    "#             Connected and preprocessed graph data.\n",
    "#         \"\"\"\n",
    "#         # Check(s)\n",
    "#         self._validate_features(data)\n",
    "\n",
    "#         # Preprocessing\n",
    "#         data.x[:, 0] /= 500.0  # x\n",
    "#         data.x[:, 1] /= 500.0  # y\n",
    "#         data.x[:, 2] /= 500.0  # z\n",
    "#         data.x[:, 3] = (data.x[:, 3] - 1.0e04) / 3.0e4  # time\n",
    "#         data.x[:, 4] = torch.log10(data.x[:, 4]) / 3.0  # charge\n",
    "\n",
    "#         return data\n",
    "\n",
    "# class Direction(Label):\n",
    "#     \"\"\"Class for producing particle direction/pointing label.\"\"\"\n",
    "\n",
    "#     def __init__(\n",
    "#         self, azimuth_key: str = \"azimuth\", zenith_key: str = \"zenith\"\n",
    "#     ):\n",
    "#         \"\"\"Construct `Direction`.\"\"\"\n",
    "#         self._azimuth_key = azimuth_key\n",
    "#         self._zenith_key = zenith_key\n",
    "\n",
    "#     def __call__(self, graph: Data) -> torch.tensor:\n",
    "#         \"\"\"Compute label for `graph`.\"\"\"\n",
    "#         x = torch.cos(graph[self._azimuth_key]) * torch.sin(\n",
    "#             graph[self._zenith_key]\n",
    "#         ).reshape(-1, 1)\n",
    "#         y = torch.sin(graph[self._azimuth_key]) * torch.sin(\n",
    "#             graph[self._zenith_key]\n",
    "#         ).reshape(-1, 1)\n",
    "#         z = torch.cos(graph[self._zenith_key]).reshape(-1, 1)\n",
    "#         return torch.cat((x, y, z), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
