{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from datasets import  load_from_disk\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb import set_trace\n",
    "import seaborn as sns\n",
    "class CFG:\n",
    "    CACHE_PATH = Path('../data/cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = list((CFG.CACHE_PATH/'batch_3').glob('*.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# function that loads the data from the pth file and return the data and the label as pd.DataFrame\n",
    "def load_data(\n",
    "    fn: Path,\n",
    "    columns_event: str = [\"time\", \"charge\", \"auxiliary\", \"x\", \"y\", \"z\"],\n",
    "    columns_label: str = [\"azimuth\", \"zenith\"],\n",
    "    keep_auxiliary_event: bool = False,\n",
    "):\n",
    "    data = torch.load(fn)\n",
    "    event = pd.DataFrame.from_records(data[\"event\"])[columns_event]\n",
    "    if keep_auxiliary_event:\n",
    "        event = event.query(\"auxiliary == True\")\n",
    "    label = pd.DataFrame.from_records(data[\"target\"])[columns_label]\n",
    "    return event.astype(np.float32), label\n",
    "\n",
    "\n",
    "class IceCubeCasheDatasetV0(Dataset):\n",
    "    def __init__(self, fns, max_events=100):\n",
    "        self.fns = fns\n",
    "        self.max_events = max_events\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fn = self.fns[idx]\n",
    "        event, label = load_data(fn)\n",
    "\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = torch.tensor(event.values)\n",
    "        mask = torch.ones(len(event), dtype=torch.bool)\n",
    "        label = torch.tensor(label.values, dtype=torch.float32)\n",
    "\n",
    "        return {\"event\": event, \"mask\": mask, \"label\": label}\n",
    "\n",
    "\n",
    "class IceCubeCasheDatasetV1(Dataset):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        Dataset (_type_): Same as IceCubeCasheDatasetV0 but with the option to keep the auxiliary events\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fns, max_events=100, keep_auxiliary_event: bool = True):\n",
    "        self.fns = fns\n",
    "        self.max_events = max_events\n",
    "        self.keep_auxiliary_event = keep_auxiliary_event\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fn = self.fns[idx]\n",
    "        event, label = load_data(fn, keep_auxiliary_event=self.keep_auxiliary_event)\n",
    "\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = torch.tensor(event.values)\n",
    "        mask = torch.ones(len(event), dtype=torch.bool)\n",
    "        label = torch.tensor(label.values, dtype=torch.float32)\n",
    "\n",
    "        return {\"event\": event, \"mask\": mask, \"label\": label}\n",
    "\n",
    "\n",
    "# collate_fn that pads the event and mask to the max length in the batch using pythorch pad_sequence\n",
    "class HuggingFaceDatasetV0(Dataset):\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = event.values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "# function to normalize input between 1 and 0\n",
    "def normalize(x):\n",
    "    return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV1(Dataset):\n",
    "    \"\"\"\n",
    "    Same as HuggingFaceDatasetV0 but returns sensor_id as well\n",
    "    in addition it adds + 1 to make the sensor_id start from 1 instead of 0,\n",
    "    0 is ignore index\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        # this is done in order to shift sensor id from 0 to 1\n",
    "        # since paddding index is 0\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "\n",
    "        # feature engineering\n",
    "        event[\"w1\"] = event[\"charge\"] * event[\"time\"]\n",
    "        event[\"w0\"] = event[\"charge\"] - event[\"w1\"]\n",
    "\n",
    "        event[\"wx0\"] = event.x * event.w0\n",
    "        event[\"wy0\"] = event.y * event.w0\n",
    "        event[\"wz0\"] = event.z * event.w0\n",
    "        event[\"wx1\"] = event.x * event.w1\n",
    "        event[\"wy1\"] = event.y * event.w1\n",
    "        event[\"wz1\"] = event.z * event.w1\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"w1\",\n",
    "                \"w0\",\n",
    "                \"wx0\",\n",
    "                \"wy0\",\n",
    "                \"wz0\",\n",
    "                \"wx1\",\n",
    "                \"wy1\",\n",
    "                \"wz1\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV2(Dataset):\n",
    "    \"\"\"\n",
    "    Same as HuggingFaceDatasetV0 but returns sensor_id as well\n",
    "    in addition it adds + 1 to make the sensor_id start from 1 instead of 0,\n",
    "    0 is ignore index\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        # this is done in order to shift sensor id from 0 to 1\n",
    "        # since paddding index is 0\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV3(Dataset):\n",
    "    \"\"\"\n",
    "    Same as HuggingFaceDatasetV0 but returns sensor_id as well\n",
    "    in addition it adds + 1 to make the sensor_id start from 1 instead of 0,\n",
    "    0 is ignore index\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        # this is done in order to shift sensor id from 0 to 1\n",
    "        # since paddding index is 0\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "class HuggingFaceDatasetV4(Dataset):\n",
    "    \"\"\"\n",
    "    Same as HuggingFaceDatasetV0 but returns sensor_id as well\n",
    "    in addition it adds + 1 to make the sensor_id start from 1 instead of 0,\n",
    "    0 is ignore index\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=160):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        # this is done in order to shift sensor id from 0 to 1\n",
    "        # since paddding index is 0\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "def event_filtering_v1(batch, max_pulse_count=128, t_valid_length=6199.700247193777):\n",
    "    col = batch.columns\n",
    "    t_peak = batch[\"time\"][batch[\"charge\"].argmax()]\n",
    "    t_valid_min = t_peak - t_valid_length\n",
    "    t_valid_max = t_peak + t_valid_length\n",
    "    t_valid = (batch[\"time\"] > t_valid_min) * (batch[\"time\"] < t_valid_max)\n",
    "    batch[\"rank\"] = 2 * (1 - batch[\"auxiliary\"]) + (t_valid)\n",
    "    batch = batch.sort_values(by=[\"rank\", \"charge\"])\n",
    "    # pick-up from backward\n",
    "    batch = batch[-max_pulse_count:]\n",
    "        # resort by time\n",
    "    batch = batch.sort_values(by=\"time\")\n",
    "    return batch[col]\n",
    "        \n",
    "\n",
    "class HuggingFaceDatasetV5(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        \n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = IceCubeCasheDatasetV1(fns)\n",
    "#dl = DataLoader(ds, batch_size=64, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "# for x in dl:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py:1536: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "ds = HuggingFaceDatasetV5(load_from_disk('/opt/slh/icecube/data/hf_cashe/batch_1.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ice_transparency(\n",
    "    data_path=\"/opt/slh/icecube/data/ice_transparency.txt\", datum=1950\n",
    "):\n",
    "    # Data from page 31 of https://arxiv.org/pdf/1301.5361.pdf\n",
    "    # Datum is from footnote 8 of page 29\n",
    "    df = pd.read_csv(data_path, delim_whitespace=True)\n",
    "    df[\"z\"] = df[\"depth\"] - datum\n",
    "    df[\"z_norm\"] = df[\"z\"] / 500\n",
    "    df[[\"scattering_len_norm\", \"absorption_len_norm\"]] = RobustScaler().fit_transform(\n",
    "        df[[\"scattering_len\", \"absorption_len\"]]\n",
    "    )\n",
    "\n",
    "    # These are both roughly equivalent after scaling\n",
    "    f_scattering = interp1d(df[\"z_norm\"], df[\"scattering_len_norm\"])\n",
    "    f_absorption = interp1d(df[\"z_norm\"], df[\"absorption_len_norm\"])\n",
    "    return f_scattering, f_absorption\n",
    "\n",
    "def prepare_sensors():\n",
    "    sensors = pd.read_csv('/opt/slh/icecube/data/sensor_geometry.csv').astype(\n",
    "        {\n",
    "            \"sensor_id\": np.int16,\n",
    "            \"x\": np.float32,\n",
    "            \"y\": np.float32,\n",
    "            \"z\": np.float32,\n",
    "        }\n",
    "    )\n",
    "    sensors[\"string\"] = 0\n",
    "    sensors[\"qe\"] = 1\n",
    "\n",
    "    for i in range(len(sensors) // 60):\n",
    "        start, end = i * 60, (i * 60) + 60\n",
    "        sensors.loc[start:end, \"string\"] = i\n",
    "\n",
    "        # High Quantum Efficiency in the lower 50 DOMs - https://arxiv.org/pdf/2209.03042.pdf (Figure 1)\n",
    "        if i in range(78, 86):\n",
    "            start_veto, end_veto = i * 60, (i * 60) + 10\n",
    "            start_core, end_core = end_veto + 1, (i * 60) + 60\n",
    "            sensors.loc[start_core:end_core, \"qe\"] = 1.35\n",
    "\n",
    "    # https://github.com/graphnet-team/graphnet/blob/b2bad25528652587ab0cdb7cf2335ee254cfa2db/src/graphnet/models/detector/icecube.py#L33-L41\n",
    "    # Assume that \"rde\" (relative dom efficiency) is equivalent to QE\n",
    "    sensors[\"x\"] /= 500\n",
    "    sensors[\"y\"] /= 500\n",
    "    sensors[\"z\"] /= 500\n",
    "    sensors[\"qe\"] -= 1.25\n",
    "    sensors[\"qe\"] /= 0.25\n",
    "\n",
    "    return sensors.set_index(\"sensor_id\")[['qe']]\n",
    "\n",
    "\n",
    "def convert_to_3d(azimuth, zenith):\n",
    "    \"\"\"Converts zenith and azimuth to 3D direction vectors\"\"\"\n",
    "    x = np.cos(azimuth) * np.sin(zenith)\n",
    "    y = np.sin(azimuth) * np.sin(zenith)\n",
    "    z = np.cos(zenith)\n",
    "    return np.array([x, y, z], dtype=np.float32)\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV6(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV7(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV8(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=148):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV9(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event[\"absorption\"] = self.f_absorption(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "                \"absorption\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1289, -0.0369,  0.5000,  0.0237,  0.3584, -0.2548, -1.0000,  0.2957],\n",
       "        [-0.1266, -0.0037,  0.5000,  0.0832,  0.0710, -0.5961,  0.4000,  0.2331],\n",
       "        [-0.0982,  0.0233,  0.5000,  1.0105,  0.5158,  0.0253, -1.0000, -0.4893],\n",
       "        [-0.0864, -0.0801,  0.5000,  0.2264, -0.1209, -0.4764,  0.4000, -0.3048],\n",
       "        [-0.0747, -0.0466,  0.5000,  1.0105,  0.5158, -0.1790, -1.0000, -0.4543]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = HuggingFaceDatasetV8(load_from_disk('/opt/slh/icecube/data/hf_cashe/batch_1.parquet'))\n",
    "ds[100]['event'][:5, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = ds[0]['event'][0]\n",
    "x = ds[0]['event'][3]\n",
    "y = ds[0]['event'][4]\n",
    "z = ds[0]['event'][5]\n",
    "chage = ds[0]['event'][1]\n",
    "magnitude = torch.sqrt(x ** 2 + y ** 2 + z ** 2)\n",
    "distance = magnitude / 3 * 10 ** 8\n",
    "time_of_flight = time + distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([61, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]['event'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "# pytorch function that takes [n, x, y, z] tensor and calculates the distance between each point and returns [n x n] matrix using torch.cdist\n",
    "def get_distance_matrix(xyz):\n",
    "    return torch.cdist(xyz, xyz)\n",
    "\n",
    "\n",
    "def get_distance_matrix_for_indices(dm, indices):\n",
    "    return dm[indices][:, indices]\n",
    "\n",
    "\n",
    "def get_distance_matrix_from_csv(\n",
    "    path_to_geom=\"/opt/slh/icecube/data/sensor_geometry.csv\",\n",
    "):\n",
    "    geom = pd.read_csv(path_to_geom)[[\"x\", \"y\", \"z\"]]\n",
    "    geom = torch.tensor(geom.values, dtype=torch.float32)\n",
    "    geom = get_distance_matrix(geom)\n",
    "    # nromalize goematry matrix\n",
    "    geom = geom / geom.max()\n",
    "    return geom\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetGraphV0(Dataset):\n",
    "    def __init__(self, ds, min_adj_distance=0.015, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "        self.mad = min_adj_distance\n",
    "        self.distance_matrix_ = get_distance_matrix_from_csv()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        # getting distance matrix for event\n",
    "        distance_matrix = get_distance_matrix_for_indices(\n",
    "            self.distance_matrix_, event[\"sensor_id\"].values\n",
    "        )\n",
    "\n",
    "        dmx = torch.zeros((self.max_events, self.max_events), dtype=torch.float32)\n",
    "        dmx[: distance_matrix.shape[0], : distance_matrix.shape[1]] = distance_matrix\n",
    "        adjecent_matrix = (dmx < self.mad).type(torch.float32)\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"distance_matrix\": dmx,\n",
    "                \"adjecent_matrix\": adjecent_matrix,\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetGraphV1(Dataset):\n",
    "    def __init__(self, ds, min_adj_distance=0.05, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.mad = min_adj_distance\n",
    "        self.distance_matrix_ = get_distance_matrix_from_csv()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = (event['time'] - 1.0e04) / 3.0e4\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event['x'] /=500\n",
    "        event['y'] /=500\n",
    "        event['z'] /=500\n",
    "\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])/3.0\n",
    "\n",
    "        # getting distance matrix for event\n",
    "        distance_matrix = get_distance_matrix_for_indices(\n",
    "            self.distance_matrix_, event[\"sensor_id\"].values\n",
    "        )\n",
    "\n",
    "        dmx = torch.zeros((self.max_events, self.max_events), dtype=torch.float32)\n",
    "        dmx[: distance_matrix.shape[0], : distance_matrix.shape[1]] = distance_matrix\n",
    "        adjecent_matrix = (dmx < self.mad).type(torch.float32)\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"time\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"distance_matrix\": dmx,\n",
    "                \"adjecent_matrix\": adjecent_matrix,\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py:1536: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = HuggingFaceDatasetGraphV1(load_from_disk('/opt/slh/icecube/data/hf_cashe/batch_1.parquet'))\n",
    "sns.heatmap(ds[np.random.randint(0, len(ds))]['adjecent_matrix'].numpy())\n",
    "#dl = DataLoader(ds, batch_size=64, shuffle=True, num_workers=4, collate_fn=collate_fn_graphv0)\n",
    "#for x in dl:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def good_luck():\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class IceCubeKaggle():\n",
    "#     \"\"\"`Detector` class for Kaggle Competition.\"\"\"\n",
    "\n",
    "#     # Implementing abstract class attribute\n",
    "\n",
    "#     def _forward(self, data: Data) -> Data:\n",
    "#         \"\"\"Ingest data, build graph, and preprocess features.\n",
    "#         Args:\n",
    "#             data: Input graph data.\n",
    "#         Returns:\n",
    "#             Connected and preprocessed graph data.\n",
    "#         \"\"\"\n",
    "#         # Check(s)\n",
    "#         self._validate_features(data)\n",
    "\n",
    "#         # Preprocessing\n",
    "#         data.x[:, 0] /= 500.0  # x\n",
    "#         data.x[:, 1] /= 500.0  # y\n",
    "#         data.x[:, 2] /= 500.0  # z\n",
    "#         data.x[:, 3] = (data.x[:, 3] - 1.0e04) / 3.0e4  # time\n",
    "#         data.x[:, 4] = torch.log10(data.x[:, 4]) / 3.0  # charge\n",
    "\n",
    "#         return data\n",
    "\n",
    "# class Direction(Label):\n",
    "#     \"\"\"Class for producing particle direction/pointing label.\"\"\"\n",
    "\n",
    "#     def __init__(\n",
    "#         self, azimuth_key: str = \"azimuth\", zenith_key: str = \"zenith\"\n",
    "#     ):\n",
    "#         \"\"\"Construct `Direction`.\"\"\"\n",
    "#         self._azimuth_key = azimuth_key\n",
    "#         self._zenith_key = zenith_key\n",
    "\n",
    "#     def __call__(self, graph: Data) -> torch.tensor:\n",
    "#         \"\"\"Compute label for `graph`.\"\"\"\n",
    "#         x = torch.cos(graph[self._azimuth_key]) * torch.sin(\n",
    "#             graph[self._zenith_key]\n",
    "#         ).reshape(-1, 1)\n",
    "#         y = torch.sin(graph[self._azimuth_key]) * torch.sin(\n",
    "#             graph[self._zenith_key]\n",
    "#         ).reshape(-1, 1)\n",
    "#         z = torch.cos(graph[self._zenith_key]).reshape(-1, 1)\n",
    "#         return torch.cat((x, y, z), dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
