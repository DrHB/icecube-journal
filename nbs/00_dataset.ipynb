{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from datasets import  load_from_disk\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb import set_trace\n",
    "import seaborn as sns\n",
    "class CFG:\n",
    "    CACHE_PATH = Path('../data/cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = list((CFG.CACHE_PATH/'batch_3').glob('*.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# function that loads the data from the pth file and return the data and the label as pd.DataFrame\n",
    "def load_data(\n",
    "    fn: Path,\n",
    "    columns_event: str = [\"time\", \"charge\", \"auxiliary\", \"x\", \"y\", \"z\"],\n",
    "    columns_label: str = [\"azimuth\", \"zenith\"],\n",
    "    keep_auxiliary_event: bool = False,\n",
    "):\n",
    "    data = torch.load(fn)\n",
    "    event = pd.DataFrame.from_records(data[\"event\"])[columns_event]\n",
    "    if keep_auxiliary_event:\n",
    "        event = event.query(\"auxiliary == True\")\n",
    "    label = pd.DataFrame.from_records(data[\"target\"])[columns_label]\n",
    "    return event.astype(np.float32), label\n",
    "\n",
    "\n",
    "class IceCubeCasheDatasetV0(Dataset):\n",
    "    def __init__(self, fns, max_events=100):\n",
    "        self.fns = fns\n",
    "        self.max_events = max_events\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fn = self.fns[idx]\n",
    "        event, label = load_data(fn)\n",
    "\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = torch.tensor(event.values)\n",
    "        mask = torch.ones(len(event), dtype=torch.bool)\n",
    "        label = torch.tensor(label.values, dtype=torch.float32)\n",
    "\n",
    "        return {\"event\": event, \"mask\": mask, \"label\": label}\n",
    "\n",
    "\n",
    "class IceCubeCasheDatasetV1(Dataset):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        Dataset (_type_): Same as IceCubeCasheDatasetV0 but with the option to keep the auxiliary events\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fns, max_events=100, keep_auxiliary_event: bool = True):\n",
    "        self.fns = fns\n",
    "        self.max_events = max_events\n",
    "        self.keep_auxiliary_event = keep_auxiliary_event\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fn = self.fns[idx]\n",
    "        event, label = load_data(fn, keep_auxiliary_event=self.keep_auxiliary_event)\n",
    "\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = torch.tensor(event.values)\n",
    "        mask = torch.ones(len(event), dtype=torch.bool)\n",
    "        label = torch.tensor(label.values, dtype=torch.float32)\n",
    "\n",
    "        return {\"event\": event, \"mask\": mask, \"label\": label}\n",
    "\n",
    "\n",
    "# collate_fn that pads the event and mask to the max length in the batch using pythorch pad_sequence\n",
    "class HuggingFaceDatasetV0(Dataset):\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = event.values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "# function to normalize input between 1 and 0\n",
    "def normalize(x):\n",
    "    return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV1(Dataset):\n",
    "    \"\"\"\n",
    "    Same as HuggingFaceDatasetV0 but returns sensor_id as well\n",
    "    in addition it adds + 1 to make the sensor_id start from 1 instead of 0,\n",
    "    0 is ignore index\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        # this is done in order to shift sensor id from 0 to 1\n",
    "        # since paddding index is 0\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "\n",
    "        # feature engineering\n",
    "        event[\"w1\"] = event[\"charge\"] * event[\"time\"]\n",
    "        event[\"w0\"] = event[\"charge\"] - event[\"w1\"]\n",
    "\n",
    "        event[\"wx0\"] = event.x * event.w0\n",
    "        event[\"wy0\"] = event.y * event.w0\n",
    "        event[\"wz0\"] = event.z * event.w0\n",
    "        event[\"wx1\"] = event.x * event.w1\n",
    "        event[\"wy1\"] = event.y * event.w1\n",
    "        event[\"wz1\"] = event.z * event.w1\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"w1\",\n",
    "                \"w0\",\n",
    "                \"wx0\",\n",
    "                \"wy0\",\n",
    "                \"wz0\",\n",
    "                \"wx1\",\n",
    "                \"wy1\",\n",
    "                \"wz1\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV2(Dataset):\n",
    "    \"\"\"\n",
    "    Same as HuggingFaceDatasetV0 but returns sensor_id as well\n",
    "    in addition it adds + 1 to make the sensor_id start from 1 instead of 0,\n",
    "    0 is ignore index\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        # this is done in order to shift sensor id from 0 to 1\n",
    "        # since paddding index is 0\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV3(Dataset):\n",
    "    \"\"\"\n",
    "    Same as HuggingFaceDatasetV0 but returns sensor_id as well\n",
    "    in addition it adds + 1 to make the sensor_id start from 1 instead of 0,\n",
    "    0 is ignore index\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        # this is done in order to shift sensor id from 0 to 1\n",
    "        # since paddding index is 0\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "class HuggingFaceDatasetV4(Dataset):\n",
    "    \"\"\"\n",
    "    Same as HuggingFaceDatasetV0 but returns sensor_id as well\n",
    "    in addition it adds + 1 to make the sensor_id start from 1 instead of 0,\n",
    "    0 is ignore index\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=160):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        # this is done in order to shift sensor id from 0 to 1\n",
    "        # since paddding index is 0\n",
    "        sensor_id = event[\"sensor_id\"].values + 1\n",
    "\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"sensor_id\": torch.tensor(sensor_id, dtype=torch.int32),\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "def event_filtering_v1(batch, max_pulse_count=128, t_valid_length=6199.700247193777):\n",
    "    col = batch.columns\n",
    "    t_peak = batch[\"time\"][batch[\"charge\"].argmax()]\n",
    "    t_valid_min = t_peak - t_valid_length\n",
    "    t_valid_max = t_peak + t_valid_length\n",
    "    t_valid = (batch[\"time\"] > t_valid_min) * (batch[\"time\"] < t_valid_max)\n",
    "    batch[\"rank\"] = 2 * (1 - batch[\"auxiliary\"]) + (t_valid)\n",
    "    batch = batch.sort_values(by=[\"rank\", \"charge\"])\n",
    "    # pick-up from backward\n",
    "    batch = batch[-max_pulse_count:]\n",
    "        # resort by time\n",
    "    batch = batch.sort_values(by=\"time\")\n",
    "    return batch[col]\n",
    "        \n",
    "\n",
    "class HuggingFaceDatasetV5(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        \n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = IceCubeCasheDatasetV1(fns)\n",
    "#dl = DataLoader(ds, batch_size=64, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "# for x in dl:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py:1536: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "ds = HuggingFaceDatasetV5(load_from_disk('/opt/slh/icecube/data/hf_cashe/batch_1.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ice_transparency(\n",
    "    data_path=\"/opt/slh/icecube/data/ice_transparency.txt\", datum=1950\n",
    "):\n",
    "    # Data from page 31 of https://arxiv.org/pdf/1301.5361.pdf\n",
    "    # Datum is from footnote 8 of page 29\n",
    "    df = pd.read_csv(data_path, delim_whitespace=True)\n",
    "    df[\"z\"] = df[\"depth\"] - datum\n",
    "    df[\"z_norm\"] = df[\"z\"] / 500\n",
    "    df[[\"scattering_len_norm\", \"absorption_len_norm\"]] = RobustScaler().fit_transform(\n",
    "        df[[\"scattering_len\", \"absorption_len\"]]\n",
    "    )\n",
    "\n",
    "    # These are both roughly equivalent after scaling\n",
    "    f_scattering = interp1d(df[\"z_norm\"], df[\"scattering_len_norm\"])\n",
    "    f_absorption = interp1d(df[\"z_norm\"], df[\"absorption_len_norm\"])\n",
    "    return f_scattering, f_absorption\n",
    "\n",
    "def prepare_sensors():\n",
    "    sensors = pd.read_csv('/opt/slh/icecube/data/sensor_geometry.csv').astype(\n",
    "        {\n",
    "            \"sensor_id\": np.int16,\n",
    "            \"x\": np.float32,\n",
    "            \"y\": np.float32,\n",
    "            \"z\": np.float32,\n",
    "        }\n",
    "    )\n",
    "    sensors[\"string\"] = 0\n",
    "    sensors[\"qe\"] = 1\n",
    "\n",
    "    for i in range(len(sensors) // 60):\n",
    "        start, end = i * 60, (i * 60) + 60\n",
    "        sensors.loc[start:end, \"string\"] = i\n",
    "\n",
    "        # High Quantum Efficiency in the lower 50 DOMs - https://arxiv.org/pdf/2209.03042.pdf (Figure 1)\n",
    "        if i in range(78, 86):\n",
    "            start_veto, end_veto = i * 60, (i * 60) + 10\n",
    "            start_core, end_core = end_veto + 1, (i * 60) + 60\n",
    "            sensors.loc[start_core:end_core, \"qe\"] = 1.35\n",
    "\n",
    "    # https://github.com/graphnet-team/graphnet/blob/b2bad25528652587ab0cdb7cf2335ee254cfa2db/src/graphnet/models/detector/icecube.py#L33-L41\n",
    "    # Assume that \"rde\" (relative dom efficiency) is equivalent to QE\n",
    "    sensors[\"x\"] /= 500\n",
    "    sensors[\"y\"] /= 500\n",
    "    sensors[\"z\"] /= 500\n",
    "    sensors[\"qe\"] -= 1.25\n",
    "    sensors[\"qe\"] /= 0.25\n",
    "\n",
    "    return sensors.set_index(\"sensor_id\")[['qe']]\n",
    "\n",
    "\n",
    "def convert_to_3d(azimuth, zenith):\n",
    "    \"\"\"Converts zenith and azimuth to 3D direction vectors\"\"\"\n",
    "    x = np.cos(azimuth) * np.sin(zenith)\n",
    "    y = np.sin(azimuth) * np.sin(zenith)\n",
    "    z = np.cos(zenith)\n",
    "    return np.array([x, y, z], dtype=np.float32)\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV6(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV7(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV8(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=148):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetV9(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event[\"absorption\"] = self.f_absorption(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "                \"absorption\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py:1536: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([61, 9])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = HuggingFaceDatasetV9(load_from_disk('/opt/slh/icecube/data/hf_cashe/batch_1.parquet'))\n",
    "ds[0]['event'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = ds[0]['event'][0]\n",
    "x = ds[0]['event'][3]\n",
    "y = ds[0]['event'][4]\n",
    "z = ds[0]['event'][5]\n",
    "chage = ds[0]['event'][1]\n",
    "magnitude = torch.sqrt(x ** 2 + y ** 2 + z ** 2)\n",
    "distance = magnitude / 3 * 10 ** 8\n",
    "time_of_flight = time + distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([61, 9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]['event'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "# pytorch function that takes [n, x, y, z] tensor and calculates the distance between each point and returns [n x n] matrix using torch.cdist\n",
    "def get_distance_matrix(xyz):\n",
    "    return torch.cdist(xyz, xyz)\n",
    "\n",
    "\n",
    "def get_distance_matrix_for_indices(dm, indices):\n",
    "    return dm[indices][:, indices]\n",
    "\n",
    "\n",
    "def get_distance_matrix_from_csv(\n",
    "    path_to_geom=\"/opt/slh/icecube/data/sensor_geometry.csv\",\n",
    "):\n",
    "    geom = pd.read_csv(path_to_geom)[[\"x\", \"y\", \"z\"]]\n",
    "    geom = torch.tensor(geom.values, dtype=torch.float32)\n",
    "    geom = get_distance_matrix(geom)\n",
    "    # nromalize goematry matrix\n",
    "    geom = geom / geom.max()\n",
    "    return geom\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetGraphV0(Dataset):\n",
    "    def __init__(self, ds, min_adj_distance=0.015, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.geom_max = np.array([576.37, 509.5, 524.56])\n",
    "        self.geom_min = np.array([[-570.9, -521.08, -512.82]])\n",
    "        self.mad = min_adj_distance\n",
    "        self.distance_matrix_ = get_distance_matrix_from_csv()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = 1 - normalize(event[\"time\"])\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event[[\"x\", \"y\", \"z\"]] = (event[[\"x\", \"y\", \"z\"]].values - self.geom_min) / (\n",
    "            self.geom_max - self.geom_min\n",
    "        )\n",
    "\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        # getting distance matrix for event\n",
    "        distance_matrix = get_distance_matrix_for_indices(\n",
    "            self.distance_matrix_, event[\"sensor_id\"].values\n",
    "        )\n",
    "\n",
    "        dmx = torch.zeros((self.max_events, self.max_events), dtype=torch.float32)\n",
    "        dmx[: distance_matrix.shape[0], : distance_matrix.shape[1]] = distance_matrix\n",
    "        adjecent_matrix = (dmx < self.mad).type(torch.float32)\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"distance_matrix\": dmx,\n",
    "                \"adjecent_matrix\": adjecent_matrix,\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "class HuggingFaceDatasetGraphV1(Dataset):\n",
    "    def __init__(self, ds, min_adj_distance=0.05, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.mad = min_adj_distance\n",
    "        self.distance_matrix_ = get_distance_matrix_from_csv()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"sensor_id\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        # in this way the time start at 0 and end at 1\n",
    "        event[\"time\"] = (event['time'] - 1.0e04) / 3.0e4\n",
    "\n",
    "        # normalize the x,y,z coordinates of geomatry\n",
    "        # TO DO add this in to preprocessing\n",
    "        event['x'] /=500\n",
    "        event['y'] /=500\n",
    "        event['z'] /=500\n",
    "\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])/3.0\n",
    "\n",
    "        # getting distance matrix for event\n",
    "        distance_matrix = get_distance_matrix_for_indices(\n",
    "            self.distance_matrix_, event[\"sensor_id\"].values\n",
    "        )\n",
    "\n",
    "        dmx = torch.zeros((self.max_events, self.max_events), dtype=torch.float32)\n",
    "        dmx[: distance_matrix.shape[0], : distance_matrix.shape[1]] = distance_matrix\n",
    "        adjecent_matrix = (dmx < self.mad).type(torch.float32)\n",
    "\n",
    "        event = event[\n",
    "            [\n",
    "\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"time\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"distance_matrix\": dmx,\n",
    "                \"adjecent_matrix\": adjecent_matrix,\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py:1536: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = HuggingFaceDatasetGraphV1(load_from_disk('/opt/slh/icecube/data/hf_cashe/batch_1.parquet'))\n",
    "sns.heatmap(ds[np.random.randint(0, len(ds))]['adjecent_matrix'].numpy())\n",
    "#dl = DataLoader(ds, batch_size=64, shuffle=True, num_workers=4, collate_fn=collate_fn_graphv0)\n",
    "#for x in dl:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def good_luck():\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class IceCubeKaggle():\n",
    "#     \"\"\"`Detector` class for Kaggle Competition.\"\"\"\n",
    "\n",
    "#     # Implementing abstract class attribute\n",
    "\n",
    "#     def _forward(self, data: Data) -> Data:\n",
    "#         \"\"\"Ingest data, build graph, and preprocess features.\n",
    "#         Args:\n",
    "#             data: Input graph data.\n",
    "#         Returns:\n",
    "#             Connected and preprocessed graph data.\n",
    "#         \"\"\"\n",
    "#         # Check(s)\n",
    "#         self._validate_features(data)\n",
    "\n",
    "#         # Preprocessing\n",
    "#         data.x[:, 0] /= 500.0  # x\n",
    "#         data.x[:, 1] /= 500.0  # y\n",
    "#         data.x[:, 2] /= 500.0  # z\n",
    "#         data.x[:, 3] = (data.x[:, 3] - 1.0e04) / 3.0e4  # time\n",
    "#         data.x[:, 4] = torch.log10(data.x[:, 4]) / 3.0  # charge\n",
    "\n",
    "#         return data\n",
    "\n",
    "# class Direction(Label):\n",
    "#     \"\"\"Class for producing particle direction/pointing label.\"\"\"\n",
    "\n",
    "#     def __init__(\n",
    "#         self, azimuth_key: str = \"azimuth\", zenith_key: str = \"zenith\"\n",
    "#     ):\n",
    "#         \"\"\"Construct `Direction`.\"\"\"\n",
    "#         self._azimuth_key = azimuth_key\n",
    "#         self._zenith_key = zenith_key\n",
    "\n",
    "#     def __call__(self, graph: Data) -> torch.tensor:\n",
    "#         \"\"\"Compute label for `graph`.\"\"\"\n",
    "#         x = torch.cos(graph[self._azimuth_key]) * torch.sin(\n",
    "#             graph[self._zenith_key]\n",
    "#         ).reshape(-1, 1)\n",
    "#         y = torch.sin(graph[self._azimuth_key]) * torch.sin(\n",
    "#             graph[self._zenith_key]\n",
    "#         ).reshape(-1, 1)\n",
    "#         z = torch.cos(graph[self._zenith_key]).reshape(-1, 1)\n",
    "#         return torch.cat((x, y, z), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_distance_matrix_from_csv()[:50,:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adjacent_matrix_from_distance_matrix(distance_matrix):\n",
    "    n = distance_matrix.shape[0]\n",
    "    adjacency_matrix = torch.zeros((n, n), dtype=torch.bool)\n",
    "    \n",
    "    for i in range(n):\n",
    "        nearest_neighbors = torch.argsort(distance_matrix[i])[1:9]\n",
    "        adjacency_matrix[i, nearest_neighbors] = 1\n",
    "        \n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(create_adjacent_matrix_from_distance_matrix(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyzt = ds[0]['event'][:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(create_adjacent_matrix_from_distance_matrix(torch.cdist(xyzt, xyzt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuggingFaceDatasetX(Dataset):\n",
    "    \"\"\"\n",
    "    dataset with event filtering up to 128\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ds, max_events=128):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "        self.f_scattering, self.f_absorption = ice_transparency()\n",
    "        self.sensor_data = prepare_sensors()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"sensor_id\"\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        t = (event[\"time\"].values - 1.0e04) / 3.0e4\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "\n",
    "        if event.shape[0] > self.max_events:\n",
    "            event = event_filtering_v1(event, max_pulse_count=self.max_events)\n",
    "\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"]) / 3.0\n",
    "        event[\"auxiliary\"] -= 0.5\n",
    "\n",
    "        event[\"time\"] = t[: self.max_events]\n",
    "        event[\"scattering\"] = self.f_scattering(event[\"z\"].values).reshape(-1)\n",
    "        event[\"absorption\"] = self.f_absorption(event[\"z\"].values).reshape(-1)\n",
    "        event['qe'] = self.sensor_data.loc[event['sensor_id'].values].values.reshape(-1)\n",
    "        event = event[\n",
    "            [\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"qe\",\n",
    "                \"scattering\",\n",
    "                \"absorption\",\n",
    "            ]\n",
    "        ].values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = convert_to_3d(item[\"azimuth\"], item[\"zenith\"])\n",
    "        #print(item[\"azimuth\"], item[\"zenith\"])\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event, dtype=torch.float32),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "    \n",
    "    \n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Dataset as gDataset\n",
    "from torch_geometric.loader import DataLoader as gDataLoader\n",
    "from graphnet.models.graph_builders import KNNGraphBuilder\n",
    "\n",
    "pre_transform = KNNGraphBuilder(nb_nearest_neighbours=8)\n",
    "\n",
    "class IceCubeSubmissionDataset(gDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ds,\n",
    "        pulse_limit=300,\n",
    "        transform=None,\n",
    "        pre_transform=pre_transform,\n",
    "        pre_filter=None,\n",
    "    ):\n",
    "        super().__init__(transform, pre_transform, pre_filter)\n",
    "        self.ds = ds\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def get(self, idx):\n",
    "        batch = self.ds[0]\n",
    "        data = Data(x=batch['event'], \n",
    "                    pos= batch['event'][:, :3],\n",
    "                    n_pulses=torch.tensor(batch['event'].shape[0],\n",
    "                                          dtype=torch.int32))\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py:1536: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "ds = IceCubeSubmissionDataset(ds=HuggingFaceDatasetX(load_from_disk('/opt/slh/icecube/data/hf_cashe/batch_1.parquet')), \n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdl = gDataLoader(ds, batch_size=10, shuffle=False, num_workers=1)\n",
    "batch = next(iter(gdl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, Union\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import  global_add_pool, global_mean_pool\n",
    "import torch_scatter\n",
    "from torch_scatter import scatter\n",
    "\n",
    "import torch\n",
    "from torch.nn import Linear, ReLU, SiLU, Sequential\n",
    "from torch_geometric.nn import MessagePassing, global_add_pool, global_mean_pool\n",
    "from torch_scatter import scatter\n",
    "\n",
    "\n",
    "class EGNNLayer(MessagePassing):\n",
    "    def __init__(self, emb_dim, activation=\"relu\", norm=\"layer\", aggr=\"add\"):\n",
    "        \"\"\"E(n) Equivariant GNN Layer\n",
    "        Paper: E(n) Equivariant Graph Neural Networks, Satorras et al.\n",
    "        \n",
    "        Args:\n",
    "            emb_dim: (int) - hidden dimension `d`\n",
    "            activation: (str) - non-linearity within MLPs (swish/relu)\n",
    "            norm: (str) - normalisation layer (layer/batch)\n",
    "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
    "        \"\"\"\n",
    "        # Set the aggregation function\n",
    "        super().__init__(aggr=aggr)\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.activation = {\"swish\": SiLU(), \"relu\": ReLU()}[activation]\n",
    "        self.norm = {\"layer\": torch.nn.LayerNorm, \"batch\": torch.nn.BatchNorm1d}[norm]\n",
    "\n",
    "        # MLP `\\psi_h` for computing messages `m_ij`\n",
    "        self.mlp_msg = Sequential(\n",
    "            Linear(2 * emb_dim + 1, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "            Linear(emb_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "        )\n",
    "        # MLP `\\psi_x` for computing messages `\\overrightarrow{m}_ij`\n",
    "        self.mlp_pos = Sequential(\n",
    "            Linear(emb_dim, emb_dim), self.norm(emb_dim), self.activation, Linear(emb_dim, 1)\n",
    "        )\n",
    "        # MLP `\\phi` for computing updated node features `h_i^{l+1}`\n",
    "        self.mlp_upd = Sequential(\n",
    "            Linear(2 * emb_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "            Linear(emb_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "        )\n",
    "\n",
    "    def forward(self, h, pos, edge_index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            h: (n, d) - initial node features\n",
    "            pos: (n, 3) - initial node coordinates\n",
    "            edge_index: (e, 2) - pairs of edges (i, j)\n",
    "        Returns:\n",
    "            out: [(n, d),(n,3)] - updated node features\n",
    "        \"\"\"\n",
    "        out = self.propagate(edge_index, h=h, pos=pos)\n",
    "        return out\n",
    "\n",
    "    def message(self, h_i, h_j, pos_i, pos_j):\n",
    "        # Compute messages\n",
    "        pos_diff = pos_i - pos_j\n",
    "        dists = torch.norm(pos_diff, dim=-1).unsqueeze(1)\n",
    "        msg = torch.cat([h_i, h_j, dists], dim=-1)\n",
    "        msg = self.mlp_msg(msg)\n",
    "        # Scale magnitude of displacement vector\n",
    "        pos_diff = pos_diff * self.mlp_pos(msg)  # torch.clamp(updates, min=-100, max=100)\n",
    "        return msg, pos_diff\n",
    "\n",
    "    def aggregate(self, inputs, index):\n",
    "        msgs, pos_diffs = inputs\n",
    "        # Aggregate messages\n",
    "        msg_aggr = scatter(msgs, index, dim=self.node_dim, reduce=self.aggr)\n",
    "        # Aggregate displacement vectors\n",
    "        pos_aggr = scatter(pos_diffs, index, dim=self.node_dim, reduce=\"mean\")\n",
    "        return msg_aggr, pos_aggr\n",
    "\n",
    "    def update(self, aggr_out, h, pos):\n",
    "        msg_aggr, pos_aggr = aggr_out\n",
    "        upd_out = self.mlp_upd(torch.cat([h, msg_aggr], dim=-1))\n",
    "        upd_pos = pos + pos_aggr\n",
    "        return upd_out, upd_pos\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})\"\n",
    "\n",
    "\n",
    "class MPNNLayer(MessagePassing):\n",
    "    def __init__(self, emb_dim, activation=\"relu\", norm=\"layer\", aggr=\"add\"):\n",
    "        \"\"\"Vanilla Message Passing GNN layer\n",
    "        \n",
    "        Args:\n",
    "            emb_dim: (int) - hidden dimension `d`\n",
    "            activation: (str) - non-linearity within MLPs (swish/relu)\n",
    "            norm: (str) - normalisation layer (layer/batch)\n",
    "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
    "        \"\"\"\n",
    "        # Set the aggregation function\n",
    "        super().__init__(aggr=aggr)\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.activation = {\"swish\": SiLU(), \"relu\": ReLU()}[activation]\n",
    "        self.norm = {\"layer\": torch.nn.LayerNorm, \"batch\": torch.nn.BatchNorm1d}[norm]\n",
    "\n",
    "        # MLP `\\psi_h` for computing messages `m_ij`\n",
    "        self.mlp_msg = Sequential(\n",
    "            Linear(2 * emb_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "            Linear(emb_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "        )\n",
    "        # MLP `\\phi` for computing updated node features `h_i^{l+1}`\n",
    "        self.mlp_upd = Sequential(\n",
    "            Linear(2 * emb_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "            Linear(emb_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "        )\n",
    "\n",
    "    def forward(self, h, edge_index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            h: (n, d) - initial node features\n",
    "            edge_index: (e, 2) - pairs of edges (i, j)\n",
    "        Returns:\n",
    "            out: (n, d) - updated node features\n",
    "        \"\"\"\n",
    "        out = self.propagate(edge_index, h=h)\n",
    "        return out\n",
    "\n",
    "    def message(self, h_i, h_j):\n",
    "        # Compute messages\n",
    "        msg = torch.cat([h_i, h_j], dim=-1)\n",
    "        msg = self.mlp_msg(msg)\n",
    "        return msg\n",
    "\n",
    "    def aggregate(self, inputs, index):\n",
    "        # Aggregate messages\n",
    "        msg_aggr = scatter(inputs, index, dim=self.node_dim, reduce=self.aggr)\n",
    "        return msg_aggr\n",
    "\n",
    "    def update(self, aggr_out, h):\n",
    "        upd_out = self.mlp_upd(torch.cat([h, aggr_out], dim=-1))\n",
    "        return upd_out\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})\"\n",
    "    \n",
    "class EGNNModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers=5,\n",
    "        emb_dim=128,\n",
    "        in_dim=9,\n",
    "        out_dim=3,\n",
    "        activation=\"relu\",\n",
    "        norm=\"layer\",\n",
    "        aggr=\"sum\",\n",
    "        pool=\"sum\",\n",
    "        residual=True\n",
    "    ):\n",
    "        \"\"\"E(n) Equivariant GNN model \n",
    "        \n",
    "        Args:\n",
    "            num_layers: (int) - number of message passing layers\n",
    "            emb_dim: (int) - hidden dimension\n",
    "            in_dim: (int) - initial node feature dimension\n",
    "            out_dim: (int) - output number of classes\n",
    "            activation: (str) - non-linearity within MLPs (swish/relu)\n",
    "            norm: (str) - normalisation layer (layer/batch)\n",
    "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
    "            pool: (str) - global pooling function (sum/mean)\n",
    "            residual: (bool) - whether to use residual connections\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding lookup for initial node features\n",
    "        self.emb_in = torch.nn.Linear(in_dim, emb_dim)\n",
    "\n",
    "        # Stack of GNN layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.convs.append(EGNNLayer(emb_dim, activation, norm, aggr))\n",
    "\n",
    "        # Global pooling/readout function\n",
    "        self.pool = {\"mean\": global_mean_pool, \"sum\": global_add_pool}[pool]\n",
    "\n",
    "        # Predictor MLP\n",
    "        self.pred = torch.nn.Sequential(\n",
    "            torch.nn.Linear(emb_dim, emb_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(emb_dim, out_dim)\n",
    "        )\n",
    "        self.residual = residual\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \n",
    "        h = self.emb_in(batch.x)  # (n,) -> (n, d)\n",
    "        pos = batch.pos  # (n, 3)\n",
    "\n",
    "        for conv in self.convs:\n",
    "            # Message passing layer\n",
    "            h_update, pos_update = conv(h, pos, batch.edge_index)\n",
    "\n",
    "            # Update node features (n, d) -> (n, d)\n",
    "            h = h + h_update if self.residual else h_update \n",
    "\n",
    "            # Update node coordinates (no residual) (n, 3) -> (n, 3)\n",
    "            pos = pos_update\n",
    "\n",
    "        out = self.pool(h, batch.batch)  # (n, d) -> (batch_size, d)\n",
    "        return self.pred(out)  # (batch_size, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphnet.models.utils import calculate_xyzt_homophily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EGNNModel(\n",
       "  (emb_in): Linear(in_features=9, out_features=128, bias=True)\n",
       "  (convs): ModuleList(\n",
       "    (0): EGNNLayer(emb_dim=128, aggr=sum)\n",
       "    (1): EGNNLayer(emb_dim=128, aggr=sum)\n",
       "    (2): EGNNLayer(emb_dim=128, aggr=sum)\n",
       "    (3): EGNNLayer(emb_dim=128, aggr=sum)\n",
       "    (4): EGNNLayer(emb_dim=128, aggr=sum)\n",
       "  )\n",
       "  (pred): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EGNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_max, scatter_mean, scatter_min, scatter_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_means = scatter_mean(batch.x, batch.batch, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 9])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2520],\n",
       "         [0.2520],\n",
       "         [0.2520],\n",
       "         [0.2520],\n",
       "         [0.2520],\n",
       "         [0.2520],\n",
       "         [0.2520],\n",
       "         [0.2520],\n",
       "         [0.2520],\n",
       "         [0.2520]]),\n",
       " tensor([[0.2520],\n",
       "         [0.2520],\n",
       "         [0.2520],\n",
       "         [0.2520],\n",
       "         [0.2520],\n",
       "         [0.2520],\n",
       "         [0.2520],\n",
       "         [0.2520],\n",
       "         [0.2520],\n",
       "         [0.2520]]),\n",
       " tensor([[0.0656],\n",
       "         [0.0656],\n",
       "         [0.0656],\n",
       "         [0.0656],\n",
       "         [0.0656],\n",
       "         [0.0656],\n",
       "         [0.0656],\n",
       "         [0.0656],\n",
       "         [0.0656],\n",
       "         [0.0656]]),\n",
       " tensor([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_xyzt_homophily(batch.x, batch.edge_index, batch.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = EGNN_Network(\n",
    "    num_tokens = 8,\n",
    "    num_positions = 1024,           # unless what you are passing in is an unordered set, set this to the maximum sequence length\n",
    "    dim = 32,\n",
    "    depth = 3,\n",
    "    num_nearest_neighbors = 8,\n",
    "    coor_weights_clamp_value = 2.,  \n",
    "    update_coors = False,\n",
    ")\n",
    "\n",
    "feats = torch.randn(1, 128, 8) # (1, 1024)\n",
    "coors = torch.randn(1, 128, 3)         # (1, 1024, 3)\n",
    "mask = torch.ones_like(torch.rand(1, 128)).bool()    # (1, 1024)\n",
    "\n",
    "out = net(feats, coors, mask = mask) # (1, 1024, 32), (1, 1024, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6222, -0.6894,  1.4351,  ...,  0.6770, -0.1985, -0.3066],\n",
       "         [ 0.1334,  0.5690,  1.1985,  ...,  0.5571,  1.1911,  0.2584],\n",
       "         [-0.7382, -2.4675, -2.0786,  ...,  0.1279, -0.0603,  0.6245],\n",
       "         ...,\n",
       "         [-1.5872, -1.0584, -2.1567,  ..., -1.0447,  0.5525, -0.3704],\n",
       "         [-1.5893, -0.8412, -1.3699,  ...,  0.2627, -1.1399, -1.2501],\n",
       "         [ 1.4129, -0.6143,  0.7806,  ...,  0.3414,  2.3914,  0.5984]]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EGNN_Network(\n",
       "  (token_emb): Linear(in_features=8, out_features=32, bias=True)\n",
       "  (pos_emb): Embedding(1024, 32)\n",
       "  (layers): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): None\n",
       "      (1): EGNN(\n",
       "        (edge_mlp): Sequential(\n",
       "          (0): Linear(in_features=65, out_features=130, bias=True)\n",
       "          (1): Identity()\n",
       "          (2): SiLU()\n",
       "          (3): Linear(in_features=130, out_features=16, bias=True)\n",
       "          (4): SiLU()\n",
       "        )\n",
       "        (node_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (coors_norm): Identity()\n",
       "        (node_mlp): Sequential(\n",
       "          (0): Linear(in_features=48, out_features=64, bias=True)\n",
       "          (1): Identity()\n",
       "          (2): SiLU()\n",
       "          (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "        )\n",
       "        (coors_mlp): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "          (1): Identity()\n",
       "          (2): SiLU()\n",
       "          (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): None\n",
       "      (1): EGNN(\n",
       "        (edge_mlp): Sequential(\n",
       "          (0): Linear(in_features=65, out_features=130, bias=True)\n",
       "          (1): Identity()\n",
       "          (2): SiLU()\n",
       "          (3): Linear(in_features=130, out_features=16, bias=True)\n",
       "          (4): SiLU()\n",
       "        )\n",
       "        (node_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (coors_norm): Identity()\n",
       "        (node_mlp): Sequential(\n",
       "          (0): Linear(in_features=48, out_features=64, bias=True)\n",
       "          (1): Identity()\n",
       "          (2): SiLU()\n",
       "          (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "        )\n",
       "        (coors_mlp): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "          (1): Identity()\n",
       "          (2): SiLU()\n",
       "          (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): None\n",
       "      (1): EGNN(\n",
       "        (edge_mlp): Sequential(\n",
       "          (0): Linear(in_features=65, out_features=130, bias=True)\n",
       "          (1): Identity()\n",
       "          (2): SiLU()\n",
       "          (3): Linear(in_features=130, out_features=16, bias=True)\n",
       "          (4): SiLU()\n",
       "        )\n",
       "        (node_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (coors_norm): Identity()\n",
       "        (node_mlp): Sequential(\n",
       "          (0): Linear(in_features=48, out_features=64, bias=True)\n",
       "          (1): Identity()\n",
       "          (2): SiLU()\n",
       "          (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "        )\n",
       "        (coors_mlp): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "          (1): Identity()\n",
       "          (2): SiLU()\n",
       "          (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
