{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp modelsgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import sys\n",
    "sys.path.append('/opt/slh/archive/software/graphnet/src')\n",
    "\n",
    "\n",
    "from x_transformers import ContinuousTransformerWrapper, Encoder, Decoder\n",
    "from graphnet.models.task.reconstruction import DirectionReconstructionWithKappa\n",
    "from graphnet.training.loss_functions import VonMisesFisher3DLoss\n",
    "from graphnet.training.labels import Direction\n",
    "\n",
    "from typing import Callable, Optional, Union\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import SchNet, global_add_pool, global_mean_pool\n",
    "import torch_scatter\n",
    "from torch_scatter import scatter\n",
    "from torch.nn import Linear, ReLU, SiLU, Sequential\n",
    "from torch_geometric.nn import MessagePassing, global_add_pool, global_mean_pool\n",
    "from torch_scatter import scatter\n",
    "from torch_geometric.loader import DataLoader as gDataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/opt/slh/icecube')\n",
    "from icecube.graphdataset import GraphDasetV0\n",
    "from datasets import  load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class EGNNLayer(MessagePassing):\n",
    "    def __init__(self, emb_dim, activation=\"relu\", norm=\"layer\", aggr=\"add\"):\n",
    "        \"\"\"E(n) Equivariant GNN Layer\n",
    "        Paper: E(n) Equivariant Graph Neural Networks, Satorras et al.\n",
    "        \n",
    "        Args:\n",
    "            emb_dim: (int) - hidden dimension `d`\n",
    "            activation: (str) - non-linearity within MLPs (swish/relu)\n",
    "            norm: (str) - normalisation layer (layer/batch)\n",
    "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
    "        \"\"\"\n",
    "        # Set the aggregation function\n",
    "        super().__init__(aggr=aggr)\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.activation = {\"swish\": SiLU(), \"relu\": ReLU()}[activation]\n",
    "        self.norm = {\"layer\": torch.nn.LayerNorm, \"batch\": torch.nn.BatchNorm1d}[norm]\n",
    "\n",
    "        # MLP `\\psi_h` for computing messages `m_ij`\n",
    "        self.mlp_msg = Sequential(\n",
    "            Linear(2 * emb_dim + 1, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "            Linear(emb_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "        )\n",
    "        # MLP `\\psi_x` for computing messages `\\overrightarrow{m}_ij`\n",
    "        self.mlp_pos = Sequential(\n",
    "            Linear(emb_dim, emb_dim), self.norm(emb_dim), self.activation, Linear(emb_dim, 1)\n",
    "        )\n",
    "        # MLP `\\phi` for computing updated node features `h_i^{l+1}`\n",
    "        self.mlp_upd = Sequential(\n",
    "            Linear(2 * emb_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "            Linear(emb_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "        )\n",
    "\n",
    "    def forward(self, h, pos, edge_index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            h: (n, d) - initial node features\n",
    "            pos: (n, 3) - initial node coordinates\n",
    "            edge_index: (e, 2) - pairs of edges (i, j)\n",
    "        Returns:\n",
    "            out: [(n, d),(n,3)] - updated node features\n",
    "        \"\"\"\n",
    "        out = self.propagate(edge_index, h=h, pos=pos)\n",
    "        return out\n",
    "\n",
    "    def message(self, h_i, h_j, pos_i, pos_j):\n",
    "        # Compute messages\n",
    "        pos_diff = pos_i - pos_j\n",
    "        dists = torch.norm(pos_diff, dim=-1).unsqueeze(1)\n",
    "        msg = torch.cat([h_i, h_j, dists], dim=-1)\n",
    "        msg = self.mlp_msg(msg)\n",
    "        # Scale magnitude of displacement vector\n",
    "        pos_diff = pos_diff * self.mlp_pos(msg)  # torch.clamp(updates, min=-100, max=100)\n",
    "        return msg, pos_diff\n",
    "\n",
    "    def aggregate(self, inputs, index):\n",
    "        msgs, pos_diffs = inputs\n",
    "        # Aggregate messages\n",
    "        msg_aggr = scatter(msgs, index, dim=self.node_dim, reduce=self.aggr)\n",
    "        # Aggregate displacement vectors\n",
    "        pos_aggr = scatter(pos_diffs, index, dim=self.node_dim, reduce=\"mean\")\n",
    "        return msg_aggr, pos_aggr\n",
    "\n",
    "    def update(self, aggr_out, h, pos):\n",
    "        msg_aggr, pos_aggr = aggr_out\n",
    "        upd_out = self.mlp_upd(torch.cat([h, msg_aggr], dim=-1))\n",
    "        upd_pos = pos + pos_aggr\n",
    "        return upd_out, upd_pos\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})\"\n",
    "    \n",
    "    \n",
    "class EGNNModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers=5,\n",
    "        emb_dim=128,\n",
    "        in_dim=9,\n",
    "        out_dim=4,\n",
    "        activation=\"relu\",\n",
    "        norm=\"layer\",\n",
    "        aggr=\"sum\",\n",
    "        pool=\"sum\",\n",
    "        residual=True\n",
    "    ):\n",
    "        \"\"\"E(n) Equivariant GNN model \n",
    "        \n",
    "        Args:\n",
    "            num_layers: (int) - number of message passing layers\n",
    "            emb_dim: (int) - hidden dimension\n",
    "            in_dim: (int) - initial node feature dimension\n",
    "            out_dim: (int) - output number of classes\n",
    "            activation: (str) - non-linearity within MLPs (swish/relu)\n",
    "            norm: (str) - normalisation layer (layer/batch)\n",
    "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
    "            pool: (str) - global pooling function (sum/mean)\n",
    "            residual: (bool) - whether to use residual connections\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding lookup for initial node features\n",
    "        self.emb_in = nn.Linear(in_dim, emb_dim)\n",
    "\n",
    "        # Stack of GNN layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.convs.append(EGNNLayer(emb_dim, activation, norm, aggr))\n",
    "\n",
    "        # Global pooling/readout function\n",
    "        self.pool = {\"mean\": global_mean_pool, \"sum\": global_add_pool}[pool]\n",
    "\n",
    "        # Predictor MLP\n",
    "        self.postpool = torch.nn.Sequential(\n",
    "            torch.nn.Linear(emb_dim, emb_dim),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.out = DirectionReconstructionWithKappa(\n",
    "            hidden_size=emb_dim,\n",
    "            target_labels='direction',\n",
    "            loss_function=VonMisesFisher3DLoss(),\n",
    "        )\n",
    "\n",
    "        self.residual = residual\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \n",
    "        h = self.emb_in(batch.x)  # (n,) -> (n, d)\n",
    "        pos = batch.pos  # (n, 3)\n",
    "\n",
    "        for conv in self.convs:\n",
    "            # Message passing layer\n",
    "            h_update, pos_update = conv(h, pos, batch.edge_index)\n",
    "\n",
    "            # Update node features (n, d) -> (n, d)\n",
    "            h = h + h_update if self.residual else h_update \n",
    "\n",
    "            # Update node coordinates (no residual) (n, 3) -> (n, 3)\n",
    "            pos = pos_update\n",
    "\n",
    "        out = self.pool(h, batch.batch)  # (n, d) -> (batch_size, d)\n",
    "        out = self.postpool(out) \n",
    "        out = self.out(out)  # (batch_size, d) -> (batch_size, 1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py:1536: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "ds = GraphDasetV0(load_from_disk('/opt/slh/icecube/data/hf_cashe/batch_1.parquet'))\n",
    "dl = gDataLoader(ds, batch_size=64, shuffle=True)\n",
    "x = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = EGNNModel().eval()\n",
    "with torch.no_grad():\n",
    "    out = md(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.3360e-01,  7.8692e-01, -4.3903e-01],\n",
       "        [ 3.5603e-01, -6.5630e-01,  6.6522e-01],\n",
       "        [ 5.6932e-01,  5.3317e-01,  6.2578e-01],\n",
       "        [-8.7482e-01, -4.5451e-01,  1.6765e-01],\n",
       "        [-8.0436e-01, -4.1511e-01, -4.2506e-01],\n",
       "        [-4.7833e-01,  1.7376e-01,  8.6082e-01],\n",
       "        [ 2.5790e-01,  9.4348e-01, -2.0815e-01],\n",
       "        [-7.0665e-02,  9.0034e-01,  4.2940e-01],\n",
       "        [ 4.8997e-01,  2.4937e-02, -8.7138e-01],\n",
       "        [ 7.0611e-01,  1.3525e-01, -6.9506e-01],\n",
       "        [ 4.0584e-01, -9.1394e-01, -7.8477e-04],\n",
       "        [-8.5595e-01,  3.1931e-01, -4.0668e-01],\n",
       "        [-6.3817e-02, -8.8359e-01,  4.6389e-01],\n",
       "        [-7.1645e-01,  6.9421e-01, -6.9115e-02],\n",
       "        [-1.7384e-01, -9.2958e-01,  3.2505e-01],\n",
       "        [ 2.4919e-01, -9.6507e-01, -8.0927e-02],\n",
       "        [ 6.3849e-01, -1.8381e-01, -7.4736e-01],\n",
       "        [-4.6091e-01, -2.2264e-01, -8.5907e-01],\n",
       "        [ 1.3469e-01,  8.9402e-01,  4.2731e-01],\n",
       "        [ 3.2838e-01,  1.9967e-01, -9.2320e-01],\n",
       "        [-1.0364e-01, -9.8620e-01,  1.2914e-01],\n",
       "        [-5.4188e-01,  8.0393e-01, -2.4505e-01],\n",
       "        [-4.1952e-01,  2.5953e-01,  8.6986e-01],\n",
       "        [ 9.4323e-01, -2.1470e-01,  2.5343e-01],\n",
       "        [ 9.0013e-01,  4.0834e-01,  1.5175e-01],\n",
       "        [-5.5295e-01, -8.2504e-01, -1.1643e-01],\n",
       "        [-4.1240e-02, -4.2804e-01, -9.0282e-01],\n",
       "        [-3.1070e-01,  2.7951e-02,  9.5010e-01],\n",
       "        [ 1.3485e-01,  8.1320e-01, -5.6615e-01],\n",
       "        [ 7.5326e-01,  4.3044e-01,  4.9731e-01],\n",
       "        [ 7.1648e-01,  5.2738e-01,  4.5665e-01],\n",
       "        [-7.4542e-01,  6.6649e-01,  1.1468e-02],\n",
       "        [-7.2780e-01,  5.7443e-01,  3.7462e-01],\n",
       "        [-2.3226e-01, -9.7012e-01, -7.0126e-02],\n",
       "        [ 4.4564e-01, -6.3612e-01, -6.2989e-01],\n",
       "        [-4.9311e-01, -8.6336e-01,  1.0697e-01],\n",
       "        [ 9.7782e-01,  1.7295e-01, -1.1811e-01],\n",
       "        [-6.7831e-01, -2.5356e-01,  6.8964e-01],\n",
       "        [ 1.8659e-01,  3.6077e-01,  9.1380e-01],\n",
       "        [ 4.8085e-01,  4.1262e-01,  7.7365e-01],\n",
       "        [-2.6382e-01, -8.8156e-01, -3.9147e-01],\n",
       "        [-4.6276e-01,  8.7354e-01,  1.5090e-01],\n",
       "        [-8.8204e-01, -3.3042e-01,  3.3589e-01],\n",
       "        [ 8.8280e-01, -4.0991e-01,  2.2943e-01],\n",
       "        [ 1.4335e-02, -7.2139e-02,  9.9729e-01],\n",
       "        [-6.4440e-01, -7.4795e-01, -1.5911e-01],\n",
       "        [ 3.2168e-01,  3.8212e-01,  8.6632e-01],\n",
       "        [-6.0226e-01,  6.8067e-01,  4.1710e-01],\n",
       "        [-2.0050e-01, -8.8644e-01, -4.1716e-01],\n",
       "        [ 9.1624e-01, -2.7785e-02, -3.9967e-01],\n",
       "        [ 8.0061e-01,  3.0926e-01, -5.1320e-01],\n",
       "        [-3.3919e-01, -6.5984e-01,  6.7049e-01],\n",
       "        [-9.8642e-01,  1.4578e-01,  7.5707e-02],\n",
       "        [-8.8463e-01,  4.6324e-01, -5.3196e-02],\n",
       "        [-9.3256e-01,  2.9163e-01, -2.1279e-01],\n",
       "        [-4.6731e-01, -4.4626e-01, -7.6320e-01],\n",
       "        [ 1.9797e-01, -5.5801e-01,  8.0587e-01],\n",
       "        [ 2.2177e-02, -9.2693e-01,  3.7458e-01],\n",
       "        [ 8.1100e-01,  5.8425e-01,  3.0532e-02],\n",
       "        [ 4.7605e-01,  7.7998e-03,  8.7938e-01],\n",
       "        [-9.2254e-01, -3.4708e-01,  1.6869e-01],\n",
       "        [ 1.2037e-01, -2.3611e-01, -9.6424e-01],\n",
       "        [-3.9496e-01, -9.0652e-01, -1.4911e-01],\n",
       "        [ 5.4868e-01,  7.6725e-01,  3.3208e-01]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.y.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
