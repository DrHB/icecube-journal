{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fef8a4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-02-27 22:41:50 - get_logger - Writing log to \u001b[1mlogs/graphnet_20230227-224150.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbd26574-d0cc-4284-9f06-ec5e706e5a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1\n"
     ]
    }
   ],
   "source": [
    "def set_gpu_environ():\n",
    "    \"\"\"Sets CUDA_VISIBLE_DEVICES to those under minimal memory load.\n",
    "    Meant to be used in notebooks only.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import subprocess\n",
    "    query = subprocess.check_output(['nvidia-smi', '--query-gpu=memory.used', '--format=csv']).decode().split('\\n')[1:-1]\n",
    "    utilization = [int(x.replace(\" MiB\", \"\")) for x in query]\n",
    "    free = [i for i in range(len(utilization)) if utilization[i] == min(utilization)]\n",
    "    set_visible = \",\".join([str(i) for i in free])\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = set_visible\n",
    "    print(set_visible)\n",
    "set_gpu_environ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e5001d1-84db-4c43-970b-bd2502a43f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def train(cfg):\n",
    "    seed()\n",
    "    custom_model = cfg.MODEL_NAME()\n",
    "    if cfg.MODEL_WTS:\n",
    "        print(f\"Loading model weights from {cfg.MODEL_WTS}\")\n",
    "        custom_model.load_state_dict(torch.load(cfg.MODEL_WTS))\n",
    "    opt = cfg.OPT(\n",
    "        custom_model.parameters(), lr=cfg.LR, weight_decay=cfg.WD\n",
    "    )\n",
    "    loss_func = cfg.LOSS_FUNC()\n",
    "    len_trn_dl = (cfg.N_FILES * 200000)//cfg.BATCH_SIZE\n",
    "    warmup_steps = int(len_trn_dl * cfg.WARM_UP_PCT * cfg.EPOCHS)\n",
    "    total_steps = int(len_trn_dl * cfg.EPOCHS)\n",
    "\n",
    "    print(f\"Total steps: {total_steps}, Warmup steps: {warmup_steps}\")\n",
    "\n",
    "    scheduler = cfg.SCHEDULER(\n",
    "        opt,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps,\n",
    "    )\n",
    "\n",
    "    cfg.FIT_FUNC(\n",
    "        epochs=cfg.EPOCHS,\n",
    "        model=custom_model,\n",
    "        loss_fn=loss_func,\n",
    "        opt=opt,\n",
    "        metric=cfg.METRIC,\n",
    "        config = cfg,\n",
    "        folder=cfg.FOLDER/cfg.EXP_NAME,\n",
    "        exp_name=f\"{cfg.EXP_NAME}\",\n",
    "        device=cfg.DEVICE,\n",
    "        sched=scheduler,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e6e220c-0dfc-406d-b55d-d77770f6e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config_name):\n",
    "    configs = eval(f\"config.{config_name}\")\n",
    "    print(f\"Training with config: {configs.__dict__}\")\n",
    "    os.makedirs(configs.FOLDER/configs.EXP_NAME)\n",
    "    train(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e233b09-b818-4718-b28f-663ccdebe80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with config: {'__module__': 'config', 'MODEL_WTS': False, 'EXP_NAME': 'EXP_37', 'FILTER': False, 'LOSS_FUNC': <class 'graphnet.training.loss_functions.VonMisesFisher3DLoss'>, 'FIT_FUNC': <function fit_shuflle at 0x7f6d6d896b00>, 'NUM_WORKERS': 22, 'TRN_DATASET': <class 'icecube.dataset.HuggingFaceDatasetV14'>, 'VAL_DATASET': <class 'icecube.dataset.HuggingFaceDatasetV14'>, 'MODEL_NAME': <class 'icecube.models.EncoderWithDirectionReconstructionV7'>, 'N_FILES': 50, 'TRN_BATCH_RANGE': [[1, 51], [51, 101], [101, 151], [151, 201], [201, 251], [251, 301], [301, 351], [351, 401], [401, 451], [451, 501], [501, 551], [501, 601]], 'EPOCHS': 24, 'DEVICE': 'cuda:0', 'BATCH_SIZE': 512, 'LR': 0.0003, 'WD': 0.05, 'COLLAT_FN': <function collate_fn_v2 at 0x7f6d6d898290>, 'WARM_UP_PCT': 0.01, '__doc__': None}\n",
      "Total steps: 468744, Warmup steps: 4687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdrhb\u001b[0m (\u001b[33mkaggle-hi\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/opt/slh/icecube/wandb/run-20230227_224152-2cvh20z3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kaggle-hi/ice/runs/2cvh20z3\" target=\"_blank\">EXP_37</a></strong> to <a href=\"https://wandb.ai/kaggle-hi/ice\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      12.50% [3/24 14:21:29&lt;100:30:26]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>val_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='16179' class='' max='19532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      82.83% [16179/19532 3:47:28&lt;47:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_range: [1, 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with value: 1.0526936054229736.\n",
      "   epoch  train_loss  valid_loss     metric\n",
      "0      0    1.808428     1.62048  1.0526936\n",
      "trn_range: [51, 101]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 2 with value: 1.034018874168396.\n",
      "   epoch  train_loss  valid_loss     metric\n",
      "0      2     1.59782    1.541793  1.0340189\n",
      "trn_range: [151, 201]\n"
     ]
    }
   ],
   "source": [
    "main('NANO_TRANSFORMER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcecc6a9-38b2-404d-aaec-4d9cf49d95f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 min\n",
    "NUM_WORKERS = 22\n",
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128c2409-c8f1-4a34-a950-bf4950a2f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4840bc22-6111-4318-a0c6-1a1274ca530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2983fa-5d58-46e3-b4b8-bd20648455a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd39fb95-604a-42f2-bf65-8bd5f94d75f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ffe4d3-675e-4aa6-9c47-07e63a25a4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "06c039cc12e84f18a3a762e1bbe6eed4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_cfc184b2ed1945519f9fc4f5c7296605",
        "IPY_MODEL_23a94cb474164f9993c00b0e9b07ad63"
       ],
       "layout": "IPY_MODEL_c3757abdbaff4a7eb3dcbc880ebd7ca4"
      }
     },
     "23a94cb474164f9993c00b0e9b07ad63": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_eac6b4bbc53944cc9d77602249c06bb1",
       "max": 1,
       "style": "IPY_MODEL_3d99ae01ab464787b1010a74ffe39e35"
      }
     },
     "2a64365c4d234172afce28b25a089d91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3d99ae01ab464787b1010a74ffe39e35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "663305bb953d41bda70bd9cbd6b7127b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c3757abdbaff4a7eb3dcbc880ebd7ca4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cfc184b2ed1945519f9fc4f5c7296605": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_663305bb953d41bda70bd9cbd6b7127b",
       "style": "IPY_MODEL_2a64365c4d234172afce28b25a089d91"
      }
     },
     "eac6b4bbc53944cc9d77602249c06bb1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
