{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fef8a4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-04 11:55:01 - get_logger - Writing log to \u001b[1mlogs/graphnet_20230304-115501.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbd26574-d0cc-4284-9f06-ec5e706e5a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def set_gpu_environ():\n",
    "    \"\"\"Sets CUDA_VISIBLE_DEVICES to those under minimal memory load.\n",
    "    Meant to be used in notebooks only.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import subprocess\n",
    "    query = subprocess.check_output(['nvidia-smi', '--query-gpu=memory.used', '--format=csv']).decode().split('\\n')[1:-1]\n",
    "    utilization = [int(x.replace(\" MiB\", \"\")) for x in query]\n",
    "    free = [i for i in range(len(utilization)) if utilization[i] == min(utilization)]\n",
    "    set_visible = \",\".join([str(i) for i in free])\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = set_visible\n",
    "    print(set_visible)\n",
    "set_gpu_environ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e5001d1-84db-4c43-970b-bd2502a43f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def train(cfg):\n",
    "    seed()\n",
    "    custom_model = cfg.MODEL_NAME()\n",
    "    if cfg.MODEL_WTS:\n",
    "        print(f\"Loading model weights from {cfg.MODEL_WTS}\")\n",
    "        custom_model.load_state_dict(torch.load(cfg.MODEL_WTS))\n",
    "    opt = cfg.OPT(\n",
    "        custom_model.parameters(), lr=cfg.LR, weight_decay=cfg.WD\n",
    "    )\n",
    "    loss_func = cfg.LOSS_FUNC()\n",
    "    len_trn_dl = (cfg.N_FILES * 200000)//cfg.BATCH_SIZE\n",
    "    warmup_steps = int(len_trn_dl * cfg.WARM_UP_PCT * cfg.EPOCHS)\n",
    "    total_steps = int(len_trn_dl * cfg.EPOCHS)\n",
    "\n",
    "    print(f\"Total steps: {total_steps}, Warmup steps: {warmup_steps}\")\n",
    "\n",
    "    scheduler = cfg.SCHEDULER(\n",
    "        opt,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps,\n",
    "    )\n",
    "\n",
    "    cfg.FIT_FUNC(\n",
    "        epochs=cfg.EPOCHS,\n",
    "        model=custom_model,\n",
    "        loss_fn=loss_func,\n",
    "        opt=opt,\n",
    "        metric=cfg.METRIC,\n",
    "        config = cfg,\n",
    "        folder=cfg.FOLDER/cfg.EXP_NAME,\n",
    "        exp_name=f\"{cfg.EXP_NAME}\",\n",
    "        device=cfg.DEVICE,\n",
    "        sched=scheduler,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e6e220c-0dfc-406d-b55d-d77770f6e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config_name):\n",
    "    configs = eval(f\"config.{config_name}\")\n",
    "    print(f\"Training with config: {configs.__dict__}\")\n",
    "    os.makedirs(configs.FOLDER/configs.EXP_NAME)\n",
    "    train(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e233b09-b818-4718-b28f-663ccdebe80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with config: {'__module__': 'config', 'MODEL_WTS': '/opt/slh/icecube/RESULTS/EXP_40/EXP_40_0.pth', 'EXP_NAME': 'EXP_40_FT', 'FILTER': False, 'LOSS_FUNC': <class 'icecube.modelsgraph.gVonMisesFisher3DLoss'>, 'NUM_WORKERS': 22, 'MODEL_NAME': <class 'icecube.modelsgraph.GraphxTransformerV3'>, 'FIT_FUNC': <function gfit_shuflle_f32 at 0x7f1edc280200>, 'METRIC': <function gget_score_vector at 0x7f1edc280560>, 'TRN_DATASET': <class 'icecube.graphdataset.GraphDasetV0'>, 'VAL_DATASET': <class 'icecube.graphdataset.GraphDasetV0'>, 'TRN_BATCH_RANGE': [[101, 151], [1, 51], [151, 201], [251, 301], [201, 251], [301, 351], [401, 451], [351, 401], [451, 501], [551, 601], [601, 651], [501, 551], [51, 101]], 'EPOCHS': 13, 'DEVICE': 'cuda:0', 'BATCH_SIZE': 512, 'VAL_BATCH_RANGE': (655, 660), 'LR': 0.0005, 'WD': 0.05, 'N_FILES': 50, 'WARM_UP_PCT': 0.01, '__doc__': None}\n",
      "Loading model weights from /opt/slh/icecube/RESULTS/EXP_40/EXP_40_0.pth\n",
      "Total steps: 253903, Warmup steps: 2539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdrhb\u001b[0m (\u001b[33mkaggle-hi\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/opt/slh/icecube/wandb/run-20230304_115504-77qtbgjc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kaggle-hi/ice/runs/77qtbgjc\" target=\"_blank\">EXP_40_FT</a></strong> to <a href=\"https://wandb.ai/kaggle-hi/ice\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='4' class='' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      30.77% [4/13 15:33:33&lt;35:00:30]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>val_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='12647' class='' max='19532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      64.75% [12647/19532 2:24:57&lt;1:18:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_range: [101, 151]\n",
      "Better model found at epoch 0 with value: 1.0588619709014893.\n",
      "   epoch  train_loss  valid_loss    metric\n",
      "0      0    1.517539    1.549849  1.058862\n",
      "trn_range: [1, 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 3 with value: 1.0445926189422607.\n",
      "   epoch  train_loss  valid_loss     metric\n",
      "0      3    1.581381    1.588248  1.0445926\n",
      "trn_range: [201, 251]\n"
     ]
    }
   ],
   "source": [
    "main('BASELINE_graph_V14_FT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcecc6a9-38b2-404d-aaec-4d9cf49d95f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 min\n",
    "NUM_WORKERS = 22\n",
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128c2409-c8f1-4a34-a950-bf4950a2f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4840bc22-6111-4318-a0c6-1a1274ca530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2983fa-5d58-46e3-b4b8-bd20648455a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd39fb95-604a-42f2-bf65-8bd5f94d75f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ffe4d3-675e-4aa6-9c47-07e63a25a4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "032eb306e4ce4b75a470689c7b0d50bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "169e529570094bc1a3aa96756fd0d4e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_877e9feef61540ac987aa08bfd5205f5",
       "style": "IPY_MODEL_032eb306e4ce4b75a470689c7b0d50bf"
      }
     },
     "21a5e54c7bf84b81b4ec9403739cf04e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_dc3b4d3b0c8a489d83f5910a09d7440d",
       "max": 1,
       "style": "IPY_MODEL_fcc2638826bc44e69f285309b3374899"
      }
     },
     "876b36ac64da4355a56ddabce3a3d859": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_169e529570094bc1a3aa96756fd0d4e1",
        "IPY_MODEL_21a5e54c7bf84b81b4ec9403739cf04e"
       ],
       "layout": "IPY_MODEL_fa78dda1639344b0b8aaefa4917c91c4"
      }
     },
     "877e9feef61540ac987aa08bfd5205f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "dc3b4d3b0c8a489d83f5910a09d7440d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fa78dda1639344b0b8aaefa4917c91c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fcc2638826bc44e69f285309b3374899": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
