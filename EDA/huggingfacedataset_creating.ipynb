{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1662b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset, load_from_disk, concatenate_datasets\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "import torch\n",
    "from torch.utils.data.sampler import BatchSampler, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355019af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that reduces the size of pandas dataframe\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618c59ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_DATAST = Path(\"../data\")\n",
    "# train_meta = pl.scan_parquet(PATH_DATAST / \"train_meta.parquet\")\n",
    "# geometry = pd.read_csv(PATH_DATAST / \"sensor_geometry.csv\")\n",
    "# geometry[\"sensor_id\"] = geometry[\"sensor_id\"].astype(\"int16\")\n",
    "# geometry = pl.from_pandas(geometry).lazy()\n",
    "\n",
    "\n",
    "# def batch_to_hf(batch_id, store_dist=Path(\"../data/hf_cashe\")):\n",
    "\n",
    "#     fn = PATH_DATAST / \"train\" / f\"batch_{batch_id}.parquet\"\n",
    "#     train = pl.scan_parquet(fn)\n",
    "#     train = (\n",
    "#         train.join(geometry, on=\"sensor_id\")\n",
    "#         .groupby(\"event_id\")\n",
    "#         .agg([pl.all()])\n",
    "#         .join(train_meta, on=\"event_id\")\n",
    "#         .collect()\n",
    "#     )\n",
    "#     train = train.to_pandas()[\n",
    "#         [\n",
    "#             \"event_id\",\n",
    "#             \"sensor_id\",\n",
    "#             \"time\",\n",
    "#             \"charge\",\n",
    "#             \"auxiliary\",\n",
    "#             \"x\",\n",
    "#             \"y\",\n",
    "#             \"z\",\n",
    "#             \"azimuth\",\n",
    "#             \"zenith\",\n",
    "#         ]\n",
    "#     ]\n",
    "#     # train = reduce_mem_usage(train)\n",
    "#     dataset = Dataset.from_pandas(train)\n",
    "#     dataset.save_to_disk(store_dist / fn.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0079678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the batches sorted \n",
    "# batches = sorted([int(x.stem.split(\"_\")[1]) for x in (PATH_DATAST / \"train\").glob(\"batch_*.parquet\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7248ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(batches):\n",
    "#     batch_to_hf(i)\n",
    "\n",
    "from pdb import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be523a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee3a128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39888a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raed all hugingface datasets and concatenate them into one\n",
    "\n",
    "#save the dataset to disk with batch_id as name \n",
    "#dataset.save_to_disk(PATH_DATAST / \"hf_cashe\" / \"dataset_0-20\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f543b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class HuggingFaceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ds, max_events=100):\n",
    "        self.ds = ds\n",
    "        self.max_events = max_events\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        event = pd.DataFrame(item)[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"charge\",\n",
    "                \"auxiliary\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "        ].astype(np.float32)\n",
    "        if self.max_events:\n",
    "            event = event[: self.max_events]\n",
    "        event[\"time\"] /= event[\"time\"].max()\n",
    "        event[[\"x\", \"y\", \"z\"]] /= 500\n",
    "        event[\"charge\"] = np.log10(event[\"charge\"])\n",
    "\n",
    "        event = event.values\n",
    "        mask = np.ones(len(event), dtype=bool)\n",
    "        label = np.array([item[\"azimuth\"], item[\"zenith\"]], dtype=np.float32)\n",
    "\n",
    "        batch = deepcopy(\n",
    "            {\n",
    "                \"event\": torch.tensor(event),\n",
    "                \"mask\": torch.tensor(mask),\n",
    "                \"label\": torch.tensor(label),\n",
    "            }\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    event = [x[\"event\"] for x in batch]\n",
    "    mask = [x[\"mask\"] for x in batch]\n",
    "    label = [x[\"label\"] for x in batch]\n",
    "\n",
    "    event = torch.nn.utils.rnn.pad_sequence(event, batch_first=True)\n",
    "    mask = torch.nn.utils.rnn.pad_sequence(mask, batch_first=True)\n",
    "    batch = {\"event\": event, \"mask\": mask, \"label\": torch.concat(label)}\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d087ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_custom = HuggingFaceDataset(hf_datasets)\n",
    "\n",
    "dl = torch.utils.data.DataLoader(\n",
    "    dataset_custom,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=16, \n",
    "    batch_size = 256, \n",
    "    persistent_workers=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f2679",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tqdm(dl):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a04998",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hf_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e155e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "24."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
