{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from icecube.dataset import IceCubeCasheDatasetV0\n",
    "from icecube.dataset import collate_fn\n",
    "from icecube.utils import fit\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers.optimization import (\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    ")\n",
    "from torch import nn\n",
    "from x_transformers import ContinuousTransformerWrapper, Encoder, Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angular_dist_score(\n",
    "    az_true: torch.Tensor,\n",
    "    zen_true: torch.Tensor,\n",
    "    az_pred: torch.Tensor,\n",
    "    zen_pred: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    sa1 = torch.sin(az_true)\n",
    "    ca1 = torch.cos(az_true)\n",
    "    sz1 = torch.sin(zen_true)\n",
    "    cz1 = torch.cos(zen_true)\n",
    "\n",
    "    sa2 = torch.sin(az_pred)\n",
    "    ca2 = torch.cos(az_pred)\n",
    "    sz2 = torch.sin(zen_pred)\n",
    "    cz2 = torch.cos(zen_pred)\n",
    "\n",
    "    scalar_prod = sz1 * sz2 * (ca1 * ca2 + sa1 * sa2) + cz1 * cz2\n",
    "    scalar_prod = torch.clamp(scalar_prod, -1, 1)\n",
    "    return torch.mean(torch.abs(torch.acos(scalar_prod)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    DATA_CACHE_DIR = Path(\"../data/cache\")\n",
    "    BATCH_SIZE = 1024\n",
    "    NUM_WORKERS = 16\n",
    "    PRESISTENT_WORKERS = True\n",
    "    LR = 1e-3\n",
    "    WD = 1e-5\n",
    "    WARM_UP_PCT = 0.1\n",
    "    EPOCHS = 10\n",
    "    FOLDER = 'EXP_00'\n",
    "    EXP_NAME = 'FIRST_EXP'\n",
    "\n",
    "\n",
    "def get_batch_paths(start: int, end: int, extension: str = \"*.pth\"):\n",
    "    trn_path = []\n",
    "    for i in range(start, end+1):\n",
    "        path = (CFG.DATA_CACHE_DIR / f\"batch_{i}\").glob(extension)\n",
    "        trn_path.extend(list(path))\n",
    "    return trn_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogCoshLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, y_t, y_prime_t):\n",
    "        ey_t = y_t - y_prime_t\n",
    "        return torch.mean(torch.log(torch.cosh(ey_t + 1e-12)))\n",
    "\n",
    "\n",
    "\n",
    "class MeanPoolingWithMask(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPoolingWithMask, self).__init__()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # Multiply the mask with the input tensor to zero out the padded values\n",
    "        x = x * mask.unsqueeze(-1)\n",
    "\n",
    "        # Sum the values along the sequence dimension\n",
    "        x = torch.sum(x, dim=1)\n",
    "\n",
    "        # Divide the sum by the number of non-padded values (i.e. the sum of the mask)\n",
    "        x = x / torch.sum(mask, dim=1, keepdim=True)\n",
    "\n",
    "        return x\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, dim_out = None, mult = 4):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, dim * mult),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim * mult, dim_out)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class IceCubeModelEncoderV0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = ContinuousTransformerWrapper(\n",
    "            dim_in=6,\n",
    "            dim_out=128,\n",
    "            max_seq_len=150,\n",
    "            attn_layers=Encoder(dim=128,\n",
    "                        depth=3, \n",
    "                        heads=8),\n",
    "        )\n",
    "\n",
    "        #self.pool = MeanPoolingWithMask()\n",
    "        self.head = FeedForward(128, 2)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.encoder(x, mask = mask)\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "#calculte metric based on angular distance\n",
    "def get_score(y_hat, y):\n",
    "    return angular_dist_score(y[:, 0], y[:, 1], y_hat[:, 0], y_hat[:, 1]).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18800000 800000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='9' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      90.00% [9/10 9:01:35&lt;1:00:10]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>val_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.674216</td>\n",
       "      <td>1.554134</td>\n",
       "      <td>1.276736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.525211</td>\n",
       "      <td>1.509722</td>\n",
       "      <td>1.235875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.500366</td>\n",
       "      <td>1.489993</td>\n",
       "      <td>1.212262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.488791</td>\n",
       "      <td>1.484644</td>\n",
       "      <td>1.211941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.481066</td>\n",
       "      <td>1.479461</td>\n",
       "      <td>1.200866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.474846</td>\n",
       "      <td>1.477871</td>\n",
       "      <td>1.199028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.469452</td>\n",
       "      <td>1.469063</td>\n",
       "      <td>1.193366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.464338</td>\n",
       "      <td>1.467149</td>\n",
       "      <td>1.187193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.459508</td>\n",
       "      <td>1.463810</td>\n",
       "      <td>1.188819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='11024' class='' max='18359' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      60.05% [11024/18359 35:16&lt;23:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 3 with value: 1.2119414806365967.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 7 with value: 1.1871932744979858.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 8 with value: 1.1888186931610107.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vld_path = get_batch_paths(3, 6)\n",
    "trn_path = get_batch_paths(7, 100)\n",
    "\n",
    "print(len(trn_path), len(vld_path))\n",
    "\n",
    "trn_ds = IceCubeCasheDatasetV0(trn_path)\n",
    "vld_ds = IceCubeCasheDatasetV0(vld_path)\n",
    "\n",
    "trn_dl = DataLoader(\n",
    "    trn_ds,\n",
    "    batch_size=CFG.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=CFG.NUM_WORKERS,\n",
    "    persistent_workers=CFG.PRESISTENT_WORKERS,\n",
    "    drop_last=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "vld_dl = DataLoader(\n",
    "    vld_ds,\n",
    "    batch_size=CFG.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.NUM_WORKERS,\n",
    "    persistent_workers=CFG.PRESISTENT_WORKERS,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "\n",
    "custom_model = IceCubeModelEncoderV0()\n",
    "opt = torch.optim.AdamW(custom_model.parameters(), lr=CFG.LR, weight_decay=CFG.WD)\n",
    "loss_func = nn.MSELoss()\n",
    "warmup_steps = int(len(trn_dl) * int(CFG.WARM_UP_PCT * CFG.EPOCHS))\n",
    "total_steps = int(len(trn_dl) * CFG.EPOCHS)\n",
    "sched = get_linear_schedule_with_warmup(\n",
    "    opt, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "fit(\n",
    "    epochs=CFG.EPOCHS,\n",
    "    model=custom_model,\n",
    "    train_dl=trn_dl,\n",
    "    valid_dl=vld_dl,\n",
    "    loss_fn=loss_func,\n",
    "    opt=opt,\n",
    "    metric=get_score,\n",
    "    folder=CFG.FOLDER,\n",
    "    exp_name=f\"{CFG.EXP_NAME}\",\n",
    "    device=\"cuda:0\",\n",
    "    sched=sched,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
