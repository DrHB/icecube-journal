{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f418a53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('/opt/slh/icecube/')\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,0\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "#os.environ[\"NCCL_P2P_DISABLE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6efa89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-04-13 11:37:36 - get_logger - Writing log to \u001b[1mlogs/graphnet_20230413-113736.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "from icecube.fastai_fix import *\n",
    "from tqdm.notebook import tqdm\n",
    "from icecube.data_train_v3 import RandomChunkSampler,LenMatchBatchSampler,IceCubeCache, DeviceDataLoader\n",
    "from icecube.loss import loss, loss_vms, loss_comb\n",
    "from icecube.models import EncoderWithDirectionReconstructionV23\n",
    "from fastxtend.vision.all import EMACallback\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b613edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTION = 'total'\n",
    "OUT = 'V23FT3'\n",
    "PATH = '../data/'\n",
    "\n",
    "NUM_WORKERS = 12\n",
    "SEED = 2023\n",
    "bs = 512 - 64 -32\n",
    "L = 192\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)\n",
    "os.makedirs(OUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "835aa86f-8905-4cdd-a439-2973c73d32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WrapperAdamW(param_groups,**kwargs):\n",
    "    return OptimWrapper(param_groups,torch.optim.AdamW)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_matching_weights(model, weights_path):\n",
    "    \"\"\"\n",
    "    Load model weights from a given path if they match, otherwise skip.\n",
    "    Prints the number of matched and unmatched weights.\n",
    "\n",
    "    :param model: The PyTorch model for which weights should be loaded.\n",
    "    :param weights_path: The path to the saved weights file (.pth or .pt).\n",
    "    \"\"\"\n",
    "    # Load the saved state dictionary\n",
    "    saved_state_dict = torch.load(weights_path, map_location=torch.device('cpu'))\n",
    "\n",
    "    # Get the model's state dictionary\n",
    "    model_state_dict = model.state_dict()\n",
    "\n",
    "    # Create a new state dictionary to store matching weights\n",
    "    matching_state_dict = {}\n",
    "\n",
    "    # Initialize counters for matched and unmatched weights\n",
    "    matched_weights = 0\n",
    "    unmatched_weights = 0\n",
    "\n",
    "    # Iterate through the saved state dictionary\n",
    "    for name, saved_weight in saved_state_dict.items():\n",
    "        # Check if the name exists in the model's state dictionary and the shapes match\n",
    "        if name in model_state_dict and model_state_dict[name].shape == saved_weight.shape:\n",
    "            # If it matches, add it to the matching state dictionary\n",
    "            matching_state_dict[name] = saved_weight\n",
    "            matched_weights += 1\n",
    "        else:\n",
    "            #print(f\"Skipping weight: {name} - Shape mismatch or not found in model\")\n",
    "            unmatched_weights += 1\n",
    "\n",
    "    # Update the model's state dictionary with the matching state dictionary\n",
    "    model_state_dict.update(matching_state_dict)\n",
    "\n",
    "    # Load the updated state dictionary into the model\n",
    "    model.load_state_dict(model_state_dict)\n",
    "\n",
    "    print(f\"Matched weights: {matched_weights}\")\n",
    "    print(f\"Unmatched weights: {unmatched_weights}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "037a8dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_matching_weights(model, '/opt/slh/icecube/hb_training_loop/V22FT5/models/model_7.pth')\n",
    "#load_matching_weights(model, '/opt/slh/icecube/hb_training_loop/V23/baselineV3_BE_globalrel_d64_0_2.pth')\n",
    "\n",
    "fname = OUT\n",
    "\n",
    "ds_train = IceCubeCache(PATH, mode='train', L=L, selection=SELECTION,reduce_size=0.125)\n",
    "ds_train_len = IceCubeCache(PATH, mode='train', L=L, reduce_size=0.125, selection=SELECTION, mask_only=True)\n",
    "sampler_train = RandomChunkSampler(ds_train_len, chunks=ds_train.chunks)\n",
    "len_sampler_train = LenMatchBatchSampler(sampler_train, batch_size=bs, drop_last=True)\n",
    "dl_train = DeviceDataLoader(torch.utils.data.DataLoader(ds_train, \n",
    "            batch_sampler=len_sampler_train, num_workers=NUM_WORKERS, persistent_workers=True))\n",
    "\n",
    "ds_val = IceCubeCache(PATH, mode='eval', L=L, selection=SELECTION)\n",
    "ds_val_len = IceCubeCache(PATH, mode='eval', L=L, selection=SELECTION, mask_only=True)\n",
    "sampler_val = torch.utils.data.SequentialSampler(ds_val_len)\n",
    "len_sampler_val = LenMatchBatchSampler(sampler_val, batch_size=bs, drop_last=False)\n",
    "dl_val= DeviceDataLoader(torch.utils.data.DataLoader(ds_val, batch_sampler=len_sampler_val,\n",
    "            num_workers=0))\n",
    "\n",
    "\n",
    "data = DataLoaders(dl_train,dl_val)\n",
    "model = EncoderWithDirectionReconstructionV23(dim=768, dim_base=192, depth=12, head_size=64)\n",
    "model.load_state_dict(torch.load('/opt/slh/icecube/hb_training_loop/V23FT2/models/model_3.pth'))\n",
    "model = nn.DataParallel(model)\n",
    "learn = Learner(data, model,  path = OUT, loss_func=loss_comb,cbs=[GradientClip(3.0),CSVLogger(),EMACallback(), \n",
    "            SaveModelCallback(monitor='loss',comp=np.less,every_epoch=True),\n",
    "            GradientAccumulation(n_acc=4)],\n",
    "            metrics=[loss], opt_func=partial(WrapperAdamW,eps=1e-7)).to_fp16()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a5e7dd-e1a1-4370-8c57-c1210fbe8d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb30a33-80e3-4d26-bacc-819e96e73cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/8 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='360' class='' max='39349' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.91% [360/39349 03:12&lt;5:47:53 1.0477]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/slh/icecube/icecube/data_train_v3.py:264: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  L = max(1,L // 16)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/cuda/nccl.py:51: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  if not isinstance(inputs, collections.Container) or isinstance(inputs, torch.Tensor):\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(8, \n",
    "                    lr_max=1e-5,\n",
    "                    wd=0.05, \n",
    "                    pct_start=0.01, \n",
    "                    div=25,\n",
    "                    div_final=25,\n",
    "                    moms=(0.95,0.95,0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77be403c-678a-4cc9-93ed-10ed1d40d803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1567cddd-6f23-447f-8177-e6be1cf0c7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
