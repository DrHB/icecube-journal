{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87dd6834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "from fastai_fix import *\n",
    "from tqdm.notebook import tqdm\n",
    "from data_train_v3 import RandomChunkSampler,LenMatchBatchSampler,IceCubeCache, DeviceDataLoader\n",
    "#from model_transformer_base import DeepIceModel\n",
    "from loss import loss, loss_vms, loss_comb\n",
    "from baselineV3_SE_globalrel_d32_2 import DeepIceModel as TransformerV3_2\n",
    "from fastxtend.vision.all import EMACallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b6f8ee-1aa5-4c14-8eb6-71655a7b6b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install polars==0.16.8\n",
    "# !pip install pyarrow\n",
    "# !pip install fastxtend\n",
    "# !pip install kornia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67b8fd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTION = 'total'\n",
    "OUT = 'baselineV3_BE_globalrel_d64_0_3emaFT'\n",
    "PATH = 'data/'\n",
    "\n",
    "NUM_WORKERS = 16\n",
    "SEED = 2023\n",
    "bs = 512 + 64 + 32\n",
    "L = 256\n",
    "L_VALID = 512\n",
    "bs_VALID = 256 + 128\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)\n",
    "os.makedirs(OUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edc6f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WrapperAdamW(param_groups,**kwargs):\n",
    "    return OptimWrapper(param_groups,torch.optim.AdamW)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_matching_weights(model, weights_path):\n",
    "    \"\"\"\n",
    "    Load model weights from a given path if they match, otherwise skip.\n",
    "    Prints the number of matched and unmatched weights.\n",
    "\n",
    "    :param model: The PyTorch model for which weights should be loaded.\n",
    "    :param weights_path: The path to the saved weights file (.pth or .pt).\n",
    "    \"\"\"\n",
    "    # Load the saved state dictionary\n",
    "    saved_state_dict = torch.load(weights_path, map_location=torch.device('cpu'))\n",
    "\n",
    "    # Get the model's state dictionary\n",
    "    model_state_dict = model.state_dict()\n",
    "\n",
    "    # Create a new state dictionary to store matching weights\n",
    "    matching_state_dict = {}\n",
    "\n",
    "    # Initialize counters for matched and unmatched weights\n",
    "    matched_weights = 0\n",
    "    unmatched_weights = 0\n",
    "\n",
    "    # Iterate through the saved state dictionary\n",
    "    for name, saved_weight in saved_state_dict.items():\n",
    "        # Check if the name exists in the model's state dictionary and the shapes match\n",
    "        if name in model_state_dict and model_state_dict[name].shape == saved_weight.shape:\n",
    "            # If it matches, add it to the matching state dictionary\n",
    "            matching_state_dict[name] = saved_weight\n",
    "            matched_weights += 1\n",
    "        else:\n",
    "            #print(f\"Skipping weight: {name} - Shape mismatch or not found in model\")\n",
    "            unmatched_weights += 1\n",
    "\n",
    "    # Update the model's state dictionary with the matching state dictionary\n",
    "    model_state_dict.update(matching_state_dict)\n",
    "\n",
    "    # Load the updated state dictionary into the model\n",
    "    model.load_state_dict(model_state_dict)\n",
    "\n",
    "    print(f\"Matched weights: {matched_weights}\")\n",
    "    print(f\"Unmatched weights: {unmatched_weights}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9464d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f8f9bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_matching_weights(model, '/opt/slh/icecube/hb_training_loop/V22FT5/models/model_7.pth')\n",
    "#load_matching_weights(model, '/opt/slh/icecube/hb_training_loop/V23/baselineV3_BE_globalrel_d64_0_2.pth')\n",
    "\n",
    "fname = OUT\n",
    "\n",
    "ds_train = IceCubeCache(PATH, mode='train', L=L, selection=SELECTION,reduce_size=0.125)\n",
    "ds_train_len = IceCubeCache(PATH, mode='train', L=L, reduce_size=0.125, selection=SELECTION, mask_only=True)\n",
    "sampler_train = RandomChunkSampler(ds_train_len, chunks=ds_train.chunks)\n",
    "len_sampler_train = LenMatchBatchSampler(sampler_train, batch_size=bs, drop_last=True)\n",
    "dl_train = DeviceDataLoader(torch.utils.data.DataLoader(ds_train, \n",
    "            batch_sampler=len_sampler_train, num_workers=NUM_WORKERS, persistent_workers=True))\n",
    "\n",
    "ds_val = IceCubeCache(PATH, mode='eval', L=L_VALID, selection=SELECTION)\n",
    "ds_val_len = IceCubeCache(PATH, mode='eval', L=L_VALID, selection=SELECTION, mask_only=True)\n",
    "sampler_val = torch.utils.data.SequentialSampler(ds_val_len)\n",
    "len_sampler_val = LenMatchBatchSampler(sampler_val, batch_size=bs_VALID, drop_last=False)\n",
    "dl_val= DeviceDataLoader(torch.utils.data.DataLoader(ds_val, batch_sampler=len_sampler_val,\n",
    "            num_workers=0))\n",
    "\n",
    "\n",
    "data = DataLoaders(dl_train,dl_val)\n",
    "model = TransformerV3_2(dim=768, dim_base=192, depth=12, head_size=64)\n",
    "model.load_state_dict(torch.load('baselineV3_BE_globalrel_d64_0_3ema.pth'))\n",
    "model = nn.DataParallel(model)\n",
    "learn = Learner(data, \n",
    "                model,\n",
    "                path = OUT,\n",
    "                loss_func=loss_comb,\n",
    "                cbs=[GradientClip(3.0),\n",
    "                     CSVLogger(),\n",
    "                     EMACallback(), \n",
    "                     SaveModelCallback(monitor='loss',comp=np.less,every_epoch=True),\n",
    "                     GradientAccumulation(n_acc=4096//bs)],\n",
    "                     metrics=[loss],\n",
    "                     opt_func=partial(WrapperAdamW,eps=1e-7)).to_fp16()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820f626e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      75.00% [3/4 12:57:47<4:19:15]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.997746</td>\n",
       "      <td>1.030024</td>\n",
       "      <td>0.964070</td>\n",
       "      <td>4:20:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.005598</td>\n",
       "      <td>1.029966</td>\n",
       "      <td>0.964018</td>\n",
       "      <td>4:19:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.005712</td>\n",
       "      <td>1.029867</td>\n",
       "      <td>0.963947</td>\n",
       "      <td>4:18:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='302' class='' max='26923' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      1.12% [302/26923 02:43<4:00:38 1.0314]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_train_v3.py:264: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  L = max(1,L // 16)\n"
     ]
    }
   ],
   "source": [
    "learn.fit(4, lr=0.2e-6, wd=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c9fc8a-7a4e-4efd-ac08-2ad5878e129b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
