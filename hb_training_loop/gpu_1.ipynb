{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_gpu_environ():\n",
    "    \"\"\"Sets CUDA_VISIBLE_DEVICES to those under minimal memory load.\n",
    "    Meant to be used in notebooks only.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import subprocess\n",
    "    query = subprocess.check_output(['nvidia-smi', '--query-gpu=memory.used', '--format=csv']).decode().split('\\n')[1:-1]\n",
    "    utilization = [int(x.replace(\" MiB\", \"\")) for x in query]\n",
    "    free = [i for i in range(len(utilization)) if utilization[i] == min(utilization)]\n",
    "    set_visible = \",\".join([str(i) for i in free])\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = set_visible\n",
    "    print(set_visible)\n",
    "set_gpu_environ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-03-09 14:26:59 - get_logger - Writing log to \u001b[1mlogs/graphnet_20230309-142659.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/slh/icecube/')\n",
    "import config\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "from contextlib import nullcontext\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "from icecube.modelsgraph import DynEdgeV1, gVonMisesFisher3DLoss, GraphxTransformerV4\n",
    "from icecube.graphdataset import GraphDasetV0\n",
    "from icecube.utils import gget_score_vector\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset, load_from_disk, concatenate_datasets\n",
    "from torch_geometric.loader import DataLoader as gDataLoader\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IceCubeModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name, \n",
    "        loss_func, \n",
    "        metric_func,\n",
    "        dl_len,\n",
    "        max_lr, \n",
    "        wd, \n",
    "        beta_1, \n",
    "        beta_2,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = model_name()\n",
    "        self.loss_func = loss_func()\n",
    "        self.metric_func = metric_func\n",
    "\n",
    "    def forward(self, batch):\n",
    "        out = self.model(batch)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        out = self.forward(batch)\n",
    "        loss = self.loss_func(out, batch.y)\n",
    "        self.log_dict({\"loss/train_step\": loss})\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        avg_loss = torch.stack([x[\"loss\"] for x in training_step_outputs]).mean()\n",
    "        self.log(\"loss/train\", avg_loss, sync_dist=True)\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        out = self.forward(batch)\n",
    "        loss = self.loss_func(out, batch.y)\n",
    "        score = self.metric_func(out, batch.y)\n",
    "\n",
    "        output = {\n",
    "            \"val_loss\": loss,\n",
    "            \"metric\": torch.tensor(score),\n",
    "        }\n",
    "\n",
    "        return output\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        loss_val = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        metric = torch.stack([x[\"metric\"] for x in outputs]).mean()\n",
    "\n",
    "        self.log_dict(\n",
    "            {\"loss/valid\": loss_val, \"metric\": metric},\n",
    "            prog_bar=True,\n",
    "            sync_dist=True,\n",
    "        )\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(),\n",
    "                                  lr=self.hparams.max_lr, \n",
    "                                  weight_decay=self.hparams.wd, \n",
    "                                  betas=(self.hparams.beta_1, self.hparams.beta_2))\n",
    "\n",
    "\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer,\n",
    "                num_warmup_steps=self.hparams.warmup_steps,\n",
    "                num_training_steps=self.hparams.dl_len,\n",
    "                )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1},\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(config_name):\n",
    "    configs = eval(f\"config.{config_name}\")\n",
    "    print(f\"Training with config: {configs.__dict__}\")\n",
    "    os.makedirs(configs.FOLDER/configs.EXP_NAME)\n",
    "    return configs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with config: {'__module__': 'config', 'FOLDER': Path('/opt/slh/icecube/RESULTS'), 'DATA_CACHE_DIR': Path('/opt/slh/icecube/data/hf_cashe'), 'EXP_NAME': 'EXP_100', 'TRN_BATCH_RANGE': (1, 650), 'VAL_BATCH_RANGE': (655, 656), 'METRIC': <function gget_score_vector at 0x7fc221164290>, 'TRN_DATASET': <class 'icecube.graphdataset.GraphDasetV0'>, 'VAL_DATASET': <class 'icecube.graphdataset.GraphDasetV0'>, 'BATCH_SIZE': 768, 'NUM_WORKERS': 22, 'PRESISTENT_WORKERS': True, 'LOSS_FUNC': <class 'icecube.modelsgraph.gVonMisesFisher3DLoss'>, 'MAX_LR': 0.0005, 'WD': 0.1, 'GRADIEN_ACCUMULATION_STEPS': 12, 'WARMUP_STEPS': 1000, 'BETA1': 0.9, 'BETA2': 0.95, 'MODEL': <class 'icecube.modelsgraph.GraphxTransformerV4'>, 'SCHEDULER': <function get_cosine_schedule_with_warmup at 0x7fbf7f5efd40>, '__dict__': <attribute '__dict__' of 'EXP_100' objects>, '__weakref__': <attribute '__weakref__' of 'EXP_100' objects>, '__doc__': None}\n"
     ]
    }
   ],
   "source": [
    "config = get_config('EXP_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "vld_pth = [\n",
    "        load_from_disk(config.DATA_CACHE_DIR / f\"batch_{i}.parquet\")\n",
    "        for i in range(config.VAL_BATCH_RANGE[0], config.VAL_BATCH_RANGE[1])\n",
    "    ]\n",
    "vld_pth = concatenate_datasets(vld_pth)\n",
    "vld_ds = config.VAL_DATASET(vld_pth)\n",
    "valid_dl = gDataLoader(\n",
    "        vld_ds,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=config.NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=config.PRESISTENT_WORKERS,\n",
    "    )\n",
    "nums = [i for i in range(config.TRN_BATCH_RANGE[0], config.TRN_BATCH_RANGE[1])]\n",
    "random.shuffle(nums)\n",
    "trn_pth = [\n",
    "                load_from_disk(config.DATA_CACHE_DIR / f\"batch_{i}.parquet\") for i in nums\n",
    "            ]\n",
    "trn_pth = concatenate_datasets(trn_pth)\n",
    "trn_ds = config.TRN_DATASET(trn_pth)\n",
    "train_dl = gDataLoader(\n",
    "            trn_ds,\n",
    "            batch_size=config.BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=config.NUM_WORKERS,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=config.PRESISTENT_WORKERS,\n",
    "        )\n",
    "\n",
    "dl_len = len(train_dl)// config.GRADIEN_ACCUMULATION_STEPS\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = IceCubeModel(model_name = config.MODEL, \n",
    "                  loss_func = config.LOSS_FUNC,\n",
    "                  metric_func = config.METRIC, \n",
    "                  dl_len = dl_len,\n",
    "                  max_lr = config.MAX_LR, \n",
    "                  wd = config.WD, \n",
    "                  beta_1 = config.BETA1,\n",
    "                  beta_2 = config.BETA2, \n",
    "                  warmup_steps = config.WARMUP_STEPS)\n",
    "#md.model.load_state_dict(torch.load('/opt/slh/icecube/RESULTS/EXP_25_FT/EXP_25_FT_2.pth'))\n",
    "#md.load_from_checkpoint(\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdrhb\u001b[0m (\u001b[33mkaggle-hi\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20230309_143223-3t8abvev</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kaggle-hi/ice/runs/3t8abvev\" target=\"_blank\">EXP_100</a></strong> to <a href=\"https://wandb.ai/kaggle-hi/ice\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26215fcb17b4ae7bc6d865c68335996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"ice\",\n",
    "         entity=\"kaggle-hi\",\n",
    "         name=config.EXP_NAME)\n",
    "\n",
    "chekpoint_callback = ModelCheckpoint(dirpath = config.FOLDER / config.EXP_NAME, \n",
    "                filename = \"{epoch:02d}-{metric:.4f}\", \n",
    "                monitor=\"metric\",\n",
    "                save_top_k=8, \n",
    "                save_last=True,\n",
    "                )\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=1, \n",
    "                    accelerator='gpu', \n",
    "                    devices=1,\n",
    "                    precision=16, \n",
    "                    accumulate_grad_batches=config.GRADIEN_ACCUMULATION_STEPS,\n",
    "                    gradient_clip_val=1.0,\n",
    "                    val_check_interval=len(train_dl)//8, \n",
    "                    logger=wandb_logger,\n",
    "                    callbacks=[chekpoint_callback, lr_monitor])\n",
    "\n",
    "trainer.fit(model=md, train_dataloaders = train_dl, val_dataloaders = valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "091bce3c30384a9fbc227741a9070ae3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0bfd39bc2c7745e196281cc8ef26a66a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1d42b3715b914550922bf5681cf94510": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "27af6ffb88b54f23b3e79f84b9173541": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_9aa5daeced354521a266811c5c41f136",
        "IPY_MODEL_ca32cee1e10742ac9751173271bff6a7"
       ],
       "layout": "IPY_MODEL_76505fa349324672b32d9819da1d106a"
      }
     },
     "328cd78f19234170bb3de3705f308c19": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "4cf9cd503339492f9d4352ccc87da0df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "51409c1067274dc5a8a9672b056e4edb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5eb3b65715e145acb0b3507d850a6f98": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6251d3fac8e546cfb71c9a22386c974e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "62d6b6655f3f40d4b05b815251f223d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_091bce3c30384a9fbc227741a9070ae3",
       "style": "IPY_MODEL_4cf9cd503339492f9d4352ccc87da0df",
       "value": " 110/171099 [01:42&lt;44:13:48,  1.07it/s, loss=2.68, v_num=bvev]"
      }
     },
     "76505fa349324672b32d9819da1d106a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7792c8045d4241dabbc9a5a319d3deb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7defd23f2778420bbec8deb45359f241": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "88f5ff35ec534b38948e41d1d6f9e23f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7defd23f2778420bbec8deb45359f241",
       "style": "IPY_MODEL_8a592413c0984bd889ec724f626e6e0f",
       "value": "Sanity Checking DataLoader 0: 100%"
      }
     },
     "8a592413c0984bd889ec724f626e6e0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9aa5daeced354521a266811c5c41f136": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_d0433d0ecb5a4338b954cfc4f71103b5",
       "style": "IPY_MODEL_d17e54ab87ef4fa8a0b2e4b1b1e02205"
      }
     },
     "a26215fcb17b4ae7bc6d865c68335996": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_bb8e8fab87384791880fe0b9951d4f79",
        "IPY_MODEL_ff91f8919506468982777bc16fa29f8c",
        "IPY_MODEL_62d6b6655f3f40d4b05b815251f223d0"
       ],
       "layout": "IPY_MODEL_328cd78f19234170bb3de3705f308c19"
      }
     },
     "b39926f6e5ad487a96044288d5d7bb6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "bb8e8fab87384791880fe0b9951d4f79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6251d3fac8e546cfb71c9a22386c974e",
       "style": "IPY_MODEL_51409c1067274dc5a8a9672b056e4edb",
       "value": "Epoch 0:   0%"
      }
     },
     "c2659f9391b04e58988a155d732c8a35": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "ca32cee1e10742ac9751173271bff6a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_0bfd39bc2c7745e196281cc8ef26a66a",
       "max": 1,
       "style": "IPY_MODEL_b39926f6e5ad487a96044288d5d7bb6c"
      }
     },
     "cfc2dea166a143949f99cd9da8ffde1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d0433d0ecb5a4338b954cfc4f71103b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d17e54ab87ef4fa8a0b2e4b1b1e02205": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d888c61171704f9bb14e8e365af5e258": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e2e217dd916549a8945873b1b0b6d4a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "f6797c1f61e0471293a9c63e860572cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_1d42b3715b914550922bf5681cf94510",
       "max": 2,
       "style": "IPY_MODEL_d888c61171704f9bb14e8e365af5e258",
       "value": 2
      }
     },
     "fbe52c84e6834fd6aaaae5f3753cc1b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7792c8045d4241dabbc9a5a319d3deb2",
       "style": "IPY_MODEL_5eb3b65715e145acb0b3507d850a6f98",
       "value": " 2/2 [00:01&lt;00:00,  1.55it/s]"
      }
     },
     "ff91f8919506468982777bc16fa29f8c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_c2659f9391b04e58988a155d732c8a35",
       "max": 171099,
       "style": "IPY_MODEL_cfc2dea166a143949f99cd9da8ffde1c",
       "value": 110
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
